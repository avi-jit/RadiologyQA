{"papers":[{"url":"https://www.semanticscholar.org/paper/18f9a6045ba01cb079c4fa49a630d71bbd27cd92","title":"A dataset of clinically generated visual questions and answers about radiology images","venue":"Scientific Data","year":2018,"referenceCount":23,"citationCount":86,"influentialCitationCount":31,"publicationDate":"20/11/2018","authors":"J. Lau,Soumya Gayen,Asma Ben Abacha,Dina Demner-Fushman","citations":[{"paperId":"ac4d13b6a4f9fb67337099f4602135a0351f5c99","title":"Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining"},{"paperId":"6ea380977abf56cc01bf01efbfd297bfa71a5073","title":"Assertiveness-based Agent Communication for a Personalized Medicine on Medical Imaging Diagnosis"},{"paperId":"4cf4528e3b19a22bcfb041d09be53bd3095bcef8","title":"Q2ATransformer: Improving Medical VQA via an Answer Querying Decoder"},{"paperId":"f7ea746cd2cc25628a7a553ac27d228198be42cb","title":"Pre-trained multilevel fuse network based on vision-conditioned reasoning and bilinear attentions for medical image visual question answering"},{"paperId":"9e8936a131ee0c765a6749d93bc58ad9522b7d6d","title":"Logical Implications for Visual Question Answering Consistency"},{"paperId":"3d45e69557f0c6a54ec698304c2e27ec29bc1c2b","title":"PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents"},{"paperId":"17ca48ad1b944c897863f04ba9ffa72674dce1ce","title":"Parallel multi-head attention and term-weighted question embedding for medical visual question answering"},{"paperId":"d8da72e7857cc1a0d3505e6c8a746eac815901b2","title":"Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language Processing"},{"paperId":"20fb06a4aa4010470d388098618af5d1bea224ad","title":"Vision–Language Model for Visual Question Answering in Medical Imagery"},{"paperId":"4d4a96708fc67403176bb2b891b564af7a20c148","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training"},{"paperId":"8200be2e8b9af243ee72a9d919a4f7fbe82a17d2","title":"Medical knowledge-based network for Patient-oriented Visual Question Answering"},{"paperId":"ffeeb60b76d18e1e36dee0f87c95bab1bc65aa79","title":"Medical visual question answering using joint self-supervised learning"},{"paperId":"9259c41695c4451f1ca3e6bdc9829623b43f9a69","title":"Interpretable Medical Image Visual Question Answering via Multi-Modal Relationship Graph Learning"},{"paperId":"da9579539385daedd33a0de0f814e2977ad0d1f5","title":"Towards Unifying Medical Vision-and-Language Pre-training via Soft Prompts"},{"paperId":"940f303c2530a52c5fd3c52c9c64ceea4b53ab05","title":"Diversity Learning Based on Multi-Latent Space for Medical Image Visual Question Generation"},{"paperId":"e0b4ca7bffb64b4bbd95c9f5ee7a610e35fe95d8","title":"A comprehensive interpretation for medical VQA: Datasets, techniques, and challenges"},{"paperId":"8a49d48f1ac243cf7ea92f7000cb8759eda37be0","title":"Barlow constrained optimization for Visual Question Answering"},{"paperId":"a627232a97a7a63f8399d157f0b022eb1ccd547c","title":"Biomedical Question Answering: A Survey of Approaches and Challenges"},{"paperId":"f4b9ec310ef9aff69066e3e482cc113c8ae8d9dd","title":"PathNarratives: Data annotation for pathological human-AI collaborative diagnosis"},{"paperId":"2ea26b243171e37ef20af269942ffde414f9f8cc","title":"UnICLAM: Contrastive Representation Learning with Adversarial Masking for Unified and Interpretable Medical Vision Question Answering"},{"paperId":"83caa8f9ec66a9ebae68d0e963ac7ca2396c94c2","title":"Is Unimodal Bias Always Bad for Visual Question Answering? A Medical Domain Study with Dynamic Attention"},{"paperId":"5942335fdd35d1651aaabd7af4db129a29ed2a85","title":"How Well Apply Multimodal Mixup and Simple MLPs Backbone to Medical Visual Question Answering?"},{"paperId":"56d8d9fff399f798da97a69e891de4eeb4568d4f","title":"MHKD-MVQA: Multimodal Hierarchical Knowledge Distillation for Medical Visual Question Answering"},{"paperId":"b60711d89c34d8902d4b2768f01770473cf0adfc","title":"Medical image enhancement strategy based on morphologically processing of residuals using a special kernel"},{"paperId":"170667a96f04adf3b3b83526f75fe8d1063e0f7a","title":"Self-supervised vision-language pretraining for Medical visual question answering"},{"paperId":"9d79f3601b0d73a2b64784cad2738c0fcd030824","title":"MF2-MVQA: A Multi-stage Feature Fusion method for Medical Visual Question Answering"},{"paperId":"6ae700c89a9a9a3da7e55dd51c4710b5ed8c8d4e","title":"Caption-Aware Medical VQA via Semantic Focusing and Progressive Cross-Modality Comprehension"},{"paperId":"d4d07180764fc30cf31261ddd072175a4daee10b","title":"A Dual-Attention Learning Network with Word and Sentence Embedding for Medical Visual Question Answering"},{"paperId":"8f93076f8e060eec0c058edb3de05f62886fffdf","title":"RepsNet: Combining Vision with Language for Automated Medical Reports"},{"paperId":"81adb80e390f25d4a2d764b1063eeaa2c334d441","title":"Multi-modal Masked Autoencoders for Medical Vision-and-Language Pre-training"},{"paperId":"28ff0816f19a5e3e37eac5569de41872fd262f0a","title":"Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge"},{"paperId":"8cee548aa6a8d31dcac830695e4b72960ff45ecb","title":"MMCN: Multi-Modal Co-attention Network for Medical Visual Question Answering"},{"paperId":"0cbd644254462341a897d4bfa0134637662c3ab5","title":"A Transformer-based Medical Visual Question Answering Model"},{"paperId":"2441230bd2f3cca924d597b3044ad63aaff269ec","title":"Self-supervised Co-learning of Uncurated Images and Reports Enables Oversight AI in Radiology"},{"paperId":"79478a2ac67b9fdbeadcde13faa2d84eb239e080","title":"Vision-Language Pretraining Enables Radiographs and Reports to be Learned without Curation"},{"paperId":"b047b3b7d76b79958e23b0fcab985be22b1ce42d","title":"Alternating Cross-attention Vision-Language Model for Efficient Learning with Medical Image and Report without Curation"},{"paperId":"ef7dd87e8bfd11878e88ec3f0795ebda8aaf1690","title":"A Bi-level representation learning model for medical visual question answering"},{"paperId":"0976f5e6e7c0481f5f44c981d9f676e9ea7fa4d0","title":"AMAM: An Attention-based Multimodal Alignment Model for Medical Visual Question Answering"},{"paperId":"ef2edea434e487f288d4eed6f9b1dc480b917211","title":"Adversarial Learning to Improve Question Image Embedding in Medical Visual Question Answering"},{"paperId":"2ac3bacbbee520b701707ebcf7b9ca7a3f233129","title":"Medical visual question answering via corresponding feature fusion combined with semantic attention."},{"paperId":"67f992f43cc777a3e1aedc14cf3a11582ccfa570","title":"OVQA: A Clinically Generated Visual Question Answering Dataset"},{"paperId":"6994c3cfd50e36f0d72dfa81807f98b639215b94","title":"OVQA"},{"paperId":"6e7763ec04906726377953cc85f31a1a0c889001","title":"Anomaly Matters: An Anomaly-Oriented Model for Medical Visual Question Answering"},{"paperId":"c98eafbef6fa40010fc3b78d96a04c41699e2c1b","title":"EBMs vs. CL: Exploring Self-Supervised Visual Pretraining for Visual Question Answering"},{"paperId":"e9480d62e216f77d5556b7eda769daa4c92d004d","title":"VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering"},{"paperId":"d1f25ff0b282486acf6ae225e5fd18a82673eb35","title":"Multi-Modal Alignment of Visual Question Answering Based on Multi-Hop Attention Mechanism"},{"paperId":"8c9a9a1bbba2a3e3bab34bce533b3b2acfda32b0","title":"Medical visual question answering based on question-type reasoning and semantic space constraint"},{"paperId":"38cbcaab9387c9c08df2f89fe93792c3dfe46a01","title":"BreastScreening-AI: Evaluating medical intelligent agents for human-AI interactions"},{"paperId":"fae23fc97a31bf66563dd033faf311eaaaa05911","title":"Exploratory analysis of different metaheuristic optimization methods for medical image enhancement"},{"paperId":"4ef3d9e492479e28fa57d107e52acc6a0c803de2","title":"Does CLIP Benefit Visual Question Answering in the Medical Domain as Much as it Does in the General Domain?"},{"paperId":"97af09b1436e768019aed4023cd1f9e3ccb9a635","title":"Medical Visual Question Answering: A Survey"},{"paperId":"39528ef1de5a6c1b4fba44071591e9f12167769c","title":"MVQAS: A Medical Visual Question Answering System"},{"paperId":"933242d263859a12c058979163f58035047d78b5","title":"Fine-grained Hand Gesture Recognition in Multi-viewpoint Hand Hygiene"},{"paperId":"ecf3163157d477d1a2188a3f8cf75c697a303708","title":"Goal-Driven Visual Question Generation from Radiology Images"},{"paperId":"e4f99837e02e7fbcccec1bf15cececacaaabbe32","title":"MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering"},{"paperId":"3795b18bb223ee70c6c4347ea371b28fffb671e8","title":"Automatic Generation of Structured Radiology Reports for Volumetric Computed Tomography Images Using Question-Specific Deep Feature Extraction and Learning"},{"paperId":"5bd42c29a5ba8a6c39547db89023d879e98a6b32","title":"Multiple Meta-model Quantifying for Medical Visual Question Answering"},{"paperId":"3c83f80f06633ff4598d33c2959f8e4cdcad3e93","title":"Cross-Modal Self-Attention with Multi-Task Pre-Training for Medical Visual Question Answering"},{"paperId":"17c2bb358169541f2d0a769f80779f46d1cd3d37","title":"MMBERT: Multimodal BERT Pretraining for Improved Medical VQA"},{"paperId":"a4d21d620a6cb7a8e6f06b996463172478562a0a","title":"Visual Question Answering using Data Mining Techniques for Skeletal Scintigraphy in medical domain - VQADMSS"},{"paperId":"93b6b79b4ef6c345f31722ce7c829385c6dce0d6","title":"Slake: A Semantically-Labeled Knowledge-Enhanced Dataset For Medical Visual Question Answering"},{"paperId":"9fe3eeafbe022de014aeb54d0b55502e2a2e46fe","title":"Hierarchical Deep Multi-modal Network for Medical Visual Question Answering"},{"paperId":"9ae30ac3609a90b487df3beec10eeface021c7c5","title":"Machine Learning in Computer Vision: A Review"},{"paperId":"1f96539c083d60fa83f7548bc6996cdede1026ee","title":"Biomedical Question Answering: A Comprehensive Review"},{"paperId":"2551990a1ccdffb1a4d1d9040b2d493ba6d26dd1","title":"Towards Visual Question Answering on Pathology Images"},{"paperId":"31acfba3a19f780a3239925ff12a7a4047d6a705","title":"MLEC-QA: A Chinese Multi-Choice Biomedical Question Answering Dataset"},{"paperId":"357fc385caf2e5b9898c9140fa3ac9955e6bb3c6","title":"TeamS at VQA-Med 2021: BBN-Orchestra for Long-tailed Medical Visual Question Answering"},{"paperId":"411c7a1fb951a1420013c0af56f9d142565112aa","title":"Chabbiimen at VQA-Med 2021: Visual Generation of Relevant Natural Language Questions from Radiology Images for Anomaly Detection"},{"paperId":"b8d5b853f2212cbb48a43f1edec9b96d76d388ec","title":"Medical Visual Question Answering via Conditional Reasoning"},{"paperId":"72e0dccf59f126a64f970fe9f4712b3221a3be8c","title":"Pathological Visual Question Answering"},{"paperId":"ff554f6228cf1f939a0e9e44ada06ef9cd28be15","title":"A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports"},{"paperId":"6609489a0f800a9ef411efdcfca4c014c4e86aa8","title":"Towards Visual Dialog for Radiology"},{"paperId":"d77a71c94e688d92a3fa10fb7f7feda2c306b9dc","title":"Visual Question Generation from Radiology Images"},{"paperId":"30f86e15b4fd7936b9812d476976a6ff579b9036","title":"Toward General Scene Graph: Integration of Visual Semantic Knowledge with Entity Synset Alignment"},{"paperId":"ed6ce80789889c0fd56c8117f85079c1c31fe426","title":"CGMVQA: A New Classification and Generative Model for Medical Visual Question Answering"},{"paperId":"fc0b46a0f3720e6c29c1a913aaa3de4a0699f713","title":"PathVQA: 30000+ Questions for Medical Visual Question Answering"},{"paperId":"f59ae732612ce8c42035adfb47bd5739c6288ad6","title":"Answering Questions about Data Visualizations using Efficient Bimodal Fusion"},{"paperId":"5c01315f0840d8bead978cd9a9cb4c21f0400805","title":"The Inception Team at VQA-Med 2020: Pretrained VGG with Data Augmentation for Medical VQA and VQG"},{"paperId":"39dbb2e49fb33351044a9b8c152a173b31f4c405","title":"Overview of the VQA-Med Task at ImageCLEF 2021: Visual Question Answering and Generation in the Medical Domain"},{"paperId":"33301b25a297b701bdc287e985c006375cb7bb21","title":"Overcoming Data Limitation in Medical Visual Question Answering"},{"paperId":"46699dd04d40efd34ae9088f945f672e50f9ec62","title":"Concept-Centric Visual Turing Tests for Method Validation"},{"paperId":"1526501f1939311106f72c128a189bbb6487ca6a","title":"SMAC: An Interpretable Reasoning Network for Visual Question Answering"},{"paperId":"cc71a905ca132999a158857823606cd979b9080e","title":"Visual Dialog for Radiology: Data Curation and FirstSteps"},{"paperId":"b7c9e854c1e9b964c8abe0cb80a744e2739ddf40","title":"Tlemcen University at ImageCLEF 2019 Visual Question Answering Task"},{"paperId":"9eeeb23546d3d2bbc73959bffc6819f2335f3c83","title":"VQA-Med: Overview of the Medical Visual Question Answering Task at ImageCLEF 2019"},{"paperId":"4634bf44a0c994e2bed89686225f8cef601a0224","title":"NLM at ImageCLEF 2018 Visual Question Answering in the Medical Domain"}],"references":[{"paperId":"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e","title":"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"},{"paperId":"2fdb8da25be54bbba1afcf05294fbede5ccdff37","title":"Visual Question Answering in Radiology (VQA-RAD)"},{"paperId":"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c","title":"VizWiz Grand Challenge: Answering Visual Questions from Blind People"},{"paperId":"589951bd421e2b701225fe6626fe980d94ad2770","title":"Overview of ImageCLEF 2018 Medical Domain Visual Question Answering Task"},{"paperId":"7e4b638e028498e900747b600f46cd723f1f231e","title":"Data Augmentation for Visual Question Answering"},{"paperId":"915b5b12f9bdebc321e970ecd713458c3479d70e","title":"An Analysis of Visual Question Answering Algorithms"},{"paperId":"2abde28f75a9135c8ed7c50ea16b7b9e49da0c09","title":"A survey on deep learning in medical image analysis"},{"paperId":"03eb382e04cca8cca743f7799070869954f1402a","title":"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning"},{"paperId":"fddc15480d086629b960be5bff96232f967f2252","title":"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding"},{"paperId":"0460d3497490fa8332c5ff2ecdab88fb7dff4755","title":"Learning to Read Chest X-Rays: Recurrent Neural Cascade Model for Automated Image Annotation"},{"paperId":"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d","title":"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","title":"Deep Residual Learning for Image Recognition"},{"paperId":"def584565d05d6a8ba94de6621adab9e301d375d","title":"Visual7W: Grounded Question Answering in Images"},{"paperId":"2c1890864c1c2b750f48316dc8b650ba4772adc5","title":"Stacked Attention Networks for Image Question Answering"},{"paperId":"0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac","title":"Deep Compositional Question Answering with Neural Module Networks"},{"paperId":"9b17b9c40ea8bb8904b782e91627c1f022a5574f","title":"Learning Knowledge Bases for Multimedia in 2015"},{"paperId":"580062407427236ced45253a2ff7df2e147a81e2","title":"The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)"},{"paperId":"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1","title":"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question"},{"paperId":"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db","title":"VQA: Visual Question Answering"},{"paperId":"eb42cf88027de515750f230b23b1a057dc782108","title":"Very Deep Convolutional Networks for Large-Scale Image Recognition"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","title":"Microsoft COCO: Common Objects in Context"},{"paperId":"d7da009f457917aa381619facfa5ffae9329a6e9","title":"Bleu: a Method for Automatic Evaluation of Machine Translation"},{"paperId":null,"title":"Data Citations"}],"id":"18f9a6045ba01cb079c4fa49a630d71bbd27cd92","summary":"This work introduces VQA-RAD, the first manually constructed dataset where clinicians asked naturally occurring questions about radiology images and provided reference answers and demonstrates the rich quality of this dataset over other automatically constructed ones."},{"url":"https://www.semanticscholar.org/paper/4d4a96708fc67403176bb2b891b564af7a20c148","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training","venue":"arXiv.org","year":2023,"referenceCount":46,"citationCount":2,"influentialCitationCount":0,"publicationDate":"01/03/2023","authors":"Zheng Yuan,Qiao Jin,Chuanqi Tan,Zhengyun Zhao,Hongyi Yuan,Fei Huang,Songfang Huang","citations":[{"paperId":"effc7842011fac2b9eefceec58f2a730d4d54c02","title":"LADER: Log-Augmented DEnse Retrieval for Biomedical Literature Search"},{"paperId":"052a5e2bcc999810ee6f1eedcf758c528e4f125f","title":"Retrieving Multimodal Information for Augmented Generation: A Survey"}],"references":[{"paperId":"a627232a97a7a63f8399d157f0b022eb1ccd547c","title":"Biomedical Question Answering: A Survey of Approaches and Challenges"},{"paperId":"81adb80e390f25d4a2d764b1063eeaa2c334d441","title":"Multi-modal Masked Autoencoders for Medical Vision-and-Language Pre-training"},{"paperId":"28ff0816f19a5e3e37eac5569de41872fd262f0a","title":"Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge"},{"paperId":"02251886950770e82b3d68564d60cdfe15e73199","title":"Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"},{"paperId":"0d975a8bbc1e0495cb95df8666d42111b546ab34","title":"Retrieval-Augmented Transformer for Image Captioning"},{"paperId":"5fa8f2a40ca9daa4063af8a27518bb7b74f890f2","title":"mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections"},{"paperId":"0db5207510819b9956849eb84bfe8703f8f3688d","title":"BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model"},{"paperId":"769eae977c287f7696ad8fd4cc568785fdbe1779","title":"PMC-Patients: A Large-scale Dataset of Patient Notes and Relations Extracted from Case Reports in PubMed Central"},{"paperId":"15115f67452f3305b69e6886cee98ac466d42cd5","title":"Retrieval Augmented Classification for Long-Tail Visual Recognition"},{"paperId":"94ff111c4d81bd03f159321728ceec8b4711c89d","title":"An Empirical Study of Training End-to-End Vision-and-Language Transformers"},{"paperId":"d9317660e2a538d9c018028956fd114d55330f82","title":"Multi-Modal Understanding and Generation for Medical Images and Text via Vision-Language Pre-Training"},{"paperId":"54523ff961a1ac57a86696ef9a53b3a630b482c0","title":"Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing"},{"paperId":"02c7c78fa8585b4f37420b9e0acbaf77d70108a8","title":"ViLMedic: a framework for research at the intersection of vision and language in medical AI"},{"paperId":"4ef3d9e492479e28fa57d107e52acc6a0c803de2","title":"Does CLIP Benefit Visual Question Answering in the Medical Domain as Much as it Does in the General Domain?"},{"paperId":"b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1","title":"Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"},{"paperId":"520bd2331cca8d5a9c032c186a2a0f7704ead6ff","title":"R-Drop: Regularized Dropout for Neural Networks"},{"paperId":"5bd42c29a5ba8a6c39547db89023d879e98a6b32","title":"Multiple Meta-model Quantifying for Medical Visual Question Answering"},{"paperId":"3c83f80f06633ff4598d33c2959f8e4cdcad3e93","title":"Cross-Modal Self-Attention with Multi-Task Pre-Training for Medical Visual Question Answering"},{"paperId":"58fe64beb45b18f63cbc001849a0dee3e4e60482","title":"Improving Biomedical Pretrained Language Models with Knowledge"},{"paperId":"17c2bb358169541f2d0a769f80779f46d1cd3d37","title":"MMBERT: Multimodal BERT Pretraining for Improved Medical VQA"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"93b6b79b4ef6c345f31722ce7c829385c6dce0d6","title":"Slake: A Semantically-Labeled Knowledge-Enhanced Dataset For Medical Visual Question Answering"},{"paperId":"2cbb8de53759e75411bc528518947a3094fbce3a","title":"Billion-Scale Similarity Search with GPUs"},{"paperId":"519799a9e2a72b808d81c6bcba5de263503de053","title":"Contrastive Pre-training and Representation Distillation for Medical Visual Question Answering Based on Radiology Images"},{"paperId":"eae760ee19c7d0c4e2b39adca209abcbc59e0a37","title":"Overview of the ImageCLEF 2021: Multimedia Retrieval in Medical, Nature, Internet and Social Media Applications"},{"paperId":"13e7212d5af59137ad770f42712d762247ebd3ed","title":"SYSU-HCP at VQA-Med 2021: A Data-centric Model with Efficient Training Methodology for Medical Visual Question Answering"},{"paperId":"c8b25fab5608c3e033d34b4483ec47e68ba109b7","title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"},{"paperId":"b8d5b853f2212cbb48a43f1edec9b96d76d388ec","title":"Medical Visual Question Answering via Conditional Reasoning"},{"paperId":"ea1f95989f808f409a3cd29b128000c04036c224","title":"Retrieval Augmented Language Model Pre-Training"},{"paperId":"58ed1fbaabe027345f7bb3a6312d41c5aac63e22","title":"Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"},{"paperId":"6bbd51697c25493ea15f4cac830e28eeac143898","title":"Randaugment: Practical automated data augmentation with a reduced search space"},{"paperId":"1e43c7084bdcb6b3102afaf301cce10faead2702","title":"BioBERT: a pre-trained biomedical language representation model for biomedical text mining"},{"paperId":"d1f407b16fb8d99487baee37ed0805676c58e7ac","title":"MIMIC-CXR, a de-identified publicly available database of chest radiographs with free-text reports"},{"paperId":"33301b25a297b701bdc287e985c006375cb7bb21","title":"Overcoming Data Limitation in Medical Visual Question Answering"},{"paperId":"a81874b4a651a740fffbfc47ef96515e8c7f782f","title":"Latent Retrieval for Weakly Supervised Open Domain Question Answering"},{"paperId":"156d217b0a911af97fa1b5a71dc909ccef7a8028","title":"SciBERT: A Pretrained Language Model for Scientific Text"},{"paperId":"d07284a6811f1b2745d91bdb06b040b57f226882","title":"Decoupled Weight Decay Regularization"},{"paperId":"9eeeb23546d3d2bbc73959bffc6819f2335f3c83","title":"VQA-Med: Overview of the Medical Visual Question Answering Task at ImageCLEF 2019"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"18f9a6045ba01cb079c4fa49a630d71bbd27cd92","title":"A dataset of clinically generated visual questions and answers about radiology images"},{"paperId":"a564fabf130ff6e2742cfba90c7a4018937d764d","title":"Radiology Objects in COntext (ROCO): A Multimodal Image Dataset"},{"paperId":"a5d10341717c0519cf63151b496a6d2ed67aa05f","title":"Bilinear Attention Networks"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","title":"Attention is All you Need"},{"paperId":null,"title":"Multimodal factorized bilinear pooling with co-attention learning for visual question answering"},{"paperId":"2c1890864c1c2b750f48316dc8b650ba4772adc5","title":"Stacked Attention Networks for Image Question Answering"},{"paperId":"47ced790a563344efae66588b5fb7fe6cca29ed3","title":"The Probabilistic Relevance Framework: BM25 and Beyond"}],"id":"4d4a96708fc67403176bb2b891b564af7a20c148","summary":"This paper collects a new biomedical dataset named PMCPM which offers patient-based image-text pairs containing diverse patient situations from PubMed and proposes a retrieval-augmented pretrain-and-finetune paradigm named RAMM for biomedical VQA to overcome the data limitation issue."},{"url":"https://www.semanticscholar.org/paper/93b6b79b4ef6c345f31722ce7c829385c6dce0d6","title":"Slake: A Semantically-Labeled Knowledge-Enhanced Dataset For Medical Visual Question Answering","venue":"IEEE International Symposium on Biomedical Imaging","year":2021,"referenceCount":15,"citationCount":23,"influentialCitationCount":8,"publicationDate":"18/02/2021","authors":"Bo Liu,Li-Ming Zhan,Li Xu,Lin Ma,Y. Yang,Xiao-Ming Wu","citations":[{"paperId":"ac4d13b6a4f9fb67337099f4602135a0351f5c99","title":"Towards Medical Artificial General Intelligence via Knowledge-Enhanced Multimodal Pretraining"},{"paperId":"3d45e69557f0c6a54ec698304c2e27ec29bc1c2b","title":"PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents"},{"paperId":"4d4a96708fc67403176bb2b891b564af7a20c148","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training"},{"paperId":"8200be2e8b9af243ee72a9d919a4f7fbe82a17d2","title":"Medical knowledge-based network for Patient-oriented Visual Question Answering"},{"paperId":"da9579539385daedd33a0de0f814e2977ad0d1f5","title":"Towards Unifying Medical Vision-and-Language Pre-training via Soft Prompts"},{"paperId":"940f303c2530a52c5fd3c52c9c64ceea4b53ab05","title":"Diversity Learning Based on Multi-Latent Space for Medical Image Visual Question Generation"},{"paperId":"560e0114a023bdfd99eb60eb4d9d555a348600a0","title":"PiggyBack: Pretrained Visual Question Answering Environment for Backing up Non-deep Learning Professionals"},{"paperId":"e678898301a66faab85dfa4c84e51118e434b8f2","title":"Vision-Language Transformer for Interpretable Pathology Visual Question Answering"},{"paperId":"2ea26b243171e37ef20af269942ffde414f9f8cc","title":"UnICLAM: Contrastive Representation Learning with Adversarial Masking for Unified and Interpretable Medical Vision Question Answering"},{"paperId":"5942335fdd35d1651aaabd7af4db129a29ed2a85","title":"How Well Apply Multimodal Mixup and Simple MLPs Backbone to Medical Visual Question Answering?"},{"paperId":"170667a96f04adf3b3b83526f75fe8d1063e0f7a","title":"Self-supervised vision-language pretraining for Medical visual question answering"},{"paperId":"6ae700c89a9a9a3da7e55dd51c4710b5ed8c8d4e","title":"Caption-Aware Medical VQA via Semantic Focusing and Progressive Cross-Modality Comprehension"},{"paperId":"28ff0816f19a5e3e37eac5569de41872fd262f0a","title":"Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge"},{"paperId":"0cbd644254462341a897d4bfa0134637662c3ab5","title":"A Transformer-based Medical Visual Question Answering Model"},{"paperId":"ef2edea434e487f288d4eed6f9b1dc480b917211","title":"Adversarial Learning to Improve Question Image Embedding in Medical Visual Question Answering"},{"paperId":"e9480d62e216f77d5556b7eda769daa4c92d004d","title":"VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering"},{"paperId":"22f2f53e7474af620268318ac3ff4bb5a4fe3ab4","title":"MED-GPVS: A Deep Learning-Based Joint Biomedical Image Classification and Visual Question Answering System for Precision e-Health"},{"paperId":"ab2ba04580edb4340a896b37543e77fdc2ec6bbf","title":"Hybrid deep learning model for answering visual medical questions"},{"paperId":"99267305914a44ad6d626b7a6406fd0079b5508d","title":"Incorporating Medical Knowledge to Transformer-based Language Models for Medical Dialogue Generation"},{"paperId":"4ef3d9e492479e28fa57d107e52acc6a0c803de2","title":"Does CLIP Benefit Visual Question Answering in the Medical Domain as Much as it Does in the General Domain?"},{"paperId":"97af09b1436e768019aed4023cd1f9e3ccb9a635","title":"Medical Visual Question Answering: A Survey"},{"paperId":"3c83f80f06633ff4598d33c2959f8e4cdcad3e93","title":"Cross-Modal Self-Attention with Multi-Task Pre-Training for Medical Visual Question Answering"},{"paperId":"357fc385caf2e5b9898c9140fa3ac9955e6bb3c6","title":"TeamS at VQA-Med 2021: BBN-Orchestra for Long-tailed Medical Visual Question Answering"}],"references":[{"paperId":"b8d5b853f2212cbb48a43f1edec9b96d76d388ec","title":"Medical Visual Question Answering via Conditional Reasoning"},{"paperId":"33301b25a297b701bdc287e985c006375cb7bb21","title":"Overcoming Data Limitation in Medical Visual Question Answering"},{"paperId":"4654aa505e5bcdb089d0df202cd7ceabc9d2d41f","title":"A large annotated medical image dataset for the development and evaluation of segmentation algorithms"},{"paperId":null,"title":"CHAOS - Combined (CT- MR) Healthy Abdominal Organ Segmentation Challenge Data"},{"paperId":"18f9a6045ba01cb079c4fa49a630d71bbd27cd92","title":"A dataset of clinically generated visual questions and answers about radiology images"},{"paperId":"b60630911d7746fba06de7c34abe98c9a61c6bcc","title":"FVQA: Fact-Based Visual Question Answering"},{"paperId":"05e882679d61f4c64a68ebe21826251a39f87e98","title":"ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases"},{"paperId":"03eb382e04cca8cca743f7799070869954f1402a","title":"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning"},{"paperId":"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5","title":"Analyzing the Behavior of Visual Question Answering Models"},{"paperId":"5fa973b8d284145bf0ced9acf2913a74674260f6","title":"Yin and Yang: Balancing and Answering Binary Visual Questions"},{"paperId":"2c1890864c1c2b750f48316dc8b650ba4772adc5","title":"Stacked Attention Networks for Image Question Answering"},{"paperId":"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db","title":"VQA: Visual Question Answering"},{"paperId":"eb42cf88027de515750f230b23b1a057dc782108","title":"Very Deep Convolutional Networks for Large-Scale Image Recognition"},{"paperId":"2582ab7c70c9e7fcb84545944eba8f3a7f253248","title":"Translating Embeddings for Modeling Multi-relational Data"},{"paperId":"038b582cccb00c54589c5563d9a00ee28dad83b0","title":"User-guided 3D active contour segmentation of anatomical structures: Significantly improved efficiency and reliability"}],"id":"93b6b79b4ef6c345f31722ce7c829385c6dce0d6","summary":"A large bilingual dataset, SLAKE, with comprehensive semantic labels annotated by experienced physicians and a new structural medical knowledge base for Med-VQA is presented, which includes richer modalities and covers more human body parts than the currently available dataset."},{"url":"https://www.semanticscholar.org/paper/1e43c7084bdcb6b3102afaf301cce10faead2702","title":"BioBERT: a pre-trained biomedical language representation model for biomedical text mining","venue":"Bioinform.","year":2019,"referenceCount":45,"citationCount":2887,"influentialCitationCount":536,"publicationDate":"25/01/2019","authors":"Jinhyuk Lee,Wonjin Yoon,Sungdong Kim,Donghyeon Kim,Sunkyu Kim,Chan Ho So,Jaewoo Kang","citations":[{"paperId":"ec23e0a536e0c2d09cfb115e11842fc4575043a2","title":"A social media event detection framework based on transformers and swarm optimization for public notification of crises and emergency management"},{"paperId":"316a845b449b64bed6f2aeab94045e5d77c25a8b","title":"Biomedical extractive question answering based on dynamic routing and answer voting"},{"paperId":"1681b374734559fe476aed69afaa2887f3576ad9","title":"BERT-based natural language processing analysis of French CT reports: Application to the measurement of the positivity rate for pulmonary embolism"},{"paperId":"37ebfbc27e9a9a9dd772a472c94c2ae664152508","title":"MasonNLP+ at SemEval-2023 Task 8: Extracting Medical Questions, Experiences and Claims from Social Media using Knowledge-Augmented Pre-trained Language Models"},{"paperId":"131c6f328c11706de2c43cd16e0b7c5d5e610b6a","title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"},{"paperId":"7480bf28ce20a03f8296925ec3eb6e71ee71935b","title":"Information Extraction Network Based on Multi-Granularity Attention and Multi-Scale Self-Learning"},{"paperId":"6e0fa1ec4c3007f26e091a35e74f81b37d2b525d","title":"Sebis at SemEval-2023 Task 7: A Joint System for Natural Language Inference and Evidence Retrieval from Clinical Trial Reports"},{"paperId":"12594b6afe01461384d2856d2bf44f1cf8533e3e","title":"ChatGPT and the rise of large language models: the new AI-driven infodemic threat in public health"},{"paperId":"da226d6e7007b39e7f5f0878894419858e3133cb","title":"Improving Model Transferability for Clinical Note Section Classification Models Using Continued Pretraining"},{"paperId":"76927634164d7c51514c63075779611d91709402","title":"Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training Exam (TXIT): Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology"},{"paperId":"938268731670916654eb3ccbfe71e79fe79b1822","title":"FineEHR: Refine Clinical Note Representations to Improve Mortality Prediction"},{"paperId":"286756b2b02d6a7bc49a7ad66686f30831f26c25","title":"Differentiate ChatGPT-generated and Human-written Medical Texts"},{"paperId":"40ae90005ba612cff567a96b7d0cedeca0d2635a","title":"On the Use of Transformer-Based Models for Intent Detection Using Clustering Algorithms"},{"paperId":"2d31cf90218fbf3ce4b220ab3bdff74e17d1b4f5","title":"Web Interface of NER and RE with BERT for Biomedical Text Mining"},{"paperId":"8e4558c878ecdac1091486727634c1ed5c8c38a8","title":"A Systematic survey on automated text generation tools and techniques: application, evaluation, and challenges"},{"paperId":"be545c9ec5e757513988a11cb7024e026616d8b4","title":"Multi-task learning for few-shot biomedical relation extraction"},{"paperId":"a0ec9f110ea172aa863862929cc0338934ff93c6","title":"Harnessing Biomedical Literature to Calibrate Clinicians’ Trust in AI Decision Support Systems"},{"paperId":"a564daa5ffdd4ea4cbb28b6ea459da9f9f65428d","title":"Faithful AI in Healthcare and Medicine"},{"paperId":"3f1ee0a36b970a0f8f118ccb3f6fd4ee4b5de949","title":"A Survey on Biomedical Text Summarization with Pre-trained Language Model"},{"paperId":"258605dc5b00fe66b72091f947642a554e472aee","title":"Exploring the Trade-Offs: Unified Large Language Models vs Local Fine-Tuned Models for Highly-Specific Radiology NLI Task"},{"paperId":"ea2504a6ca0a520af5ea0c96d00fb28cccc5d410","title":"A Biomedical Entity Extraction Pipeline for Oncology Health Records in Portuguese"},{"paperId":"c0f424d2a6f51f65e45d05662f3400062b3a0de5","title":"ImpressionGPT: An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT"},{"paperId":"7e97c05a1374082c49b69c8a19461490d6452efa","title":"EasyNER: A Customizable Easy-to-Use Pipeline for Deep Learning- and Dictionary-based Named Entity Recognition from Medical Text"},{"paperId":"9ec07ad77267af6c304bdf0c2b9c914d296b468b","title":"EDAD: Efficient Domain Adaptive Distillation by Integrating Domain Adaptation and Knowledge Distillation"},{"paperId":"c7705944c22a3d95413bc1a1950521662a25f1b3","title":"Bridging the Gap between Medical Tabular Data and NLP Predictive Models: A Fuzzy-Logic-Based Textualization Approach"},{"paperId":"90616bb932b345c83b5b70dffc76a75b14805315","title":"From benchmark to bedside: transfer learning from social media to patient-provider text messages for suicide risk prediction."},{"paperId":"965e0d4bfe8097baab1947fc23263ae790620e23","title":"AGI for Agriculture"},{"paperId":"12dc3ac67025588f4a94bc9cbe904eb11fd1534d","title":"The landscape of biomedical research"},{"paperId":"30fec23437cf9aaf3e9cb7d0c076483c14893abf","title":"An NLP approach to identify SDoH-related circumstance and suicide crisis from death investigation narratives."},{"paperId":"989c337316e25f8e5dadf3847f8bac36d4ed0e3c","title":"Drug–drug interaction extraction‐based system: An\n natural language processing\n approach"},{"paperId":"b8c9bcec47ac62105e32549e77aac979df8ad481","title":"DisGeReExT: a knowledge discovery system for exploration of disease–gene associations through large-scale literature-wide analysis study"},{"paperId":"89af504f2a9e0aeab794012ead793c61c76e86ba","title":"Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding"},{"paperId":"994b335b0e42955df63c3e963de47655f5aa8b8d","title":"How Does Imperfect Automatic Indexing Affect Semantic Search Performance?"},{"paperId":"1774405ae834c0e3c1f7af2b1e8f963fc23bd4a1","title":"Machine learning for synergistic network pharmacology: a comprehensive overview."},{"paperId":"cc22b83059214fbfb90e188e87461b0094dde226","title":"Linguistically inspired roadmap for building biologically reliable protein language models"},{"paperId":"0940155bec999067aba536d80e37f720ce91c4d0","title":"Automatic ICD-10 Code Association: A Challenging Task on French Clinical Texts"},{"paperId":"4b9a141650adfe60886f75466ad11c9a41647fac","title":"To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence Models for Improved Inference Efficiency"},{"paperId":"020e473d8c987dcfb03fcfffeb87b17812447031","title":"Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification"},{"paperId":"ab0746940abfa60d74e065377578adf389cb39c1","title":"G2PTL: A Pre-trained Model for Delivery Address and its Applications in Logistics System"},{"paperId":"5a2bd69547a7f03be30ed6e50a50f3616e5ab047","title":"DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical domains"},{"paperId":"538680e08812fadc22ac4a7eefa6b40ae9179b28","title":"Identifying Mentions of Pain in Mental Health Records Text: A Natural Language Processing Approach"},{"paperId":"bce55193d9a887ad00774a9134df08cd521a85ae","title":"DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task"},{"paperId":"a41552d69ca566bfc5c7f1b7e0e97fe61cadb7af","title":"Robust Identification of Figurative Language in Personal Health Mentions on Twitter"},{"paperId":"07bfaf2d713040efe69d0c61bcdfd9870bfbaf5a","title":"A novel self-attention enriching mechanism for biomedical question answering"},{"paperId":"80652b8e0c03ebfabb6255f097a9704dcb2b79ff","title":"Disto-TRP: An approach for identifying transient receptor potential (TRP) channels using structural information generated by AlphaFold."},{"paperId":"2da5b68b89d1d53373d122ac8e6fb2d23668c22f","title":"Toward structuring real-world data: Deep learning for extracting oncology information from clinical text with patient-level supervision"},{"paperId":"304b640c1b2559ac1442ac9be54853ac80ec248c","title":"Multimodal data fusion for cancer biomarker discovery with deep learning"},{"paperId":"4283021777631cbdc0e9a84218d37d2fe0e9f828","title":"Vision-Knowledge Fusion Model for Multi-Domain Medical Report Generation"},{"paperId":"10c7663b7875bd78bf3f3bce369239361f622de6","title":"Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler Alignment of Embeddings for Asymmetrical dual encoders"},{"paperId":"06c6eca6bf50d10f7e8a9d9a29f9457526a0d7a5","title":"Exploring the Potential of Large Language models in Traditional Korean Medicine: A Foundation Model Approach to Culturally-Adapted Healthcare"},{"paperId":"06cf8da98925503cd2f4186dc48d8ef454d5a6f6","title":"Methods of extracting biomedical information from patents and scientific publications (on the example of chemical compounds)"},{"paperId":"1ad9a295ea841599383e5ae3e88381438d4a7db3","title":"Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text"},{"paperId":"b88ca409c5585c9ab66ec35d0f37ea5aef9e7139","title":"oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes"},{"paperId":"364dab208cb5d1c91a37ec8eb5f9e3526517593f","title":"BloombergGPT: A Large Language Model for Finance"},{"paperId":"eaadcb852955ac2b664f7b7cd111a73661aa90df","title":"Biomedical named entity recognition based on fusion multi-features embedding."},{"paperId":"7724b53f9749339b903fdac3c6cca28571aaab73","title":"Zero-shot Clinical Entity Recognition using ChatGPT"},{"paperId":"df6ce09e914f278a95c5c2b6dfaecfaf6e81c8c7","title":"Identifying Reasons for Statin Nonuse in Patients With Diabetes Using Deep Learning of Electronic Health Records"},{"paperId":"0d7a0b53f65929776b851933d869fa753798bca3","title":"Carolina: a General Corpus of Contemporary Brazilian Portuguese with Provenance, Typology and Versioning Information"},{"paperId":"620facb14edcd4897c00e335569932392894778f","title":"A Disease-Prediction Protocol Integrating Triage Priority and BERT-Based Transfer Learning for Intelligent Triage"},{"paperId":"02634d754f4898ffd68623f8ff6f7861e700ef88","title":"Accurate and Reliable Classification of Unstructured Reports on Their Diagnostic Goal Using BERT Models"},{"paperId":"0f8f20ef4bc90a2b210bc5be08a7f326a214556f","title":"An Information Extraction Study: Take In Mind the Tokenization!"},{"paperId":"42c2507cf28070785b92342804aed1eba4380400","title":"Bias Amplification in Intersectional Subpopulations for Clinical Phenotyping by Large Language Models"},{"paperId":"ec13360ba5820b228333bc21d12f4871250546e8","title":"Lay Text Summarisation Using Natural Language Processing: A Narrative Literature Review"},{"paperId":"9305fd6d87007c7b90d2e0db579ff40467352969","title":"Natural language processing to automatically extract the presence and severity of esophagitis in notes of patients undergoing radiotherapy"},{"paperId":"2d0b9af28c80cfa5c87c08a249af7393c6b4695f","title":"Enabling Early Health Care Intervention by Detecting Depression in Users of Web-Based Forums using Language Models: Longitudinal Analysis and Evaluation"},{"paperId":"812b6f4dd78edb52959a660c1ac3cdcf5f8e13c6","title":"Bat4RCT: A suite of benchmark data and baseline methods for text classification of randomized controlled trials"},{"paperId":"3494e10a099ffef4e87f0a84d64af8f1a527b80c","title":"ChatGPT in glioma patient adjuvant therapy decision making: ready to assume the role of a doctor in the tumour board?"},{"paperId":"3f11e89e7f19e931adf31b91f15302d7539c809d","title":"A Joint Domain-Specific Pre-Training Method Based on Data Enhancement"},{"paperId":"44caf26949b4799e21f7b0754fe61315e8b71542","title":"Compositional Zero-Shot Domain Transfer with Text-to-Text Models"},{"paperId":"e9e52a94f1cd46da9ae47e40ba2981ba87cb92ab","title":"Analyzing the Generalizability of Deep Contextualized Language Representations For Text Classification"},{"paperId":"443d898928eb8e32d2e6f8f287beaa63f5b00eb9","title":"JaCoText: A Pretrained Model for Java Code-Text Generation"},{"paperId":"6fdcc152422c64de86c859b53669c0548261ec09","title":"GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering"},{"paperId":"3611674ccd820efc0b59981038bc4161d46b3add","title":"A Systematic Literature Review of the Use of Computational Text Analysis Methods in Intimate Partner Violence Research"},{"paperId":"994e08ac813028601907516aee9c4699234a6b4d","title":"Large AI Models in Health Informatics: Applications, Challenges, and the Future"},{"paperId":"79545d9d30b924df293ee103e46f78aaf3249e51","title":"Leveraging Foundation Models for Clinical Text Analysis"},{"paperId":"9f105fdbe301eb23371f35f697164a19e6c45ed5","title":"OpticalBERT and OpticalTable-SQA: Text- and Table-Based Language Models for the Optical-Materials Domain"},{"paperId":"cff26bda86237d113ed01c812ad8bedd0afbe070","title":"DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4"},{"paperId":"b243f303ad4309530bd423a82a256fcfeda2faae","title":"Exploring Partial Knowledge Base Inference in Biomedical Entity Linking"},{"paperId":"689e0dfcec660611c1f84490b3055b020b7bd0e1","title":"Public Awareness and Sentiment Analysis of COVID-Related Discussions Using BERT-Based Infoveillance"},{"paperId":"701e61977155143529e44264ccdb8443f07c4660","title":"IK-DDI: a novel framework based on instance position embedding and key external text for DDI extraction."},{"paperId":"0a438980ac42451d6d32dd2ad8ead7b55520408d","title":"A Systematic Review of Transformer-Based Pre-Trained Language Models through Self-Supervised Learning"},{"paperId":"eea77daf238730dd7e3686b33cf31bb771f058ff","title":"B-LBConA: a medical entity disambiguation model based on Bio-LinkBERT and context-aware mechanism"},{"paperId":"0429e9343424ded011eaa46547780c5c17f66fec","title":"A cross-modal deep metric learning model for disease diagnosis based on chest x-ray images"},{"paperId":"171598987de38aeac08ffa338df9e0bbd78d58ca","title":"Applying unsupervised keyphrase methods on concepts extracted from discharge sheets"},{"paperId":"6e96773bac534c87cf0eeaf11c5ba2a596b3380e","title":"Attention is not all you need: the complicated case of ethically using large language models in healthcare and medicine"},{"paperId":"8641c70c106c4f7485e613888b91a58e9812a5a7","title":"MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain"},{"paperId":"1fcd70f19c05c37f75bbf856cbb3b8bbef73373a","title":"Contextualized Medication Information Extraction Using Transformer-based Deep Learning Architectures"},{"paperId":"7d66ec6870d6773d559df20642bb2f30b106edc0","title":"Input-length-shortening and text generation via attention values"},{"paperId":"c7ccb92677afc2738868cf95d38af79a1adf7e9d","title":"Potential of natural language processing for metadata extraction from environmental scientific publications"},{"paperId":"bc1e3ae8cf66322a95e0475cdf79c867e1c9d026","title":"Self-supervised based general laboratory progress pretrained model for cardiovascular event detection"},{"paperId":"9556d7ad415cadb2c2d9b34e5fa5d9c2192a26b7","title":"Generating multiple-choice questions for medical question answering with distractors and cue-masking"},{"paperId":"17ca48ad1b944c897863f04ba9ffa72674dce1ce","title":"Parallel multi-head attention and term-weighted question embedding for medical visual question answering"},{"paperId":"3440687e1fc734baeab1abee4a86c81347d1422a","title":"aeroBERT-Classifier: Classification of Aerospace Requirements Using BERT"},{"paperId":"656e8c5f8bced540425c12d854b2911dddefff14","title":"Multimodal Data Integration for Oncology in the Era of Deep Neural Networks: A Review"},{"paperId":"e5174aeda1baa67c17f4ac630ae2e44453954cc3","title":"Personalisation within bounds: A risk taxonomy and policy framework for the alignment of large language models with personalised feedback"},{"paperId":"1475905e3687c21428ef3cad902d465093072fd1","title":"Deep multi-modal intermediate fusion of clinical record and time series data in mortality prediction"},{"paperId":"bdf7bf9e81a6c12e22323d0402885b2ba62f623e","title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?"},{"paperId":"38311d8f52e4fef86a121dd91923a1df798f79fd","title":"A Study of Text Summarization in the Medical Domain using BERT and its Variants"},{"paperId":"b388002a68143f94a6efb12ea75a2d18af64da0d","title":"The named entity recognition of vessel power equipment fault using the multi-details embedding model"},{"paperId":"914f807de0eaf055aded977419d5d22bb6078d90","title":"Document-level Relation Extraction with Cross-sentence Reasoning Graph"},{"paperId":"0606bb9a541ce7e57bd78ac680a7df0225ece30c","title":"Can large language models build causal graphs?"},{"paperId":"d0ea61e4e1413b6307d7adca333bf30be1b1dc22","title":"Enhancing Activity Prediction Models in Drug Discovery with the Ability to Understand Human Language"},{"paperId":"bd97d3171b5a9bbe9a0aae6c7461cb8f9123a5eb","title":"A Supervised Text Classification System Detects Fontan Patients in Electronic Records with Higher Accuracy than ICD Codes"},{"paperId":"883a5338dee175ae61f323202a5aba80b2458e0f","title":"Deep Learning Based Code Generation Methods: A Literature Review"},{"paperId":"d8da72e7857cc1a0d3505e6c8a746eac815901b2","title":"Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language Processing"},{"paperId":"eb78b34409a323fb36af93b5c252ee99a9c036b5","title":"Planarized sentence representation for nested named entity recognition"},{"paperId":"9991fe75b5c3d47699d7aa3b44f2a26a9b29eecd","title":"Extraction and analysis of risk factors from Chinese Chemical Accident Reports"},{"paperId":"10916b9df058a076238f6520435d0961419a4308","title":"Knowledge graph assisted end-to-end medical dialog generation."},{"paperId":"b169f2ce55e14584d2db6f64eeb5ad2702d39d40","title":"Artificial intelligence foundation and pre-trained models: Fundamentals, applications, opportunities, and social impacts"},{"paperId":"6c48f1a429e8371ebdac412602629cb6472db1a8","title":"Domain Word Extension Using Curriculum Learning"},{"paperId":"57c14d250f231bf56b3c68441aaa36d389281b0d","title":"Assessment of Natural Language Processing of Electronic Health Records to Measure Goals-of-Care Discussions as a Clinical Trial Outcome"},{"paperId":"a68ba8496d7c7125ac470057f7b2e8fb13845e3a","title":"Domain-adapted large language models for classifying nuclear medicine reports"},{"paperId":"809f3198289554fce309795219cdb42befede20e","title":"Almanac: Knowledge-Grounded Language Models for Clinical Medicine"},{"paperId":"4d4a96708fc67403176bb2b891b564af7a20c148","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training"},{"paperId":"1419dea18f214029959097c265024e9e9bc598f3","title":"WeakMeSH: Leveraging provenance information for weakly supervised classification of biomedical articles with emerging MeSH descriptors"},{"paperId":"1226d0618689ac3a262721c4ca5cd4d964a4919f","title":"CARES: A Corpus for classification of Spanish Radiological reports"},{"paperId":"31f32b26e6b997f9d5691a8edc6ea86e434865d8","title":"Constructing and analyzing domain-specific language model for financial text mining"},{"paperId":"34b897c4fb8d2ce64199aec8b29b57316d52e17d","title":"German Medical Named Entity Recognition Model and Data Set Creation Using Machine Translation and Word Alignment: Algorithm Development and Validation"},{"paperId":"41983c1fb9ee93a766cfaa1d5b1814e3d4f3d435","title":"Precision information extraction for rare disease epidemiology at scale"},{"paperId":"d8035d652a26bc96ceb9d0ba89460d11d4850e76","title":"Knowledge grounded medical dialogue generation using augmented graphs"},{"paperId":"8abee896e893dcf230c9e02de2bb435e33ecba76","title":"Survey on the Biomedical Text Summarization Techniques with an Emphasis on Databases, Techniques, Semantic Approaches, Classification Techniques, and Similarity Measures"},{"paperId":"209757d44937eb2b609e4b4ca984efefe6c29ace","title":"Language Models are Few-shot Learners for Prognostic Prediction"},{"paperId":"fefe6c2eb25da9f9f7982b8718f3abc1de2ada03","title":"Modelling Temporal Document Sequences for Clinical ICD Coding"},{"paperId":"7480d1e33e14ff113413de8dc09b7664dad1c0da","title":"Improving Clinical Decision Making with a Two-Stage Recommender System Based on Language Models: A Case Study on MIMIC-III Dataset"},{"paperId":"114655441607fbf58f5b174f2905a006b3853d91","title":"FiTs: Fine-grained Two-stage Training for Knowledge-aware Question Answering"},{"paperId":"ef959f7212091d0e9aa7502d15ef7d87dd70b902","title":"Identification of Thermophilic Proteins Based on Sequence-Based Bidirectional Representations from Transformer-Embedding Features"},{"paperId":"5c66d3d97746b7438d5b374e0322e79ab9e5ac5e","title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective"},{"paperId":"8ea7603260a648b7df42e749f28e9866aa48612d","title":"Construction of Knowledge Graphs: State and Challenges"},{"paperId":"b48adefb1d6a2da907f602c1d572704f4599792e","title":"S1000: A better taxonomic name corpus for biomedical information extraction"},{"paperId":"017dd6e9458d65cb1543bd6352900cd86c7ef83b","title":"Europe PMC Annotated Full-text Corpus for Gene/Proteins, Diseases and Organisms"},{"paperId":"460dea7c62ca0fdc27f671f50b76f477942dea12","title":"Improving text mining in plant health domain with GAN and/or pre-trained language model"},{"paperId":"f221280799e5cc9f4e43f2a26754ff802e22a3f0","title":"Question Answering Chatbots for Biomedical Research Using Transformers"},{"paperId":"b58c2110655e950c36bc533fa81f143397a5fe2e","title":"Exploring the Limits of Transfer Learning with Unified Model in the Cybersecurity Domain"},{"paperId":"692f49d243a23c220b40cbd2b6b26b773d9b31c4","title":"Hashtag-Guided Low-Resource Tweet Classification"},{"paperId":"534be0d0603866e71f873d9940e1281a5a3045fb","title":"Boosting classification reliability of NLP transformer models in the long run"},{"paperId":"6b6ea46e57d026c546e45cbe25ea4be55523a6b6","title":"On the Use of Knowledge Transfer Techniques for Biomedical Named Entity Recognition"},{"paperId":"48de1a31cca6631bd73a5d0854acfda5e5195d66","title":"BORD: A Biomedical Ontology based method for concept Recognition using Distant supervision: Application to Phenotypes and Diseases"},{"paperId":"99ecb1ffe691f5414d737c4cb8e824f513c0bb31","title":"Uni-Fold MuSSe: De Novo Protein Complex Prediction with Protein Language Models"},{"paperId":"d0c5f901868f6e2cb126fd51b155f631372a9669","title":"Biomedical Text Classification Using Augmented Word Representation Based on Distributional and Relational Contexts"},{"paperId":"ef91c31d8aab9fe95fec29149e2fe4568ab2fb32","title":"SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for Classification in Low-Resource Domains"},{"paperId":"505f446e82d4eac0862c6fac42371060e69ddfcb","title":"Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking"},{"paperId":"5ef821267fa68d3231ed8135ff8ec09f25bb1398","title":"ChatCAD: Interactive Computer-Aided Diagnosis on Medical Image using Large Language Models"},{"paperId":"629bc57782bb4326a3eb5f89314e350729c5f417","title":"AdapterSoup: Weight Averaging to Improve Generalization of Pretrained Language Models"},{"paperId":"1929c070964bac55a1d57d13bcaae44b28eb97fb","title":"BLIAM: Literature-based Data Synthesis for Synergistic Drug Combination Prediction"},{"paperId":"83c3bef2a3d24c31bccb8cf638dcdea630567089","title":"Expediting Distributed DNN Training With Device Topology-Aware Graph Deployment"},{"paperId":"dd4238d23fea6fc8e9232ca0fec4cad728f213ea","title":"Span-based Named Entity Recognition by Generating and Compressing Information"},{"paperId":"ce6f2d68b1a4029ff4a838fcf12d5ad1d47f0e68","title":"Multilingual translation for zero-shot biomedical classification using BioTranslator"},{"paperId":"d7047f54c65fee3c61288b3c490a862e95ae5092","title":"Lightweight Transformers for Clinical Natural Language Processing"},{"paperId":"292c3ca299362db1435ae8ea6a35929b430bdb17","title":"Zero-Shot Learning for Requirements Classification: An Exploratory Study"},{"paperId":"4562c122c523f7ea2b7c36ee524a47f59d7e74b2","title":"A Biomedical Knowledge Graph for Biomarker Discovery in Cancer"},{"paperId":"1e2839669f61fd99c524690e238f6cbe505e5ffd","title":"Real-Time Visual Feedback to Guide Benchmark Creation: A Human-and-Metric-in-the-Loop Workflow"},{"paperId":"9d379e0e77a57bf0c9e33576c465afcedd13ec89","title":"A prefix and attention map discrimination fusion guided attention for biomedical named entity recognition"},{"paperId":"fed2fab877ba1af72470d3dc061747d0ea9879d0","title":"Deep learning approach to detection of colonoscopic information from unstructured reports"},{"paperId":"2ad818c34b63aa2260542ac619b7098fb7745bac","title":"Machine learning and deep learning in medicine and neuroimaging"},{"paperId":"e7dcdfb7734d59b97f825cce8b3105a2d9b14d10","title":"The Effect of Metadata on Scientific Literature Tagging: A Cross-Field Cross-Model Study"},{"paperId":"e3ec55e9e6720194a0ed5d4033d93a941c8a4f99","title":"Continual Pre-training of Language Models"},{"paperId":"10c5079d2baa5a287054d9ddd7806a4c16fd7531","title":"UDApter - Efficient Domain Adaptation Using Adapters"},{"paperId":"2c6a6eb161c04d1f4149b38321b23878d24f2da3","title":"A survey on Transformers for long sentences and its application to medical notes"},{"paperId":"627b6f7687e122b5578f095221f66583850f0ea5","title":"GLADIS: A General and Large Acronym Disambiguation Benchmark"},{"paperId":"3b0424149731d10829015cb4ab6299d18162128e","title":"LIQUID: A Framework for List Question Answering Dataset Generation"},{"paperId":"4cfec8ec51a0ecd7efbc6e6622ae8f930935f714","title":"Bioformer: an efficient transformer language model for biomedical text mining"},{"paperId":"279cc657655eeb4e96a2eaf3d77f708edbf6a313","title":"Construction and evaluation of a domain-specific knowledge graph for knowledge discovery"},{"paperId":"cb1a64200edaa038326a177538b6b0d5ba21558a","title":"Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes"},{"paperId":"c41146620c907535b5f21c1f50f981f4c724f3d5","title":"Improving Protein Function Prediction by Adaptively Fusing Information From Protein Sequences and Biomedical Literature"},{"paperId":"31605129071ea6fca8e22e622de164e1a2ae1549","title":"Neurofuzzy semantic similarity measurement"},{"paperId":"f0b40e3bc7a4ed554e82905e6fb65cd8d3489f44","title":"ADPG: Biomedical entity recognition based on Automatic Dependency Parsing Graph."},{"paperId":"5e3ff15eba3770f479c1e44bc2fea54c4cab1384","title":"Transformer-based language models for mental health issues: A survey"},{"paperId":"3474e4bb497e5b5fc31a4c9757f55cd578678549","title":"Deep learning based classification of multi-label chest X-ray images via dual-weighted metric loss"},{"paperId":"47a1263ba21a72790334544f2a11b7c0ee4b5e76","title":"Multimodality Representation Learning: A Survey on Evolution, Pretraining and Its Applications"},{"paperId":"1755d306187b5b87110ae5e0006dc762942554a4","title":"Deep representation learning of scientific paper reveals its potential scholarly impact"},{"paperId":"02e6bd66517850b1ff446fc34acb647ac72f3ba9","title":"A role distinguishing Bert model for medical dialogue system in sustainable smart city"},{"paperId":"0acd41876736b1563d35588ab76cb4c2266052e9","title":"LFT-Net: Local Feature Transformer Network for Point Clouds Analysis"},{"paperId":"de7fa58930e86217498e6c3ac656366cfb39930a","title":"Supporting SNOMED CT postcoordination with knowledge graph embeddings"},{"paperId":"9bedc9b944b2480affea4832e38106ce5eccead5","title":"Classifying literature mentions of biological pathogens as experimentally studied using natural language processing"},{"paperId":"55a48a021b5927cc569b0fc461ba2e020f5356d6","title":"Large Language Models for Biomedical Causal Graph Construction"},{"paperId":"0824e6f75e18325a79b11e3e4a118409e3297f97","title":"ProtST: Multi-Modality Learning of Protein Sequences and Biomedical Texts"},{"paperId":"71dc990592911c454714e6fbe680dadf0cae1e45","title":"Context Matters: A Strategy to Pre-train Language Model for Science Education"},{"paperId":"3aa4b2873556b9039aa1ce64b1349c91ab70bbda","title":"A rule-free workflow for the automated generation of databases from scientific literature"},{"paperId":"cde6b633703eda8c3fbd7f76a967e07b19b7623d","title":"A Multi-View Joint Learning Framework for Embedding Clinical Codes and Text Using Graph Neural Networks"},{"paperId":"ca120bcaa4bc5e43f445bcfcc5e577d2112c5626","title":"TA-WHI"},{"paperId":"5ab6fb406369148bd604fa5e0ecb841d45899225","title":"Entity and relation extraction from clinical case reports of COVID-19: a natural language processing approach"},{"paperId":"51c7ba41ab310f05f34d4e0b2bc777e554dd40e0","title":"A Survey on BERT and Its Applications"},{"paperId":"76bed13bac28090bd0498757cc0c02a0ddaaa28c","title":"Task formulation for Extracting Social Determinants of Health from Clinical Narratives"},{"paperId":"811bd3079580e93c5297c882d2c59ff39df308ac","title":"Knowledge-augmented Graph Neural Networks with Concept-aware Attention for Adverse Drug Event Detection"},{"paperId":"ad8991af165bb1ecd83251867aba392adfaa0033","title":"Cross-lingual Argument Mining in the Medical Domain"},{"paperId":"223a498fd673c0fc83b4db6883052f57dbbc4278","title":"Semi-Automated Construction of Food Composition Knowledge Base"},{"paperId":"eb3f0b9a7ca8882d17328363f2eb182efda9a529","title":"Cross-lingual German Biomedical Information Extraction: from Zero-shot to Human-in-the-Loop"},{"paperId":"45f293dd4a4e13747937153817e043a346ffe617","title":"Large-scale fine-grained semantic indexing of biomedical literature based on weakly-supervised deep learning"},{"paperId":"95907abcf78601b9336f527b21915e6e9f6b4f82","title":"SPEC5G: A Dataset for 5G Cellular Network Protocol Analysis"},{"paperId":"868d5c655bb99e1ed8770d42698661dc1be12cb6","title":"Ensemble of deep learning language models to support the creation of living systematic reviews for the COVID-19 literature: a retrospective study"},{"paperId":"336c242e64a056026090e276ba855f83c839164d","title":"JCSE: Contrastive Learning of Japanese Sentence Embeddings and Its Applications"},{"paperId":"dd7f468b7e90f1d1149d238f59baea89011af31f","title":"Detection and cross-domain evaluation of cyberbullying in Facebook activity contents for Turkish"},{"paperId":"393791e54a6fb3fbcd72775e9cdb7c3e221b1907","title":"The 2022 n2c2/UW Shared Task on Extracting Social Determinants of Health"},{"paperId":"7389b6ebbf36f4d869a02e305e2ef52ad2c92264","title":"Applications of transformer-based language models in bioinformatics: a survey"},{"paperId":"924036c17537adc8574a1476bf13d9d17a6eebae","title":"ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English"},{"paperId":"728a34d0cbd7fef95ce8c6016e4db803d565b860","title":"Neighborhood-Regularized Self-Training for Learning with Few Labels"},{"paperId":"4a07c92996411dcdc94d42a3b1bef7b5093f3158","title":"COVID QA Network: A Specific Case of Biomedical Question Answering"},{"paperId":"27858514c71449e1368bc2ab235bd053db3dfc8a","title":"FullStop: Punctuation and Segmentation Prediction for Dutch with Transformers"},{"paperId":"fae35a63ec53f8e862fca83225608be0308a33d9","title":"Extraction of clinical phenotypes for Alzheimer’s disease dementia from clinical notes using natural language processing"},{"paperId":"77f4b467f0c70520a192ec74b98fcf15bd27c9b7","title":"A BERT-Based Artificial Intelligence to Analyze Free-Text Clinical Notes for Binary Classification in Papillary Thyroid Carcinoma Recurrence"},{"paperId":"44d53aa6df04dc99c441972cfd14b11ba12b1e2c","title":"End-to-End Transformer-Based Models in Textual-Based NLP"},{"paperId":"fed4bbb0e81bbc8c4ea65d55656a1145dfc1abad","title":"A review of research on eligibility criteria for clinical trials"},{"paperId":"b62b2b24378165df6a3dc904dde2b600745310f2","title":"CiT: Curation in Training for Effective Vision-Language Data"},{"paperId":"4ee4fd252e5016ab56e2edb21ad35b680d64cc48","title":"MuLan-Methyl - Multiple Transformer-based Language Models for Accurate DNA Methylation Prediction"},{"paperId":"cf0b1e762d8d88086799849a15c5c06ba76e95d9","title":"A hybrid algorithm for clinical decision support in precision medicine based on machine learning"},{"paperId":"7334e12961f8a15e2276217bbdb19709c427b337","title":"Extraction of knowledge graph of Covid-19 through mining of unstructured biomedical corpora"},{"paperId":"628f29add2f76eab14b9b7368e01b9a70d2b056a","title":"Adaptive Fine-tuning for Multiclass Classification over Software Requirement Data"},{"paperId":"81d133d94211a42a1bf58e38cbabf7fd65d33e23","title":"Automatic Extraction of Medication Mentions from Tweets—Overview of the BioCreative VII Shared Task 3 Competition"},{"paperId":"f5c02e59b431227029f0c821d8f0fa72c75da700","title":"Using Semantic Text Similarity calculation for question matching in a rheumatoid arthritis question-answering system"},{"paperId":"ad42d24f6f9cdbd2cc10da665c19e6b7dc033c80","title":"Chemical identification and indexing in full-text articles: an overview of the NLM-Chem track at BioCreative VII"},{"paperId":"8d5fd95e1042ec0dad1a953345196c9e61496901","title":"A Controlled Attention for Nested Named Entity Recognition"},{"paperId":"7aa11ff454d33ba4e79ffdd75c8a807061ed4715","title":"How data science and AI-based technologies impact genomics"},{"paperId":"ffa5d9a21a410b8a9416263f06d507be101d9628","title":"Discovering research articles containing evolutionary timetrees by machine learning"},{"paperId":"6d90f477a970effb70e2d1863c968da400a95576","title":"Identifying and Analyzing Topic Clusters in a Nutri-, Food-, and Diet-Proteomic Corpus Using Machine Reading"},{"paperId":"7e4bca67428c3b9487df550c65b36146ed278894","title":"A Machine Learning Approach for the NLP-Based Analysis of Cyber Threats and Vulnerabilities of the Healthcare Ecosystem"},{"paperId":"4b3cfa21f1baa1c4ebfab5162f477d8b031709d7","title":"Negation-based transfer learning for improving biomedical Named Entity Recognition and Relation Extraction."},{"paperId":"9d697c46e6fa79f4c3a283c7539cb58f8cd5e2e8","title":"Federated Learning with Client-Exclusive Classes"},{"paperId":"d53233323d143ed357a7b4dd5e7323ee0186706f","title":"Stacking-BERT model for Chinese medical procedure entity normalization."},{"paperId":"77fae38e1790885ad8a4f913f1d7848e9d0efba2","title":"Cluster-based text mining for extracting drug candidates for the prevention of COVID-19 from the biomedical literature"},{"paperId":"cfc946053eabf9c24443171da1c4cdd216bbaca4","title":"A Marker-based Neural Network System for Extracting Social Determinants of Health"},{"paperId":"ad1669c3d6670b26e2cd5c50f463971cf7f92835","title":"Domain Adaptation of Transformer-Based Models Using Unlabeled Data for Relevance and Polarity Classification of German Customer Feedback"},{"paperId":"45dfaebd44bbd8c67c046bc8b8cf013c38a897ae","title":"Associations Between Natural Language Processing–Enriched Social Determinants of Health and Suicide Death Among US Veterans"},{"paperId":"3f2c0ce0020285f278e467157b5475fe4b9c3fda","title":"Two-phase self-supervised pretraining for object re-identification"},{"paperId":"a0059d3baf01c6ad402d1b94232313965a059135","title":"Machine understanding surgical actions from intervention procedure textbooks"},{"paperId":"c3d877b29594bc6f244e638f576be3dca5551f11","title":"A Comparative Study of Pretrained Language Models for Long Clinical Text"},{"paperId":"b3011e3c34af29039ee6e62f8fd5c83307f8a358","title":"Towards semantic-driven boolean query formalization for biomedical systematic literature reviews"},{"paperId":"63f02dfd1ecdd945e24d80b25e64f94c4f722bc1","title":"A Novel Automated Approach to Mutation-Cancer Relation Extraction by Incorporating Heterogeneous Knowledge"},{"paperId":"d5001b854785771ded1c9c8f52d5d4e8d0045bf4","title":"An Easy-to-use and Robust Approach for the Differentially Private De-Identification of Clinical Textual Documents"},{"paperId":"b9779c84abf33a4a7d8a76b6f6344cde13c8be83","title":"TOE: A Grid-Tagging Discontinuous NER Model Enhanced by Embedding Tag/Word Relations and More Fine-Grained Tags"},{"paperId":"0d0900f2afa1db5c4133907aaaacb21b9a8d86b3","title":"Pre-trained Language Model-based Retrieval and Ranking for Web Search"},{"paperId":"3a692230558c6ed35f13403aedd57f10803c37d7","title":"End-to-End Entity Detection with Proposer and Regressor"},{"paperId":"e02dce6ee032a13b1653f69b034a35676e7d4dc2","title":"Can language representation models think in bets?"},{"paperId":"ef66e86322b5ae1e2524ad48294002c71b94830d","title":"Assessing the Impact of Contextual Information in Hate Speech Detection"},{"paperId":"9b349c140144c7a1d5e710ce3384f259863c8318","title":"How do others cope? Extracting coping strategies for adverse drug events from social media"},{"paperId":"5bbf3bd92ef05e65580e5d673f7c9302287f99b0","title":"AI-based ICD coding and classification approaches using discharge summaries: A systematic literature review"},{"paperId":"9ab6727fade0fa3f7a121801069eae9cc1ab6f50","title":"DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language Processing"},{"paperId":"e26197fb0fa409866b287f4bf63abe7997223b51","title":"A general-purpose material property data extraction pipeline from large polymer corpora using natural language processing"},{"paperId":"3ff823d50875fee0dc2c6205709920ab022e2022","title":"Adaptation of domain-specific transformer models with text oversampling for sentiment analysis of social media posts on Covid-19 vaccines"},{"paperId":"3b97687f80cf2ed753789429ba6d2e53667a0dd7","title":"On the effectiveness of compact biomedical transformers"},{"paperId":"4cd4e271bf5cc365a016c312b7c8e66c5ed926e0","title":"POPDx: an automated framework for patient phenotyping across 392 246 individuals in the UK Biobank study"},{"paperId":"a28f9187b8c213182bdcbfaeaa4d4f04ae6366dd","title":"Review of Natural Language Processing in Pharmacology."},{"paperId":"61ff8bd9e68401c8ed9617600b1f671bde0e6d05","title":"Extracting Medication Changes in Clinical Narratives using Pre-trained Language Models"},{"paperId":"570cae4358f8e25d0adb75ab7d5c2a319b9931c2","title":"Joint Learning-based Causal Relation Extraction from Biomedical Literature"},{"paperId":"483733446c603be75f24985716c452c472b3b4ef","title":"Calibrating a Transformer-Based Model’s Confidence on Community-Engaged Research Studies: Decision Support Evaluation Study"},{"paperId":"079dac66f13edc1afa80e64dffe7910e6907d266","title":"Knowledge-Driven Mechanistic Enrichment of the Preeclampsia Ignorome"},{"paperId":"3c49a23f72f6337ee68d57911e211fcbbdca6091","title":"Fine-Tuning BERT for Automatic ADME Semantic Labeling in FDA Drug Labeling to Enhance Product-Specific Guidance Assessment"},{"paperId":"c0a85e549131133bc6fc512f7001d8cb897f8e9c","title":"Fine-tuning Strategies for Classifying Community-Engaged Research Studies Using Transformer-Based Models: Algorithm Development and Improvement Study"},{"paperId":"87cb212eeb40171b32a4411a6919e22c36822140","title":"Design of a Novel Information System for Semi-automated Management of Cybersecurity in Industrial Control Systems"},{"paperId":"e0aceea5c0d00e602eb0179f6bd6a3a32bb8100a","title":"FinBERT-MRC: financial named entity recognition using BERT under the machine reading comprehension paradigm"},{"paperId":"b7d2db37e8af746b9324ff4c647123e92b59f5ba","title":"Biomedical Argument Mining Based on Sequential Multi-Task Learning"},{"paperId":"e77078d5ddcaf5c76fe1c291c2b7cbc7518afc23","title":"Improving Biomedical Question Answering by Data Augmentation and Model Weighting"},{"paperId":"b7967741deb2410e58f01cadf924381a6b0d601c","title":"PhenoBERT: A Combined Deep Learning Method for Automated Recognition of Human Phenotype Ontology"},{"paperId":"0f4111f0d8b5078ee5bb605f63fa682c74953816","title":"Design considerations for a hierarchical semantic compositional framework for medical natural language understanding"},{"paperId":"6d22954e201b71658a43c26f23a162cb9a475dd0","title":"Adversarial Knowledge Distillation Based Biomedical Factoid Question Answering"},{"paperId":"c5f51c35242c3392fb759c58f9d9b843bf154c37","title":"Noise Reduction Learning Based on XLNet-CRF for Biomedical Named Entity Recognition"},{"paperId":"16ca91786f6167c6d409cd809b0f4f77482caebf","title":"Multimodal Data Matters: Language Model Pre-Training Over Structured and Unstructured Electronic Health Records"},{"paperId":"26af463d2eb3c045eb3e9b2e769bc576d82327c1","title":"Knowledge Guided Attention and Graph Convolutional Networks for Chemical-Disease Relation Extraction"},{"paperId":"a9c5e23c5559bfc4d95dd166c1ed29fa026bbf2e","title":"Fine-Tuning Large Neural Language Models for Biomedical Natural Language Processing"},{"paperId":"11907f691e9b7fc32a492e1de676a4b788add155","title":"On the Validity of Pre-Trained Transformers for Natural Language Processing in the Software Engineering Domain"},{"paperId":"d98c73269ccd34c9fad714916c4c47ee96248713","title":"TravelBERT: Pre-training Language Model Incorporating Domain-specific Heterogeneous Knowledge into A Unified Representation"},{"paperId":"31ffee372c8c41bed0c35304c61150c834edf2f2","title":"Technology identification from patent texts: A novel named entity recognition method"},{"paperId":"28692beece311a90f5fa1ca2ec9d0c2ce293d069","title":"Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing"},{"paperId":"1db13d5bccede0dba791be7fb37d853d71b57d34","title":"ICD2Vec: Mathematical representation of diseases."},{"paperId":"d4134cadce1a6f89648b455cda81e9ebb8f9046e","title":"How Context or Knowledge Can Benefit Healthcare Question Answering?"},{"paperId":"a7266bc2229ef8da4baf769eab925646601dfaad","title":"Beyond Self-Attention: External Attention Using Two Linear Layers for Visual Tasks"},{"paperId":"48597f5aaebf9cb280df0e2fe6d7723074e0a734","title":"PharmKE: Knowledge Extraction Platform for Pharmaceutical Texts using Transfer Learning"},{"paperId":"a627232a97a7a63f8399d157f0b022eb1ccd547c","title":"Biomedical Question Answering: A Survey of Approaches and Challenges"},{"paperId":"4cae6a6989074fdfca057d6b4455c1e2e679e176","title":"COVIDScholar: An automated COVID-19 research aggregation and analysis platform"},{"paperId":"126fb7df6bcab2b70000dfe5b940ada63ae1ba6a","title":"COVID-Twitter-BERT: A natural language processing model to analyse COVID-19 content on Twitter"},{"paperId":"6ae1c3e4a22370fbab8c5c9baad9c9806f9bc6cf","title":"ChestXRayBERT: A Pretrained Language Model for Chest Radiology Report Summarization"},{"paperId":"3b6db44f29b02bbdcf7b74490735b87783172c2e","title":"Boosting Transformers and Language Models for Clinical Prediction in Immunotherapy"},{"paperId":"12f717cb08cafef453c43394079838b9602c3696","title":"cpgQA: A Benchmark Dataset for Machine Reading Comprehension Tasks on Clinical Practice Guidelines and a Case Study Using Transfer Learning"},{"paperId":"9159408884cbe7f5f7a79d90c9f91ba5cee0d932","title":"A Survey of Text Representation and Embedding Techniques in NLP"},{"paperId":"2147a8b64f406945d0d670a6dbab99b536d6e45f","title":"Document-level relation extraction with multi-layer heterogeneous graph attention network"},{"paperId":"758e94d65a10783c2a64e478a2103224d295ab13","title":"Enhanced disease-disease association with information enriched disease representation"},{"paperId":"139516aa7e5f9b214db20c280319f897047e3102","title":"Examine the Effectiveness of Patent Embedding-Based Company Comparison Method"},{"paperId":"c0cba2c9fe11f981ad2925e86d25235f2c94b1eb","title":"Continual Learning of Language Models"},{"paperId":"2209b03a9c7fe1ca5a172627099eedeb1872b6ca","title":"Study of Word Embeddings for Enhanced Cyber Security Named Entity Recognition"},{"paperId":"c0394c737b61c7471987edf8374f1310049d6aec","title":"Improving biomedical named entity recognition through transfer learning and asymmetric tri-training"},{"paperId":"45682ab07edcd5eea200084ea7346d657607f852","title":"Domain Adaptation: Challenges, Methods, Datasets, and Applications"},{"paperId":"7a0394aa776919914b8c8ac44e3e2b4c6b540cf7","title":"Classification of Medical Image Notes for Image Labeling by Using MinBERT"},{"paperId":"6f67cc28299a3ed7d5705a75af7479082ed61245","title":"Annotated Open Corpus Construction and BERT-Based Approach for Automatic Metadata Extraction From Korean Academic Papers"},{"paperId":"9dd88802b33d000a72aaba24d16e6511227381b8","title":"Improving Bug Localization With Effective Contrastive Learning Representation"},{"paperId":"fea314f9242194f6f1a796fa84c709862cd712c5","title":"Comparison of BERT implementations for natural language processing of narrative medical documents"},{"paperId":"5fa4f4da07d5edcbce0abfb93a880d2d78af3ae8","title":"Workload-Aware Query Recommendation Using Deep Learning"},{"paperId":"89cbb16aea55469e56a7b5051196e14055511a00","title":"DDI-MuG: Multi-aspect Graphs for Drug-Drug Interaction Extraction"},{"paperId":"4ce68478791bd4cfcdf883d75fa31fc1ebc6c7cc","title":"FrenchMedMCQA: A French Multiple-Choice Question Answering Dataset for Medical domain"},{"paperId":"e3f839b01567ae73af822a3da5e160dac2fb4708","title":"Adapting a Language Model While Preserving its General Knowledge"},{"paperId":"9e859882b43d2c84b4689a6ac71f7c9eb4456cf4","title":"Latent representation of single-cell transcriptomes enables algebraic operations on cellular phenotypes"},{"paperId":"b97ed0d8f7e68cddb87a3016c6c454bc60487459","title":"Identifying Tweets with Personal Medication Intake Mentions using Attentive Character and Localized Context Representations"},{"paperId":"7593a16e7b966ba327856af52ff48fb5de92694f","title":"Building Large-Scale Registries from Unstructured Clinical Notes using a Low-Resource Natural Language Processing Pipeline"},{"paperId":"2cce05dcae43fe3fb5a251f500a455cafe0be0e8","title":"Natural Language Interfaces to Data"},{"paperId":"482b544dc4b26d41d728d0a08adedb6b2e7deef1","title":"ABEE: automated bio entity extraction from biomedical text documents"},{"paperId":"9b9faaf2c33bdd1418bdc8255711c4cf66f31fb8","title":"Explainable AI for Bioinformatics: Methods, Tools, and Applications"},{"paperId":"136141b6eb604168d049df52f69ac2235a94cf64","title":"A Comprehensive Study of Gender Bias in Chemical Named Entity Recognition Models"},{"paperId":"7c6398d0b602a6b11691ddaf579e8a083ea2912b","title":"Generalizable Natural Language Processing Framework for Migraine Reporting from Social Media"},{"paperId":"4050bb719f353b7bbea902d3819115fbeb768325","title":"LiSA: an assisted literature search pipeline for detecting serious adverse drug events with deep learning"},{"paperId":"d38a1c1a15d7bd48a70e91afbed13161d6829409","title":"Edge Weight Updating Neural Network for Named Entity Normalization"},{"paperId":"ad3d4de3db4a3ad5bf086d1ece82c0ab837a90ae","title":"Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?"},{"paperId":"cf847918dc4e269699adc46535c225d7f8e54bef","title":"Exploring the effects of drug, disease, and protein dependencies on biomedical named entity recognition: A comparative analysis"},{"paperId":"365f5c1248fced6bee17a44b2bb53b2b4a1fa97e","title":"Localising In-Domain Adaptation of Transformer-Based Biomedical Language Models"},{"paperId":"284d8112888d4511f953add862447cb6b46eb126","title":"Pre-trained Language Models for Keyphrase Generation: A Thorough Empirical Study"},{"paperId":"c707cc6d6b6c617242eab3a09aa35749f89d095b","title":"PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English"},{"paperId":"e1ee25d3b09a5eb43d0145ff5ac58c7c8ae965ed","title":"Detecting Contradictory COVID-19 Drug Efficacy Claims from Biomedical Literature"},{"paperId":"f8295290551f82b325c3a3598d7eb7593508ada7","title":"JCBIE: a joint continual learning neural network for biomedical information extraction"},{"paperId":"f0684f48f7409b94a2391641d9ecb4d15cdfc5ff","title":"ShockModes: A Multimodal Model for Prognosticating Intensive Care Outcomes from Physician Notes and Vitals"},{"paperId":"51b6c7d3209536fcfd31cb5e5d4c38587ff046e3","title":"Automated Diagnosis Code Assignment of Thai Free-text Clinical Notes"},{"paperId":"c6ff92e68ac2f263610f202b531906bd95be7879","title":"A comprehensive review on knowledge graphs for complex diseases."},{"paperId":"c5bae5fc68785de447c0131ac79400e39f2aff7e","title":"Mining Latent Disease Factors from Medical Literature using Causality"},{"paperId":"054dd061a42086ab2758141655bebd7559b144fa","title":"SciFoodNER: Food Named Entity Recognition for Scientific Text"},{"paperId":"9bc765306867be1a25a00a124abb32f48ccad437","title":"Symptoms Based Disease Prediction from Bengali Text Using Transformer Network Based Pretrained Model"},{"paperId":"f8ec289d7f4e12440c5b535a6fdd7bb8f0e42280","title":"Radiopaths: Deep Multimodal Analysis on Chest Radiographs"},{"paperId":"d0b74c24e95193896aec376910188e5c7bde1799","title":"Extracting Protein-Protein Interactions (PPIs) from Biomedical Literature using Attention-based Relational Context Information"},{"paperId":"9a7bce3c8161c45c9e3302a3e2a898e9124e3fbe","title":"Emotion Recognition on StackOverflow Posts Using BERT"},{"paperId":"c9fd961913713132e63960b88be0bc5a3e15f99f","title":"GeoBERT: Pre-Training Geospatial Representation Learning on Point-of-Interest"},{"paperId":"ce0a398b240b2a3ae114bbaef805226759d107bd","title":"CafeteriaSA corpus: scientific abstracts annotated across different food semantic resources"},{"paperId":"939629c488543676aeee9ecb953f246e14a13945","title":"LegalRelectra: Mixed-domain Language Modeling for Long-range Legal Text Comprehension"},{"paperId":"64dcb27e5c31c8567725c7f67000feaa487c32e0","title":"The Effects of In-domain Corpus Size on pre-training BERT"},{"paperId":"967dbdfecb348a7bce2dd58cbdd7ae245f796618","title":"Neural Rankers for Effective Screening Prioritisation in Medical Systematic Review Literature Search"},{"paperId":"040ec58865ab50b5e6d91a355ffc146ec5034e9f","title":"Artificial Intelligence for Health Message Generation: Theory, Method, and an Empirical Study Using Prompt Engineering"},{"paperId":"47ba324f6e674b5c3b93f9d9e08d0b7968f9d53f","title":"Creating an Ignorance-Base: Exploring Known Unknowns in the Scientific Literature"},{"paperId":"d6ebf7e57d6762ae04820fa4bce852741369b160","title":"Automated ICD Coding using Extreme Multi-label Long Text Transformer-based Models"},{"paperId":"24d1d8235843b016a2cf06278606286f636dd8eb","title":"Pivot-based Unsupervised Domain Adaptation for Pre-trained Language Model"},{"paperId":"32829047e381ddf1130a3b71bf69d2c143dc6bec","title":"A Unified Knowledge Graph Service for Developing Domain Language Models in AI Software"},{"paperId":"9d06ef8ecab568b371727df9a47dff3b2e26fc61","title":"Improving Precancerous Case Characterization via Transformer-based Ensemble Learning"},{"paperId":"5ef125153b17dede6b7eb5456067bee57f09eb5e","title":"MED-SE: Medical Entity Definition-based Sentence Embedding"},{"paperId":"94dadfb4d2e321e84073fb5359a35375db65d35e","title":"A Transfer Learning based Model for Knowledge Graph in Power Grid"},{"paperId":"87778991ffea60f1d4e80d726335338270ecc2f6","title":"AUC Maximization for Low-Resource Named Entity Recognition"},{"paperId":"c211b4d8045d8ee7a1759856456131ca5f909479","title":"Predicting medical specialty from text based on a domain-specific pre-trained BERT"},{"paperId":"35499f7b1aa579b1c19a0363d53a5d06184e642c","title":"Joint model of biomedical entity recognition and normalization labels based on self-attention"},{"paperId":"5451f57c50fcdf05cb1ded2e55a6e92916e30448","title":"Detection of ADR on Covid Vaccine Safety Data"},{"paperId":"fd1e917dabadd533dba35bf73f91c808c1571404","title":"Enhanced neurologic concept recognition using a named entity recognition model based on transformers"},{"paperId":"97148858b395c5122e09d6e8a20dd7016a111aa3","title":"Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning"},{"paperId":"86c79317afa13ea4a74f656e3c48f012ee1fc326","title":"G-MAP: General Memory-Augmented Pre-trained Language Model for Domain Tasks"},{"paperId":"6d3e935ece8bf076e69e61b132a5c135fc809853","title":"Information extraction using deep learning: study of patient populations identification in texts describing drug approvals. (Preprint)"},{"paperId":"9ec324658f0499463ec1d67cd7f8a7ecfbc3fa76","title":"Natural language processing: using artificial intelligence to understand human language in orthopedics"},{"paperId":"53d127af5c25320e14cb71a8c506bce51c2a0c60","title":"Truthful Meta-Explanations for Local Interpretability of Machine Learning Models"},{"paperId":"61a09494fd097e1875e0a20ee96498d851304f47","title":"Optimization of Biomedical Language Model with Optuna and a Sentencepiece Tokenization for NER"},{"paperId":"f6e6daacc9ff7d79cd92be9dd14d8088e10cc774","title":"BioNER-CFEM: Biomedical Named Entity Recognition Based on Character Feature Enhancement with Multimodal Method"},{"paperId":"4f85cf06753035f58248384d3244bc2a89b32220","title":"CySecBERT: A Domain-Adapted Language Model for the Cybersecurity Domain"},{"paperId":"67e9ba61a35ffed87dc0d00f447102ab516af375","title":"Automated Identification of Eviction Status from Electronic Health Record Notes"},{"paperId":"f209c75506e9c39935118ce6d7259b6994f12e67","title":"BioELM: Integrating Biomedical Knowledge into Language Model with Entity-Linking"},{"paperId":"afa9b832cd699553854417e471aa291871fdf17f","title":"GCL-GO: A novel sequence-based hierarchy-aware method for protein function prediction"},{"paperId":"9526b7689b396a5b2f2a9fdc1a588477a2632b74","title":"S3 AAL: Support Set Selection based on Adversarial Active Learning for Medical Few-Shot Relation Extraction"},{"paperId":"a2964dfd9a84ceaf42046f274469bf9e9f47d1d3","title":"Efficient Gene Community Search to Discover Similar Aspects for Similarity Explanation"},{"paperId":"6bfb462d225a1b2cee0bf76128402f3345847959","title":"Multimodal feature learning framework for disease biomarker discovery"},{"paperId":"83ab85a756f37fbf7a667b5ade9cc9f435e31a93","title":"Semantic Reasoning with NLI for Assertion Detection in Medical Text"},{"paperId":"19914cc2b2b3efd3ee460ae3c35ed23e7f4482a3","title":"DEAL: Construction of a Disease-aware Human Cell Knowledge Graph from Biomedicine Literature"},{"paperId":"84652a23a9fd4b5020f3d67cf9cd0495709ea415","title":"Unified Fine-Grained Biomedical Entity Recognition as a Combination of Boundary Detection and Sequence Generation"},{"paperId":"4086fc2bc4b7966698e31c0d5ddc19f31b4702c4","title":"REACTCLASS: Cross-Modal Supervision for Subword-Guided Reactant Entity Classification"},{"paperId":"1ce47d91cfd5c071fe438bd41133ab4e58a7d37a","title":"Attention model-based and multi-organism driven gene recognition from text: application to a microbial biofilm organism set."},{"paperId":"daaeccc4567ef569a80b08c0b71abb0682422fc2","title":"Joint Extraction of Biomedical Entities and Relations based on Decomposition and Recombination Strategy"},{"paperId":"9e9c2af21d8e9b78db089190888a3cc95e10f266","title":"Extraction of Gene Regulatory Relation Using BioBERT"},{"paperId":"59dbe7d94d5f205b314b85339089939e5c5d4239","title":"Semi-Supervised Protein-Protein Interactions Extraction Method Based on Knowledge Distillation and Virtual Adversarial Training"},{"paperId":"e95e56263e919a2183d4ca62e3868f47f31bcac4","title":"Syntactic Type-aware Graph Attention Network for Drug-drug Interactions and their Adverse Effects Extraction"},{"paperId":"da4ca8bd29d1adfe82e50771c0d7b69ec4446a00","title":"Drug-Drug Interaction Extraction Using Drug Knowledge Graph"},{"paperId":"5c9515ee1c01b5b3e8403dd6483eecd5ea0c2827","title":"Intent Recognition in Conversational Recommender Systems"},{"paperId":"26619860c4a83ebfdb3748e29ffbd90745a6a851","title":"DeepCausality: A general AI-powered causal inference framework for free text: A case study of LiverTox"},{"paperId":"414e5e8199233764b69ea77ff53471a4d0ee85a7","title":"Multi-View Brain Network Analysis with Cross-View Missing Network Generation"},{"paperId":"b246d524606b2bc6fb8e9093f45c9614f293156e","title":"Discovering Social Determinants of Health from Case Reports using Natural Language Processing: Algorithmic Development and Validation"},{"paperId":"0136f2faaa902082d0e6ad15e5fd14f5842d2b14","title":"Relation-aware Language-Graph Transformer for Question Answering"},{"paperId":"de4bf50f234074fda2c504cc79af273b23297fcc","title":"A Lightweight CNN and Class Weight Balancing on Chest X-ray Images for COVID-19 Detection"},{"paperId":"934f03956a5092345ea941df915d79358ddd2581","title":"CLeBPI: Contrastive Learning for Bug Priority Inference"},{"paperId":"2532e493ebb926b38fe628aa681f97b7339c42d9","title":"Extract antibody and antigen names from biomedical literature"},{"paperId":"d9ea78cce9dafd95aea422341a05b4d1d50730df","title":"Using Twitter Data Analysis to Understand the Perceptions, Awareness, and Barriers to the Wide Use of Pre-Exposure Prophylaxis in the United States"},{"paperId":"7bb12aa7eebceef1ff4053d98e5bc2a17d46dd6e","title":"CliMedBERT: A Pre-trained Language Model for Climate and Health-related Text"},{"paperId":"955e2a788f0a9ddb7c3f971f9e830159bcf1c8e6","title":"Research on Classification Method of Bank Statement in Low Resource and Cross-domain Scenarios"},{"paperId":"4363427eba0051f1cfe69ad060a863ce5546fb29","title":"Chinese Clinical Named Entity Recognition from Electronic Medical Records based on Multi-semantic Features by using RoBERTa-wwm and CNN: Model Development and Validation (Preprint)"},{"paperId":"1ec63e1c726b2bfbfb2f3786a6b1dfca945ba1e2","title":"Joint Extraction of Entity Relations Based on Dependency Syntax and BERT in Medical Domain"},{"paperId":"befdd8ac38a8b52aa306c0f85566267a002b43d9","title":"Predicting Clinical Events via Graph Neural Networks"},{"paperId":"6a78ddf1c05f29f267e5cfd5dffe5d7f791192b9","title":"AAEBERT: Debiasing BERT-based Hate Speech Detection Models via Adversarial Learning"},{"paperId":"acef23274e8216ad0af515e911a8579d0243a3c4","title":"The Use of Pretrained Model for Matching App Reviews and Bug Reports"},{"paperId":"40fe011402ff452b0b134d8c5179ef52db986f33","title":"Clinical Application of Detecting COVID-19 Risks: A Natural Language Processing Approach"},{"paperId":"5b4e106fe657cba6ab8122cb1b098f002b6568b3","title":"Automated Detection of Substance-Use Status and Related Information from Clinical Text"},{"paperId":"7b15616d95d42c60245e2f23b68e249558ffdded","title":"Predicting drug characteristics using biomedical text embedding"},{"paperId":"c7b6c685b9694bec19ea96467fe4376ab62ae9ed","title":"CultureBERT: Fine-Tuning Transformer-Based Language Models for Corporate Culture"},{"paperId":"08ab9ba37d7fc63bb4a0969688028052ec4716c2","title":"Biomedical NER for the Enterprise with Distillated BERN2 and the Kazu Framework"},{"paperId":"a95cdf4670685a9e31bba505db9e20d3926f23ac","title":"Named entity recognition of Chinese electronic medical records based on a hybrid neural network and medical MC-BERT"},{"paperId":"06adfb6a76b7c69b678d0b81c5f3087939652102","title":"Enhancements to Language Modeling Techniques for Adaptable Log Message Classification"},{"paperId":"7009fd9eb533df6882644a1c8e1019dc034b9cc5","title":"DCA-IoMT: Knowledge-Graph-Embedding-Enhanced Deep Collaborative Alert Recommendation Against COVID-19"},{"paperId":"d14d821aa72a9fd938cbc478ab5e3bf9f2835ae9","title":"AIONER: All-in-one scheme-based biomedical named entity recognition using deep learning"},{"paperId":"7821e7639ffaeea175422f35fae2eb1c095ed1a6","title":"Protein Language Models and Structure Prediction: Connection and Progression"},{"paperId":"0885ecb3dae0fe12d7bb3af6fa5157e0a71ab549","title":"A Transformer-Based Model Trained on Large Scale Claims Data for Prediction of Severe COVID-19 Disease Progression"},{"paperId":"eb2f1c096e4b27182bb7d987e946eceb5aa57c54","title":"The New Version of the ANDDigest Tool with Improved AI-Based Short Names Recognition"},{"paperId":"90e5769a13099c4c7e887c6f729a7775ce5cd569","title":"An Automatic SOAP Classification System Using Weakly Supervision And Transfer Learning"},{"paperId":"405e7d7f24b4f6755aa56930655448425ee60e12","title":"LitCovid ensemble learning for COVID-19 multi-label classification"},{"paperId":"1f5d70da740a2c68cf066ad150312b2642ae72c1","title":"Biomedical Text NER Tagging Tool with Web Interface for Generating BERT-Based Fine-Tuning Dataset"},{"paperId":"0ef3a45e65f625b2cd46671d8118f75403471bc4","title":"Tracking biomedical articles along the translational continuum: a measure based on biomedical knowledge representation"},{"paperId":"768403710ec37fe612257384b19bf8f1c7bcce72","title":"Formative assessment strategies for students' conceptions—The potential of learning analytics"},{"paperId":"16ffa80289ca0e7d747ddae1ecdca58c64216180","title":"BioByGANS: biomedical named entity recognition by fusing contextual and syntactic features through graph attention network in node classification framework"},{"paperId":"5f98a78b1e17a594d4c9178d8610a053884a2203","title":"Evaluating the Knowledge Dependency of Questions"},{"paperId":"b9289edf2f2a5a9ba9cc3bb17a8d51fee67f4640","title":"CBEAF-Adapting: Enhanced Continual Pretraining for Building Chinese Biomedical Language Model"},{"paperId":"f304466f545f58137f317846530a2d2b65dc432e","title":"Leveraging Users' Social Network Embeddings for Fake News Detection on Twitter"},{"paperId":"ff859b26e94b0545365d6cc759dff632e788e2ae","title":"Context Variance Evaluation of Pretrained Language Models for Prompt-based Biomedical Knowledge Probing"},{"paperId":"1eb72ef89e6b7722e114e195f68cd45c86e6f344","title":"The next-generation Open Targets Platform: reimagined, redesigned, rebuilt"},{"paperId":"dd07778ce114225e13307c05ee94eb97d445d884","title":"Explainable Personality Prediction Using Answers to Open-Ended Interview Questions"},{"paperId":"f1af525155e4737fd8e43e45ed60a9fa0e6f03f6","title":"Notes on the data quality of bibliographic records from the MEDLINE database"},{"paperId":"9455ace3e18bd8659c0ae8e661813ecc5f002394","title":"BERT-based Topic Modeling Approach for Malaria Research Publication"},{"paperId":"7ae089060ecb7ac2788e94ee7e04a3eb7009f6b4","title":"CDialog: A Multi-turn Covid-19 Conversation Dataset for Entity-Aware Dialog Generation"},{"paperId":"683f73dcd2b78ce0710e17b4e6316762bd169c93","title":"Lesion Guided Explainable Few Weak-Shot Medical Report Generation"},{"paperId":"d641bfcea49dc072fe471b433b0f6b0f414947b4","title":"An Automatic ICD Coding Network Using Partition-Based Label Attention"},{"paperId":"491c65555afa2125b88191d7c81fadc4daf4c31b","title":"A correlation-based feature analysis of physical examination indicators can help predict the overall underlying health status using machine learning"},{"paperId":"c8957181e3905ac8eafacce99c7396571f09ce0c","title":"Few-Shot Learning for Clinical Natural Language Processing Using Siamese Neural Networks (Preprint)"},{"paperId":"e787c56679064c19c97af82d8b4bb7b09e179868","title":"Relation Extraction from Texts Containing Pharmacologically Significant Information on base of Multilingual Language Models"},{"paperId":"f9ddbee4289bd536f7f2101c038b8d0d87fb2b83","title":"The STRING database in 2023: protein–protein association networks and functional enrichment analyses for any sequenced genome of interest"},{"paperId":"d7837d577fc6821d095dffb559cfdc0e3574166f","title":"Hardness-guided domain adaptation to recognise biomedical named entities under low-resource scenarios"},{"paperId":"4f9adb83bac0ee0458ee6f784c32e488efbec37c","title":"When BERT Started Traveling: TourBERT—A Natural Language Processing Model for the Travel Industry"},{"paperId":"b4b37f87e0357f2e4cec70af67b2f088f6efce70","title":"A Survey of Knowledge-Enhanced Pre-trained Language Models"},{"paperId":"cfddcdc764ccf38a3cb48becd560356535425a4a","title":"Message from General Chair"},{"paperId":"c9d90133c08a92d3d99cddee5d107933cf241367","title":"FormLM: Recommending Creation Ideas for Online Forms by Modelling Semantic and Structural Information"},{"paperId":"0c007e000eaf59e86788b45b70879612cde2e8ee","title":"Biomedical Multi-hop Question Answering Using Knowledge Graph Embeddings and Language Models"},{"paperId":"e3a3d3199f8516f818fd8afe51235432ec104974","title":"Combining Contrastive Learning and Knowledge Graph Embeddings to develop medical word embeddings for the Italian language"},{"paperId":"e5f5a058c26b87dc94b8b0c35e9395bac578969c","title":"Information extraction from electronic medical documents: state of the art and future research directions"},{"paperId":"ca77a3559a718c5d2b17dc109d585744f7b7fb43","title":"Fine-Tuning BERT for Question and Answering Using PubMed Abstract Dataset"},{"paperId":"2d919381510fdc25dfebbfbf2cf3592257328e61","title":"MedBERT: A Pre-trained Language Model for Biomedical Named Entity Recognition"},{"paperId":"7618861e5ad468aa1fb9da7b7f23fac13b03efe9","title":"AD-BERT: Using Pre-trained contextualized embeddings to Predict the Progression from Mild Cognitive Impairment to Alzheimer's Disease"},{"paperId":"3fab990fb6b0efb67e3f6f39fe7eb65f95d4a111","title":"Community-in-the-loop: Creating Artificial Process Intelligence for Co-production of City Service"},{"paperId":"cf8234789a528b855da6dd9c13e54539f1a6deff","title":"Next-Day Medical Activities Recommendation Model with Double Attention Mechanism Using Generative Adversarial Network"},{"paperId":"f602784b5f46750cce1ca1e4c13b0f28a5e20d2b","title":"Assisted neuroscience knowledge extraction via machine learning applied to neural reconstruction metadata on NeuroMorpho.Org"},{"paperId":"c4c33de2fbbe01f611ed79fb058d657405db95bd","title":"ViMRT: a text-mining tool and search engine for automated virus mutation recognition"},{"paperId":"5d239bb9d64ba63ff1390342706300f67ea7e8f2","title":"ConBERT: A Concatenation of Bidirectional Transformers for Standardization of Operative Reports from Electronic Medical Records"},{"paperId":"bf5c307aa7c4bdb912408ffd831553f0ae86ffe7","title":"On the Domain Adaptation and Generalization of Pretrained Language Models: A Survey"},{"paperId":"4ac21503eddebfee77351d2072b3884f24d43807","title":"Identification and Visualization of Key Topics in Scientific Publications with Transformer-Based Language Models and Document Clustering Methods"},{"paperId":"542e09e66dc7c9863e85e6b18765c1f737d028c4","title":"Forecasting User Interests Through Topic Tag Predictions in Online Health Communities"},{"paperId":"2689c5246c33050df35f5b68dc15e68e69fb1099","title":"Federated Multilingual Models for Medical Transcript Analysis"},{"paperId":"28980fd125402febec34913ed9540a70e55888c2","title":"BERT for Long Documents: A Case Study of Automated ICD Coding"},{"paperId":"1d150032f50d65770cd7fc4ddb8e76fba4cea257","title":"BERT-Deep CNN: State-of-the-Art for Sentiment Analysis of COVID-19 Tweets"},{"paperId":"5bbb755529323897d33b9e4073385d2148f63bf1","title":"A Comparison of SVM against Pre-trained Language Models (PLMs) for Text Classification Tasks"},{"paperId":"9272a06ea006171f34d29d46319230438fd531a7","title":"Late Fusion with Triplet Margin Objective for Multimodal Ideology Prediction and Analysis"},{"paperId":"7be18eba71211a16cd4d068cdee2575efab91271","title":"Biomedical named entity recognition with the combined feature attention and fully-shared multi-task learning"},{"paperId":"10f3cf6dc50f9d52a313481f103daf959d567479","title":"Cross-stitching Text and Knowledge Graph Encoders for Distantly Supervised Relation Extraction"},{"paperId":"9d7774f5188c270e2dd4aab512e616509d3a41a3","title":"Improved Fine-Tuning of In-Domain Transformer Model for Inferring COVID-19 Presence in Multi-Institutional Radiology Reports"},{"paperId":"265afb13b7d235a0315a445ae901ca6db62d7fd3","title":"CCS Explorer: Relevance Prediction, Extractive Summarization, and Named Entity Recognition from Clinical Cohort Studies"},{"paperId":"008cb42964fbdc5ccee79ef7b981b4ee105fb361","title":"Entity Level QA Pairs Dataset for Sentiment Analysis"},{"paperId":"b7830b246c3f60a35b0bc2b2ab53d017a4e54abd","title":"MTBC-BioNER: Multi-task Learning Using BioBERT and CharCNN for Biomedical Named Entity Recognition"},{"paperId":"9a14a7882e66f683b40eb62d784b8c2418633600","title":"DCPC: Drug Candidates for the Prevention of COVID-19 Database"},{"paperId":"bc257b38b54b783ffb65b9b6c802d54351621c15","title":"Biomedical named entity normalization via interaction-based synonym marginalization"},{"paperId":"f4a8f86ce62995eccf4db80d37cd4e7952960452","title":"The Role of Natural Language Processing during the COVID-19 Pandemic: Health Applications, Opportunities, and Challenges"},{"paperId":"91ee912db3ecc8cfcbafbc2fe4ca468b25ef41a4","title":"Transferring knowledge between topics in systematic reviews"},{"paperId":"6b37985840ff40bd75fa70854a01852ff245bbc4","title":"Training a Deep Contextualized Language Model for International Classification of Diseases, 10th Revision Classification via Federated Learning: Model Development and Validation Study"},{"paperId":"b6afdf1e125618db066a535cb978aec4d262e809","title":"An accessible, efficient, and accurate natural language processing method for extracting diagnostic data from pathology reports"},{"paperId":"743066ef8253f293c635b56aa856d2c474c261a6","title":"Global meta-analysis of evolution patterns for lake topics over centurial scale: A natural language understanding-based deep clustering approach with 130,000 studies"},{"paperId":"7e0fda71cc2e561385c0a2e29f5a81654a11157f","title":"VarMAE: Pre-training of Variational Masked Autoencoder for Domain-adaptive Language Understanding"},{"paperId":"ef63635d87d77f388451cdc88175917624b1c00e","title":"Named entity recognition of building construction defect information from text with linguistic noise"},{"paperId":"0882a2b2787b35dbcc6e341c953d964b77abd4df","title":"When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain"},{"paperId":"803261d13ab134f0e3ce45f265e1d36d1ead32ef","title":"Improving Cause-of-Death Classification from Verbal Autopsy Reports"},{"paperId":"8a2376750af3212cf22be81ddd7c650bb0eedf28","title":"IAnimal: a cross-species omics knowledgebase for animals"},{"paperId":"316467770bc41a872cccfadd516cef8a79139398","title":"Civil Data Mining using Machine Learning"},{"paperId":"fbb73c93a8cbd87bdbc52deb988b8831e45b6fc2","title":"Named Entity Recognition of Protein Complex Incorporating Syntactic Information"},{"paperId":"a138041f6fa2e4ea850afddbfde9945fe4ed11f4","title":"Biomedical Entity Linking Based on Global and Local Feature Fusion"},{"paperId":"42da00c23a2c641728f090c06db5986da66ce511","title":"We are not ready yet: limitations of state-of-the-art disease named entity recognizers"},{"paperId":"bc5d28eca4fc686fe21dd0a37e138dc618fdec77","title":"Towards Language-centric Scientiﬁc AI"},{"paperId":"2cea77f07e47dd10dd4b2aa21f786b6465a93859","title":"Towards Language-driven Scientific AI"},{"paperId":"90b82c46173b5fe18cbd12371177e2281de6d647","title":"Leveraging knowledge graphs to update scientific word embeddings using latent semantic imputation"},{"paperId":"73b222c2808a95878c8a3aa762b9ba1d4dd9ecd4","title":"Parameter-Efficient Legal Domain Adaptation"},{"paperId":"b32f967c0a5777a5045d4fd59f2cda9be68dc3bb","title":"PALT: Parameter-Lite Transfer of Language Models for Knowledge Graph Completion"},{"paperId":"810e7ff45d5cdb2318f88a2787a37b2fadd9bf82","title":"Legal-Tech Open Diaries: Lesson learned on how to develop and deploy light-weight models in the era of humongous Language Models"},{"paperId":"984dd8bd2d37ed5d8f56e72f941293977429badf","title":"Enhancing Label Consistency on Document-level Named Entity Recognition"},{"paperId":"ff8f3dfd9e2f4a92310999722abefab202935521","title":"Do Language Models Understand Measurements?"},{"paperId":"c6c8a77c47b5e54527390cba6d1c2a86dfd1d4c9","title":"On Cross-Domain Pre-Trained Language Models for Clinical Text Mining: How Do They Perform on Data-Constrained Fine-Tuning?"},{"paperId":"1b2f6cacaa7305df32b8c70ef5c0ecd4db69a825","title":"PHEE: A Dataset for Pharmacovigilance Event Extraction from Text"},{"paperId":"8dd9ba9af32b05152d944b24bf9e04fdeedbcb5f","title":"GLAF: Global-and-Local Attention Flow Model for Question Answering"},{"paperId":"a2a478b91f6e00b3fcda018384121097f435e5e0","title":"MixUp based Cross-Consistency Training for Named Entity Recognition"},{"paperId":"8a5837b9245035972f97d6796f62790b6e7e9d71","title":"SpaBERT: A Pretrained Language Model from Geographic Data for Geo-Entity Representation"},{"paperId":"033ce949ded20600b7a770fda78853eb48c5ce89","title":"BioLORD: Learning Ontological Representations from Definitions (for Biomedical Concepts and their Textual Descriptions)"},{"paperId":"504d1d9b6ecdeaadb79ad8ba80fa64ac34fca18e","title":"Evidence > Intuition: Transferability Estimation for Encoder Selection"},{"paperId":"c9b21d0a1244ad554ebb5e05d9a7c0ec38ccb94c","title":"SmarTxT: A Natural Language Processing Approach for Efficient Vehicle Defect Investigation"},{"paperId":"774255e00ac21e1d6a9ac530a6789c026808fd96","title":"An automatic hypothesis generation for plausible linkage between xanthium and diabetes"},{"paperId":"130204d04c6a427480a4df889b7aa4aca9ffa18d","title":"Miko Team: Deep Learning Approach for Legal Question Answering in ALQAC 2022"},{"paperId":"4b4fc9d41e40fdccc294c0074c545e4dafce743f","title":"MedGraph: A semantic biomedical information retrieval framework using knowledge graph embedding for PubMed"},{"paperId":"145fb51975ec4ca72708bf354713f568a7541358","title":"Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study"},{"paperId":"d9270a1d97319d0b01728e7a137dde2157f1e57d","title":"Type-supervised sequence labeling based on the heterogeneous star graph for named entity recognition"},{"paperId":"b1109fb06413cdc07d2b1134f3f49e4510174e44","title":"Using Bottleneck Adapters to Identify Cancer in Clinical Notes under Low-Resource Constraints"},{"paperId":"6e391835815b88990da5d130a123c339c59b9457","title":"Extracting Drug-drug Interactions from Biomedical Texts using Knowledge Graph Embeddings and Multi-focal Loss"},{"paperId":"21c71ab196f5139c2a26ff0c7ed5f30c3e099723","title":"Named Entity-based Question-Answering Pair Generator"},{"paperId":"792c5e004430e88da5f3b013a1fda0091ec8b59c","title":"Drug Adverse Event Detection Using Text-Based Convolutional Neural Networks (TextCNN) Technique"},{"paperId":"0ae8428cde7369ba3628e571742648fb753b0cc2","title":"Comprehensive study of pre-trained language models: detecting humor in news headlines"},{"paperId":"ad3dfb2514cb0c899fcb9a14d229ff2a6018892f","title":"Deep Bidirectional Language-Knowledge Graph Pretraining"},{"paperId":"5cf75ca9549ba58f4d4c90ed8053a89b917f5fb9","title":"BidH: A Bidirectional Hierarchical Model for Nested Named Entity Recognition"},{"paperId":"bb16531b2b4f3833a068f0745475dff971032e56","title":"Improving Healthcare Question Answering System by Identifying Suitable Answers"},{"paperId":"8525f80d1ff2f3cd20c147b6665c6947d46a5080","title":"This Patient Looks Like That Patient: Prototypical Networks for Interpretable Diagnosis Prediction from Clinical Text"},{"paperId":"26c761a06fc1bf07345ccb2f5b1121926da8870b","title":"Handling missing values in healthcare data: A systematic review of deep learning-based imputation techniques"},{"paperId":"f9d01f8ab34bb707afdee382350f7ce23534c2d9","title":"AraLegal-BERT: A pretrained language model for Arabic Legal text"},{"paperId":"8bfff360bf6b46959a58aaa82d49142a13243312","title":"Improving Radiology Summarization with Radiograph and Anatomy Prompts"},{"paperId":"d465a28d8b68f4eb3133cdfa5dc209711f767fcc","title":"Automatic Creation of Named Entity Recognition Datasets by Querying Phrase Representations"},{"paperId":"1e2a5dca6f310241dd8a9b56873edf8ca211c781","title":"Enriching Biomedical Knowledge for Low-resource Language Through Translation"},{"paperId":"0eb074e0504d1062b36a7ced6efec8048e68ac1f","title":"Exploration of biomedical knowledge for recurrent glioblastoma using natural language processing deep learning models"},{"paperId":"7c71c6d3e03c098a9f7d4dcc56d9e0abfa05314a","title":"Natural language processing (NLP) aided qualitative method in health research"},{"paperId":"38e995753f222ba7d198d6d54033058de84a77f1","title":"MedJEx: A Medical Jargon Extraction Model with Wiki’s Hyperlink Span and Contextualized Masked Language Model Score"},{"paperId":"d7104dab8e5379f9566108857e3bd9dc832286df","title":"Developing a general-purpose clinical language inference model from a large corpus of clinical notes"},{"paperId":"2185ee209832acfcb7b30a0e4fcec0aa8e5095dc","title":"Opinion analysis and aspect understanding during covid-19 pandemic using BERT-Bi-LSTM ensemble method"},{"paperId":"640ae44e26587915fa9920705d726d44cc5f98b2","title":"MiniALBERT: Model Distillation via Parameter-Efficient Recursive Transformers"},{"paperId":"0979695b5d74016e97ab8f306f632114e98bd6d9","title":"Task Compass: Scaling Multi-task Pre-training with Task Prefix"},{"paperId":"50f268f24f257bbc27c7faf9037a5b5dc76a59ab","title":"RedHOT: A Corpus of Annotated Medical Questions, Experiences, and Claims on Social Media"},{"paperId":"54772ffae642a87b9a6122a6f1bae76b926a7230","title":"Enriching Biomedical Knowledge for Low-resource Language Through Large-Scale Translation"},{"paperId":"8e5c2f0e7eb5b9977219e3c810941ee7ecc1ba04","title":"Adapting without forgetting: KnowBert-UMLS"},{"paperId":"a0d7be46514e5340fec6a5c9368a7bd755af0a55","title":"An\n expert‐in‐the‐loop\n method for\n domain‐specific\n document categorization based on small training data"},{"paperId":"6ae700c89a9a9a3da7e55dd51c4710b5ed8c8d4e","title":"Caption-Aware Medical VQA via Semantic Focusing and Progressive Cross-Modality Comprehension"},{"paperId":"8a8b774077bd0be706988e5d7c45133f20b26251","title":"Systematic Evaluation of Common Natural Language Processing Techniques to Codify Clinical Notes"},{"paperId":"391c313f2db33a7a6069b0d95d59f8b818f9ff6b","title":"Spread Love Not Hate: Undermining the Importance of Hateful Pre-training for Hate Speech Detection"},{"paperId":"940d32e2f5ac604393e8a9ef9195f53e00fc20ad","title":"Short Text Pre-training with Extended Token Classification for E-commerce Query Understanding"},{"paperId":"87fdfcc68e06489266fd01f0bc24a1f9bc0a235d","title":"KG-MTT-BERT: Knowledge Graph Enhanced BERT for Multi-Type Medical Text Classification"},{"paperId":"5d0acc2f780ca2012a1c9689cc8d1475799003b7","title":"Named Entity Recognition in Twitter: A Dataset and Analysis on Short-Term Temporal Shifts"},{"paperId":"055fe58ea72df3fa296f2f0f3ad3abacafb84204","title":"GMA3D: Local-Global Attention Learning to Estimate Occluded Motions of Scene Flow"},{"paperId":"dbab937db91b9ccdb39c2840257305b16b93ce8e","title":"In silico prediction methods of self-interacting proteins: an empirical and academic survey"},{"paperId":"3d78f898dbf363371bdf28aaa1ed86e2972502a2","title":"Token Classification for Disambiguating Medical Abbreviations"},{"paperId":"9da92d387cbc09c9b68e30a52ff472a83f4283d0","title":"Critical assessment of transformer-based AI models for German clinical notes"},{"paperId":"bd195095e921ab4d62cec12f37754f2e59883546","title":"Understanding Prior Bias and Choice Paralysis in Transformer-based Language Representation Models through Four Experimental Probes"},{"paperId":"450946ff0120a3ce3b6842f104524796414115a8","title":"Medical Intention Recognition Based on MCBERT-TextCNN Model"},{"paperId":"9247c814900ed79690ba6832828470dfe60a639a","title":"Text Summarization towards Scientific Information Extraction"},{"paperId":"d6e2603227542bfe4a2bcc4551c3dbc0b2329f57","title":"Deep contextual multi-task feature fusion for enhanced concept, negation and speculation detection from clinical notes"},{"paperId":"a087c7f90597e826d94cd341f990db80e24a90eb","title":"BioKnowPrompt: Incorporating Imprecise Knowledge into Prompt-tuning Verbalizer with Biomedical Text for Relation Extraction"},{"paperId":"826430735643c4334bbf0a0920c6093f51ac7eaa","title":"Semisupervised neural biomedical sense disambiguation approach for aspect-based sentiment analysis on social networks"},{"paperId":"45e77e0d4bfe98119c24b073146298ed22b167cf","title":"PubMed Author-assigned Keyword Extraction (PubMedAKE) Benchmark"},{"paperId":"5458e62da091f0911a0a209207863c0833853e7b","title":"RadioBERT: A deep learning-based system for medical report generation from chest X-ray images using contextual embeddings"},{"paperId":"ce5aa326cdae5958bf112859dd4ea34e684b9a72","title":"An automatic descriptors recognizer customized for materials science literature"},{"paperId":"21fe96d98f730834b147e14248d09f857cf969d5","title":"Self-Distillation for Further Pre-training of Transformers"},{"paperId":"54a5e1698d9def60c1d205bd1e78a92954a704f1","title":"NLP-based classification of software tools for metagenomics sequencing data analysis into EDAM semantic annotation"},{"paperId":"5d8fd04c436367b18b35e28332ee8e452a477f3f","title":"Medical Image Understanding with Pretrained Vision Language Models: A Comprehensive Study"},{"paperId":"88e3f5b9081bafffbde86c3fb4a2ae26ccd22ff2","title":"A Survey on Computational Methods for Investigation on ncRNA-Disease Association through the Mode of Action Perspective"},{"paperId":"861e1b6989bba8c503b5cf209eaf8923f474703a","title":"YATO: Yet Another deep learning based Text analysis Open toolkit"},{"paperId":"b0a643b1ae1aad63defe25a713162dd5b0e69c89","title":"Full-text chemical identification with improved generalizability and tagging consistency"},{"paperId":"168db75f79cd2d39a7802451578662bb15572de4","title":"Improving Radiology Report Generation Systems by Removing Hallucinated References to Non-existent Priors"},{"paperId":"4c46df96d67bcca0fd98aaa9940f8d834f7213c4","title":"MediCoSpace: Visual Decision-Support for Doctor-Patient Consultations using Medical Concept Spaces from EHRs"},{"paperId":"44279244407a64431810f982be6d0c7da4429dd7","title":"BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining"},{"paperId":"c0de2e91459f6e3519d8a4839bff19bc73a9c5e0","title":"Large-scale application of named entity recognition to biomedicine and epidemiology"},{"paperId":"e23c5bf7362988624ec67bd4fe405b71e8b5c0ad","title":"Variational Open-Domain Question Answering"},{"paperId":"3ed8168abced540feab67398712e102afdb39a80","title":"Training and intrinsic evaluation of lightweight word embeddings for the clinical domain in Spanish"},{"paperId":"0b21174036879d92c2770a156fa8aa6fd6749c79","title":"Generalizing through Forgetting - Domain Generalization for Symptom Event Extraction in Clinical Notes"},{"paperId":"4fc4a4d66f29998e88750afbbf4839b9ac9ac98c","title":"Disease prediction based on multi-type data fusion from Chinese electronic health record."},{"paperId":"173153d5567553f3477ff815dd53a713177cf672","title":"Mapping Climate Change Research via Open Repositories & AI: advantages and limitations for an evidence-based R&D policy-making"},{"paperId":"a3e757fc4ef3fb929f9de43cd4558d3fa75a540c","title":"Automated MeSH Term Suggestion for Effective Query Formulation in Systematic Reviews Literature Search"},{"paperId":"fabbbcf627e4efbf7eb56647c340df1e72a6da67","title":"What Went Wrong: A Survey of Wildfire UAS Mishaps through Named Entity Recognition"},{"paperId":"e92392b73da56b226f1e71e495724c46f776a370","title":"De-Identification of French Unstructured Clinical Notes for Machine Learning Tasks"},{"paperId":"274dbb98c63cdd282eb86b0338bdc3c5dfd9b904","title":"Dataset Inference for Self-Supervised Models"},{"paperId":"7d0abebf379383afbf9b7b3f8ab89561d1aa7596","title":"MaterialBERT for natural language processing of materials science texts"},{"paperId":"2cd7bd19c9c2868a88e4c80c0c4f3cf0dd63900a","title":"Examining Large Pre-Trained Language Models for Machine Translation: What You Don’t Know about It"},{"paperId":"ac5225708efd250d217424ba27885e90f186160d","title":"Prompt Combines Paraphrase: Teaching Pre-trained Models to Understand Rare Biomedical Words"},{"paperId":"daf55a55661a6d41f3bf0a543f4c277d4c01d83e","title":"Toward Improving Health Literacy in Patient Education Materials with Neural Machine Translation Models"},{"paperId":"6ab6e6f62323132e299fc6717ad0f5ca000414d5","title":"Natural language processing in clinical neuroscience and psychiatry: A review"},{"paperId":"6d90b33d0b63111b28f5c8053da7737e7d8e871f","title":"Pre-training Transformers on Indian Legal Text"},{"paperId":"f0e0806003ee509f1f4feeabf209a8e93dddf5d2","title":"A revised application of cognitive presence automatic classifiers for MOOCs: a new set of indicators revealed?"},{"paperId":"1c7a4e8d9f4fcf19a5d1caa078c66ca39cb75dd2","title":"A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language"},{"paperId":"ca2afde4470180dbcfaa27e7a5cd3c7679569771","title":"Large-scale Evaluation of Transformer-based Article Encoders on the Task of Citation Recommendation"},{"paperId":"ca6b7c8b8389c495d53584d777d638e3307cfbca","title":"Challenges and opportunities in current vaccine technology and administration: A comprehensive survey examining oral vaccine potential in the United States"},{"paperId":"45c9883d51cda85ed44502fa174bd42f6315d36b","title":"Background knowledge in ontology matching: A survey"},{"paperId":"ab7706c845ce30e1f865a67259fac7e351474d01","title":"Transforming Drug-Drug Interaction Extraction from Biomedical Literature"},{"paperId":"88dd119dba5ee747851ade8f5d517b381614d918","title":"Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence"},{"paperId":"228c4b30bef0a85e6cd3e633293323bb559c978a","title":"A BERT-based model for coupled biological strategies in biomimetic design"},{"paperId":"d36c0b5f67bce9afccc8bdd8b68fafa8097d9dee","title":"OneEE: A One-Stage Framework for Fast Overlapping and Nested Event Extraction"},{"paperId":"bf6d47795c67cc47fc208736b87ccf49d36d0bca","title":"BertSRC: transformer-based semantic relation classification"},{"paperId":"78f4129e3c33beab4f7e4a17848828e897d4069f","title":"To Explore the Molecular Mechanism of Acupuncture Alleviating Inflammation and Treating Obesity Based on Text Mining"},{"paperId":"9370f880b6ca91754793cb7b076237043c0a73f3","title":"Query-focused Extractive Summarisation for Biomedical and COVID-19 Complex Question Answering (preprint)"},{"paperId":"83d2d9f6a315ece46fde7cb2ad5a6fec2ec36d49","title":"Named Entity Recognition System for the Biomedical Domain"},{"paperId":"c05a9797e5ead09d0885efa9f1b464d319f80709","title":"Drug-Drug Interaction Extraction from Biomedical Text using Relation BioBERT with BLSTM"},{"paperId":"ead20e9d7b48b5e48465c8aa5d3a79223b02d8e0","title":"A multi-head adjacent attention-based pyramid layered model for nested named entity recognition"},{"paperId":"0f0e147cf0356ac1c81cc710e59e309f46c5ee61","title":"Natural Language Processing in Nephrology."},{"paperId":"0f6fbddef30c530b82de3d7d3f247c69ecec47d4","title":"MolRoPE-BERT: An enhanced molecular representation with Rotary Position Embedding for molecular property prediction."},{"paperId":"cf4c627c0dc53d1524726b939887bf3b439d2b13","title":"Neural architectures for aggregating sequence labels from multiple annotators"},{"paperId":"3061e490a1f9727175c7851f73de7c40d5f06216","title":"Gaze-assisted automatic captioning of fetal ultrasound videos using three-way multi-modal deep neural networks"},{"paperId":"9cd4fc0517ea310cc85504f35857a74aedff65bb","title":"Leveraging weak supervision to perform named entity recognition in electronic health records progress notes to identify the ophthalmology exam"},{"paperId":"1190a62c5b4376f08c7461816d7466d41cf5f622","title":"Heterogeneous deep graph convolutional network with citation relational BERT for COVID-19 inline citation recommendation"},{"paperId":"23702f6f1fa80b5dcc0fed7e94157e9d52d151bb","title":"A Cross‐Domain Ontology Semantic Representation Based on NCBI‐BlueBERT Embedding"},{"paperId":"0eb5b4292319a8be4b1508acd874d3fdc569b8c0","title":"Extracting drug-drug interactions from no-blinding texts using key semantic sentences and GHM loss"},{"paperId":"9d795925e30ab8a70c4cf66f314ea5435c9b426c","title":"Automated extraction of information of lung cancer staging from unstructured reports of PET-CT interpretation: natural language processing with deep-learning"},{"paperId":"4c86ffcc12bf728706152ba8a36181374cccfd1e","title":"Attack Tactic Identification by Transfer Learning of Language Model"},{"paperId":"1b46e078b7303b0972599c514fa4b2a0fae7e7ff","title":"Few-Shot Learning for Clinical Natural Language Processing Using Siamese Neural Networks"},{"paperId":"6e59edb734194abef65a0404e425dbd823a4f07f","title":"Optimizing Bi-Encoder for Named Entity Recognition via Contrastive Learning"},{"paperId":"a076508f77cbfd5da45a73d34f31c5af8104970d","title":"A Deep Learning-Based Privacy-Preserving Model for Smart Healthcare in Internet of Medical Things Using Fog Computing"},{"paperId":"73d39a6ce4726b038f13b62307bc3cf4ef95776f","title":"No means ‘No’: a non-improper modeling approach, with embedded speculative context"},{"paperId":"6a9602743366fab44e9fccddc5a4d02068c379ad","title":"Development and Validation of a Deep Learning Model for Predicting Treatment Response in Patients With Newly Diagnosed Epilepsy."},{"paperId":"969ae2aef666cafb1c4eed2707d6206caacfd88e","title":"Supporting Medical Relation Extraction via Causality-Pruned Semantic Dependency Forest"},{"paperId":"0230c06c771bb6411614d685432ef076927e66f4","title":"Extracting Biomedical Factual Knowledge Using Pretrained Language Model and Electronic Health Record Context"},{"paperId":"9d2ad340318c2adda7ce68789678a012e4436986","title":"Application of Deep Learning in Generating Structured Radiology Reports: A Transformer-Based Technique"},{"paperId":"4ecbab28398acee9a5ddef3593f07338771152be","title":"Text mining of CHO bioprocess bibliome: Topic modeling and document classification"},{"paperId":"458fe4d368576278294fc80e55a60f2dbd1c4cb8","title":"Holistic Approach for Artificial Intelligence Implementation in Pharmaceutical Products Lifecycle: A Meta-Analysis"},{"paperId":"ba14f67834ae93f0ab67d4c7acdf89afc84ab248","title":"#ChronicPain: Automatic establishment of a chronic pain cohort from social media using machine learning for studying opioid-alternative therapies"},{"paperId":"bb4f0b15b69d15b0c1616a32191c03f8294c3082","title":"Research on Medical Text Classification based on BioBERT-GRU-Attention"},{"paperId":"0175659d3da0c56753fac44ab646af76ce7220ff","title":"Enriching Pre-Trained Language Model with Multi-Task Learning and Context for Medical Concept Normalization"},{"paperId":"a36e9583a0212c11020eefa1d9574512ad9964a4","title":"A pre-trained BERT for Korean medical natural language processing"},{"paperId":"381910542941f93fd59f1aac29384d6f711a35b7","title":"Entity Anchored ICD Coding"},{"paperId":"7c206d541552a57b4c0cfe5b5113d3cc8e31df01","title":"IMSE: interaction information attention and molecular structure based drug drug interaction extraction"},{"paperId":"d132e80f80ce0a65733f57464354b989a8209929","title":"Chemical named entity recognition in the texts of scientific publications using the naïve Bayes classifier approach"},{"paperId":"8ef7b433bb78a5a47595c0c756054d01459e2248","title":"Improving medical experts’ efficiency of misinformation detection: an exploratory study"},{"paperId":"c75b1fb2348c0f54259319b3595ececaf1d98430","title":"Medical terminology-based computing system: a lightweight post-processing solution for out-of-vocabulary multi-word terms"},{"paperId":"be6277ac11b91d7970f8b4f064bfe2b02270ec45","title":"A machine learning framework for discovery and enrichment of metagenomics metadata from open access publications"},{"paperId":"f3d7789c627d3e62d92c225a272e408f287c6317","title":"Non-Contrastive Self-Supervised Learning of Utterance-Level Speech Representations"},{"paperId":"7504aeee4c344c4cf9c6fc071dcc4b4b34d124cc","title":"Non-Contrastive Self-Supervised Learning for Utterance-Level Information Extraction From Speech"},{"paperId":"3ca54ef2f36ea81439a98692a9f61de17b0f1bed","title":"A Multimodal Transformer: Fusing Clinical Notes with Structured EHR Data for Interpretable In-Hospital Mortality Prediction"},{"paperId":"43a7b2a3a0259bdbf9ace5954f23c697d69d5b86","title":"An Embarrassingly Easy but Strong Baseline for Nested Named Entity Recognition"},{"paperId":"53510eb719df9e79b2e5bfad8b7af84d2abc202d","title":"Biomedical Named Entity Recognition Using Transformers with biLSTM + CRF and Graph Convolutional Neural Networks"},{"paperId":"f1653d36f223becc395cb726c55886bdaa27ece7","title":"Semantic taxonomy enrichment to improve business text classification for dynamic environments"},{"paperId":"3fb69a33340c1968f2ca1b3cf5d30fe1d370e532","title":"Applications of natural language processing in ophthalmology: present and future"},{"paperId":"69c791a3ec196f0b046758581c472507482469cd","title":"Introducing Improved Transformer to Land Cover Classification Using Multispectral LiDAR Point Clouds"},{"paperId":"10a69d0b1ebdf04fa079a4245609f21a245806dd","title":"ArcheGEO"},{"paperId":"c2aae385224b907ae141fe1d7d52f3a6097e970b","title":"ArcheGEO: towards improving relevance of gene expression omnibus search results"},{"paperId":"4b454d73088451200192b34ecaacd80006806eb5","title":"An Italian lexicon-based sentiment analysis approach for medical applications"},{"paperId":"032496954f7d221b5d2b0ded8f0c9b628fc49ade","title":"Using natural language processing on free-text clinical notes to identify patients with long-term COVID effects"},{"paperId":"f7b0bc71bc810440152f412371796bf7a52ee340","title":"Multi-label classification of symptom terms from free-text bilingual adverse drug reaction reports using natural language processing"},{"paperId":"12d04565528d51c3d841aea1fe16b59dc7455ecd","title":"Using language models and ontology topology to perform semantic mapping of traits between biomedical datasets"},{"paperId":"2bb16e81db12bd36242531b97387ac9a8f58f593","title":"DeepProphet2 - A Deep Learning Gene Recommendation Engine"},{"paperId":"07c72a83bbc51c30316751d2997c1080360102de","title":"Identification of bacteriophage genome sequences with representation learning"},{"paperId":"378831c67fe5f79d91fe3421ac37c044704a80ae","title":"Retraining a BERT Model for Transfer Learning in Requirements Engineering: A Preliminary Study"},{"paperId":"e962e3acf17529002ad1aa95c38499a2667f13ae","title":"YTLR: Extracting yeast transcription factor-gene associations from the literature using automated literature readers"},{"paperId":"2b2cf91d12f0928a8d1c37e3f95a2c20d194e3f8","title":"Year 2021: COVID-19, Information Extraction and BERTization among the Hottest Topics in Medical Natural Language Processing"},{"paperId":"0fae17f1cf72963694ff3f06065f7ebd12b6565d","title":"Domain Model Extraction from User-authored Scenarios and Word Embeddings"},{"paperId":"8919a186c717e7298798ac838daa49ea1654a79f","title":"How do Patent Claims Reflect Scientific Knowledge : Insights from Human Genomics"},{"paperId":"67b684626ba5ff1d54003dad7e0871be8275ed67","title":"Beyond word embeddings: A survey"},{"paperId":"c98b20c695f921451b8953fd74e748dc803febc4","title":"Natural Language Processing in Pathology: Current Trends and Future Insights"},{"paperId":"e3820a16e3c242a0fb30c389da873edf9136ae91","title":"NeuroCORD: A Language Model to Facilitate COVID-19-Associated Neurological Disorder Studies"},{"paperId":"889a23cfc57dbef77d921fdc6a5240201ac7edcb","title":"DrNote: An open medical annotation service"},{"paperId":"0e1033d886d32ea37ed82ef08bb84a294c5da828","title":"On modeling and utilizing chemical compound information with deep learning technologies: A task-oriented approach"},{"paperId":"041e3960ba823d8370cddf4fda6704de185259b4","title":"Development and Validation of Machine Models Using Natural Language Processing to Classify Substances Involved in Overdose Deaths"},{"paperId":"59e95b0a0a13ef5ac321b7e7de2c86e6dafaddf2","title":"Accurately Identifying Cerebroarterial Stenosis from Angiography Reports Using Natural Language Processing Approaches"},{"paperId":"19f39313208d15c318a219664de78dd3cee52f2b","title":"AsthmaKGxE: An asthma-environment interaction knowledge graph leveraging public databases and scientific literature"},{"paperId":"34f91cc1696071a7dab8e141b2c8a6cf62e88a19","title":"A multi-layer soft lattice based model for Chinese clinical named entity recognition"},{"paperId":"69767adf5b48e7c1f570b34af31d0f3c50e91ff1","title":"Automatic text classification of actionable radiology reports of tinnitus patients using bidirectional encoder representations from transformer (BERT) and in-domain pre-training (IDPT)"},{"paperId":"6b610232f4ae3a7cc764599b8bfb71c45629b0df","title":"Using Multi-modal Data for Improving Generalizability and Explainability of Disease Classification in Radiology"},{"paperId":"6e9636f1195770a187e40213cd028885c2f913c6","title":"Prediction of biomarker-disease associations based on graph attention network and text representation"},{"paperId":"b6fce90925c977ab1f98f4db9487596c9595f97b","title":"Learning structures of the French clinical language: development and validation of word embedding models using 21 million clinical reports from electronic health records"},{"paperId":"65b492af374605ebf62484e06a62bc14a128e868","title":"ChanFAD: A Functional Annotation Database for Ion Channels"},{"paperId":"1c9664b78ed9ea461f8e68ea2637383c4acb4e4d","title":"Utilizing Deep Learning for Detecting Adverse Drug Events in Structured and Unstructured Regulatory Drug Data Sets"},{"paperId":"b18619ca04606f532dd5b08bbce1682174a5ad59","title":"Assessing mortality prediction through different representation models based on concepts extracted from clinical notes"},{"paperId":"06ea568379211ffa07d9605f66f26f6f736ea5e0","title":"PanGu-Coder: Program Synthesis with Function-Level Language Modeling"},{"paperId":"ca3d845ee518365ca73a3f7a7143c2a1875591a7","title":"Multi-Level Fine-Tuning, Data Augmentation, and Few-Shot Learning for Specialized Cyber Threat Intelligence"},{"paperId":"cb60fd88468ee02465ea81d3af73e5c9de79a7ae","title":"Matching Biomedical Ontologies via a Hybrid Graph Attention Network"},{"paperId":"c962afecd74910dc607f64eecfe33cc474126da1","title":"Enhancing Cross-lingual Biomedical Concept Normalization Using Deep Neural Network Pretrained Language Models"},{"paperId":"b311dbc8e8869c040a3866bb1844870b1b009a37","title":"Automatic question answering for multiple stakeholders, the epidemic question answering dataset"},{"paperId":"2ac3bacbbee520b701707ebcf7b9ca7a3f233129","title":"Medical visual question answering via corresponding feature fusion combined with semantic attention."},{"paperId":"e85f6948e7906ec974134ec443f26064d9fe3d95","title":"Transforming unstructured digital clinical notes for improved health literacy"},{"paperId":"e6b4f085a1e9f1c0c6ea37d89f6bb683526d60d5","title":"3Rs: Data Augmentation Techniques Using Document Contexts For Low-Resource Chinese Named Entity Recognition"},{"paperId":"e5fd2317c0ac51ecf947d0f40ab715a78a0fe052","title":"Multilingual Transformer Encoders: a Word-Level Task-Agnostic Evaluation"},{"paperId":"df0554828bb4056b488e2a7164c024cd9dc96974","title":"An Annotated PubMed Corpus to Support Supervised Relation Extraction between Suicide-Related Entities and Drugs (Preprint)"},{"paperId":"124804b9ab1fcae6ca114902d828216de6c83a06","title":"Bi-PointFlowNet: Bidirectional Learning for Point Cloud Based Scene Flow Estimation"},{"paperId":"9153fa1e824c556118b29f3d85658dda20c7c083","title":"PLM-ICD: Automatic ICD Coding with Pretrained Language Models"},{"paperId":"7060dd75f55c97c88cffe3d4973fea03ccb00b4d","title":"OSLAT: Open Set Label Attention Transformer for Medical Entity Span Extraction"},{"paperId":"e9b06dfbad49a1c573af09a8a6e430a008f973cc","title":"Analyzing Transfer Learning of Vision Transformers for Interpreting Chest Radiography"},{"paperId":"889030bdb7e96d0abfb7c00d5c084d8b46c5671e","title":"Study of Question Answering on Legal Software Document using BERT based models"},{"paperId":"22f4412f9fa0bcd2fabb72f2a7ef81ccc82f566b","title":"Developing an NLP-based Recommender System for the Ethical, Legal, and Social Implications of Synthetic Biology"},{"paperId":"d0b3c35f736391d68a193a4c3dbf1724697dcef7","title":"Natural language processing for clusterization of genes according to their functions"},{"paperId":"3f3a62d754add66350cb71319927de4714a252e6","title":"Win-Win Cooperation: Bundling Sequence and Span Models for Named Entity Recognition"},{"paperId":"31727aa453b1b83f0639e7c6bead508b40abb5d6","title":"Interpreting Patient Descriptions using Distantly Supervised Similar Case Retrieval"},{"paperId":"38c1a356684d4f7f5c579898fad257b7f102ea99","title":"Knowledge Graph and Deep Learning-based Text-to-GraphQL Model for Intelligent Medical Consultation Chatbot"},{"paperId":"6cf8a4d05e66266233380f989edaf647eba7e1a5","title":"BioTABQA: Instruction Learning for Biomedical Table Question Answering"},{"paperId":"36aae858e5c57aaeb46ee484e86b0b5a738f3caf","title":"Do We Need a Specific Corpus and Multiple High-Performance GPUs for Training the BERT Model? An Experiment on COVID-19 Dataset"},{"paperId":"7b19b0b4e5e6278ea9475cb97c52ebcc209f7f50","title":"State-of-the-Art Evidence Retriever for Precision Medicine: Algorithm Development and Validation"},{"paperId":"3ac52f3e6f185ef61bd35b74ae8a5c2bde4d1997","title":"Shifting machine learning for healthcare from development to deployment and from models to data"},{"paperId":"d49e46606348b131d8352d40005337ab7d9c6872","title":"Learning Feature Recovery Transformer for Occluded Person Re-Identification"},{"paperId":"85eaaa985b184e7e0fd4f3eb2138e1cf20107434","title":"Enhancing Automated Software Traceability by Transfer Learning from Open-World Data"},{"paperId":"8f248b5476666e700390f7f8ff6ca923f97d726c","title":"Advancing protein language models with linguistics: a roadmap for improved interpretability"},{"paperId":"6a154672fa2efe952137208e0242d27da3136692","title":"A Biomedical Pipeline to Detect Clinical and Non-Clinical Named Entities"},{"paperId":"3e0f229c677cec20a4e5c31d99b5dd628a97b60b","title":"A comparative study on deep learning models for text classification of unstructured medical notes with various levels of class imbalance"},{"paperId":"e520b7cdbfd2e9548ddd0ada2fc686816e33da24","title":"Classifying the lifestyle status for Alzheimer’s disease from clinical notes using deep learning with weak supervision"},{"paperId":"f4fcafa3b415ff023f3ab45fbb986bd33dac4f18","title":"AgriBERT: Knowledge-Infused Agricultural Language Models for Matching Food and Nutrition"},{"paperId":"8d834506eced6f7e8aaadbbf5bf111309fd9c2b2","title":"Similarity Measures Based on Multi-knowledge Integration"},{"paperId":"fc0a33256909b0d9c76288d1978d52453580c1d4","title":"MinpakuBERT: A Language Model for Understanding Cultural Properties in Museum"},{"paperId":"c47bc7d845f707933f240c85e88a6f3dac19842b","title":"Analyzing the Structure of U.S. Patents Using Patent Families"},{"paperId":"e680e6e5ce5c886cc84b1ef7d0757154d9937212","title":"Deep learning to extract Breast Cancer diagnosis concepts"},{"paperId":"572f6be261fcc457a45bc2ece174347fbb4a94b1","title":"A Drug Repositioning Approach Using Drug and Disease Features"},{"paperId":"3d7584711440c9fe879675977d37be565b090ad6","title":"A Comprehensive and Holistic Health Database"},{"paperId":"bb15f7c8c01635a42c27ab1f2f842f9b6b2b43d4","title":"Multiview Incomplete Knowledge Graph Integration with application to cross-institutional EHR data harmonization"},{"paperId":"ae4acc595d460358c0ee44afc4483f2d9c5cb766","title":"Pre-trained language models with domain knowledge for biomedical extractive summarization"},{"paperId":"14d38a8f1fc61b243eb8cbe6f415074000c1b15c","title":"Natural Language Processing in Diagnostic Texts from Nephropathology"},{"paperId":"f1d8dbe4e217d2221c5276f1e0c616ba5f82d1d3","title":"A review on Natural Language Processing Models for COVID-19 research"},{"paperId":"582b051cdf46525803299e63a1c7b09dad409c3c","title":"Call for papers: Semantics-enabled biomedical literature analytics"},{"paperId":"7677aa43ea685ff396a9194b98a42c3f299d69f6","title":"Enhancing Entity Representations with Prompt Learning for Biomedical Entity Linking"},{"paperId":"3f3487f7918ccccc5c9b5a9f6fb449a3b7f4deac","title":"BERT-Promoter: An improved sequence-based predictor of DNA promoter using BERT pre-trained model and SHAP feature selection"},{"paperId":"c796b23df835d9b7a1d01094c67dac2be034e7e9","title":"A Syntax-enhanced model based on category keywords for biomedical relation extraction"},{"paperId":"6015a06afa659fa496a2a5f1301ec38d4b8da868","title":"Visual and buying sequence features-based product image recommendation using optimization based deep residual network."},{"paperId":"c8cb3098b753f0472ede12af9b582e091ecfea5c","title":"NILINKER: Attention-based approach to NIL Entity Linking"},{"paperId":"795e78f020b4922f1648d488ecc03b9a0ea726ac","title":"Multi-attention deep neural network fusing character and word embedding for clinical and biomedical concept extraction"},{"paperId":"d614607eef5ea32811023da07b3731e4396348f3","title":"Improving Low-Resource Speech Recognition with Pretrained Speech Models: Continued Pretraining vs. Semi-Supervised Training"},{"paperId":"ee44e1ffe88d64fbf3a9451e47d5b23b50e71772","title":"Gated tree-structured RecurNN for Detecting Biomedical Event Trigger"},{"paperId":"216cb67823c5dc727871cb846a438e91f5a8cb5b","title":"MULTICLASS CLASSIFICATION OF SCIENTIFIC TEXTS WRITTEN IN TURKISH BY APPLYING DEEP LEARNING TECHNIQUE"},{"paperId":"ee9f79f0f652011f7df2548b8fca62cb5c48ba66","title":"Trial2Vec: Zero-Shot Clinical Trial Document Similarity Search using Self-Supervision"},{"paperId":"a32be54b31a91036eaaadf6e39d62108508710fa","title":"Multi-probe attention neural network for COVID-19 semantic indexing"},{"paperId":"0af095ab3f45a665699162a3656b1603bc359e68","title":"GERNERMED++: Transfer Learning in German Medical NLP"},{"paperId":"096748b7210afca47587f4845e67680da858ba6a","title":"Note: Using Causality to Mine Sjögren’s Syndrome related Factors from Medical Literature"},{"paperId":"e015e07c76ff85f624b78112fd58937221f5ea0c","title":"Clinical-BERT: Vision-Language Pre-training for Radiograph Diagnosis and Reports Generation"},{"paperId":"c76779e705b005cb87241f490fb0957baafb7005","title":"Enhancing medical-imaging artificial intelligence through holistic use of time-tested key imaging and clinical parameters: Future insights"},{"paperId":"acb5ba438e005f407fd24aa6bb4bf5e3c67c8ea1","title":"Contextual embedding and model weighting by fusing domain knowledge on biomedical question answering"},{"paperId":"0787cee29a1a3c592f7c20ec5bc67ceffaf452bb","title":"Analyzing Twitter Conversations on Side Effects of Covid-19 Vaccine"},{"paperId":"e9480d62e216f77d5556b7eda769daa4c92d004d","title":"VQAMix: Conditional Triplet Mixup for Medical Visual Question Answering"},{"paperId":"3f0ff7887c6d922c4310dd8c92de4f07fa2612ae","title":"TabText: a Systematic Approach to Aggregate Knowledge Across Tabular Data Structures"},{"paperId":"b6856133bfebe68e26b06ff469a6c65278e3d1aa","title":"Fine-tuned Sentiment Analysis of COVID-19 Vaccine–Related Social Media Data: Comparative Study"},{"paperId":"b52e681c39d31e6abf58ad1f5d9709e2dce12e1f","title":"Automatic data extraction to support meta-analysis statistical analysis: a case study on breast cancer"},{"paperId":"905e1376e26cfcb3f9c8abe3f7c970caee952938","title":"Network approaches for modeling the effect of drugs and diseases"},{"paperId":"55976ee561064f301fcfce26356a6da9e062494c","title":"An Accuracy-Maximization Approach for Claims Classifiers in Document Content Analytics for Cybersecurity"},{"paperId":"48078f2561917a8c64fee24e86185eba796a7ce9","title":"RadBERT: Adapting Transformer-based Language Models to Radiology."},{"paperId":"eab6381a34c128abb5246348898d4c6df45c8fa6","title":"Theoretical Perspectives on Terminology"},{"paperId":"94cc16a0d283fb7bc98cf4e6b152687587b63558","title":"Task Transfer and Domain Adaptation for Zero-Shot Question Answering"},{"paperId":"62f488d3178ce448c9916caf131b83d22ff5d5ff","title":"Comparison of text preprocessing methods"},{"paperId":"be7aa2416c28d25bdbcd7666b02131a55ca869c0","title":"Knowledge Graph Construction and Its Application in Automatic Radiology Report Generation from Radiologist's Dictation"},{"paperId":"b4354536b8259c147301cdc4468aa8fa67432437","title":"How can natural language processing help model informed drug development?: a review"},{"paperId":"27bf606c781a3db61099427a393ae3bab950b629","title":"Graph-in-Graph Network for Automatic Gene Ontology Description Generation"},{"paperId":"f37efd3d94f1bffc28951e073b27f4be06505de0","title":"PreQR: Pre-training Representation for SQL Understanding"},{"paperId":"04a90a79bdfe2f9d54811141c104a4c12f74c07a","title":"SsciBERT: a pre-trained language model for social science texts"},{"paperId":"306519f049fe470a2380326f7d52f813b0723be2","title":"Iterative Annotation of Biomedical NER Corpora with Deep Neural Networks and Knowledge Bases"},{"paperId":"ff998672ac14ced3e53fb658c237f0b610a85229","title":"Discovering Content through Text Mining for a Synthetic Biology Knowledge System."},{"paperId":"1eeb28e450772ee0ab0adcd60056480faf99d150","title":"Training Subset Selection for Weak Supervision"},{"paperId":"fb5855e68b029f1391bea0cc4d8b1ca1e7335bb2","title":"BERT Models for Arabic Text Classification: A Systematic Review"},{"paperId":"f695e38bdef6dbd2bdcf80faa6359c0e7918d729","title":"Taxonomy of machine learning paradigms: A data‐centric perspective"},{"paperId":"421b8fc8c0058cefede7f4bf5421494aee235b21","title":"Combining Attention-based Models with the MeSH Ontology for Semantic Textual Similarity in Clinical Notes"},{"paperId":"102c3436913d659a5c34518a916f2078a1fad7db","title":"Developing Pretrained Language Models for Turkish Biomedical Domain"},{"paperId":"848852ef5953643b6524e1ee1b73905ab74fa4de","title":"Improving Sentence Classification in Abstracts of Randomized Controlled Trial using Prompt Learning"},{"paperId":"fa73acfcaa2e7eb08623f129420c716048baf4bf","title":"Graph-Augmented Cyclic Learning Framework for Similarity Estimation of Medical Clinical Notes"},{"paperId":"8c9a9a1bbba2a3e3bab34bce533b3b2acfda32b0","title":"Medical visual question answering based on question-type reasoning and semantic space constraint"},{"paperId":"6f3e7b7b6fffd08ee7cb63aaaf5777b232f4bd02","title":"Historical profile will tell? A deep learning-based multi-level embedding framework for adverse drug event detection and extraction"},{"paperId":"0f055c1fbcb0942c1d6d75fdf1452110db4cf210","title":"Automatic International Classification of Diseases Coding System: Deep Contextualized Language Model With Rule-Based Approaches"},{"paperId":"8971ac20865868c18bcba441ed0a37a33d6b02a4","title":"A Decade's Experience in Pediatric Chromosomal Microarray Reveals Distinct Characteristics Across Ordering Specialties."},{"paperId":"6b866e2516ad95b5db30ba2eb2e31d0589f70eb2","title":"Discovering novel drug-supplement interactions using SuppKG generated from the biomedical literature"},{"paperId":"5a0cb34032209fed9c18e538c25f5d6515584248","title":"Accelerated variant curation from scientific literature using biomedical text mining"},{"paperId":"b07bfd5cac5d2f35f2a97d29ed1270183ed125a6","title":"Geoscience language models and their intrinsic evaluation"},{"paperId":"fd5921e058932d406a39cc83c59958d277cefd06","title":"Multilabel classification of medical concepts for patient clinical profile identification"},{"paperId":"3e03e8cf0fd49ebfd7947fcf3e9cd4dd058e4676","title":"SeSG: a search string generator for Secondary Studies with hybrid search strategies using text mining"},{"paperId":"e3c429d5a2703b0ac2608c0a2f7bf5b6bdf5ae94","title":"Fast medical concept normalization for biomedical literature based on stack and index optimized self-attention"},{"paperId":"7d8b4c9bd3938868b815e79ea8d9af946615ee96","title":"Multi-model Comparison for Classification of Medical Records using the BioBERT Models"},{"paperId":"00cfcae8a594b23ef33b458e34b9b82452d0e2cc","title":"Sparse Conditional Hidden Markov Model for Weakly Supervised Named Entity Recognition"},{"paperId":"f6f51bedd048139dd70b98c80fe47f0077b9bffb","title":"Clinical Dialogue Transcription Error Correction using Seq2Seq Models"},{"paperId":"6fa3ce7831ab75ee784428ae8e3a0b7372651e48","title":"Plant phenotype relationship corpus for biomedical relationships between plants and phenotypes"},{"paperId":"d2088bae6252939f82900e6eb40720f090cc9f47","title":"Sparse*BERT: Sparse Models are Robust"},{"paperId":"f7b96c7075ffb4551a1d79a57d055c4ab4a2b2b2","title":"Sparse*BERT: Sparse Models Generalize To New tasks and Domains"},{"paperId":"686d9ee744fa013cc21cdd86acd864c936e9e456","title":"Large language models are few-shot clinical information extractors"},{"paperId":"e35c16ef1b097efe321f3d57768d72007f911af8","title":"Natural Language Processing for Information Extraction of Gastric Diseases and Its Application in Large-Scale Clinical Research"},{"paperId":"24ecf000f9a2ea678eb29a6a720f36ad91a305c5","title":"K-12BERT: BERT for K-12 education"},{"paperId":"f420c9cf9aac2d3f0e0b358af89c29eafb42849a","title":"Development of a phenotype ontology for autism spectrum disorder by natural language processing on electronic health records"},{"paperId":"6cb77f85207c680ac442275138d2458a8505256b","title":"ScholarBERT: Bigger is Not Always Better"},{"paperId":"e257f213cbe37f78375ad4f25566840b5cfa04b7","title":"Artificial intelligence for topic modelling in Hindu philosophy: Mapping themes between the Upanishads and the Bhagavad Gita"},{"paperId":"4962ce1242ff905b71e199964eafea3d2ad9688d","title":"A Domain-adaptive Pre-training Approach for Language Bias Detection in News"},{"paperId":"2b3b2d8849aacfa66724f92bdf3ef7f567d94a51","title":"Discovering trends and hotspots of biosafety and biosecurity research via machine learning"},{"paperId":"99be6dc17a7fd399f4af80c4c1cd7ee5247591a1","title":"Pre-training Data Quality and Quantity for a Low-Resource Language: New Corpus and BERT Models for Maltese"},{"paperId":"74db6506ee770b25ed1f940aa9d9e2a8058d0590","title":"Identification and Impact Analysis of Family History of Psychiatric Disorder in Mood Disorder Patients With Pretrained Language Model"},{"paperId":"b3bc37a15aa74c523d656ad89b1896651f5eef72","title":"Continual Pre-Training Mitigates Forgetting in Language and Vision"},{"paperId":"088cd170f3067de026fe2665782f639e64c6f8ad","title":"A reproducible experimental survey on biomedical sentence similarity: A string-based method sets the state of the art"},{"paperId":"ce14126ffb0999cec9137b5565f4069eacaa4127","title":"A Scalable Workflow to Build Machine Learning Classifiers with Clinician-in-the-Loop to Identify Patients in Specific Diseases"},{"paperId":"6f0a840579e80067bf774468654d45fe7abf9630","title":"Past and future uses of text mining in ecology and evolution"},{"paperId":"a1d5476c1bface0b20e6e943c3f36868186375be","title":"Generic and Trend-aware Curriculum Learning for Relation Extraction"},{"paperId":"55db77c96e57e692f5bbee3083e00720b438fa71","title":"PTM4Tag"},{"paperId":"80c732ae7adf7eb222e51fbd3ed2cb3b5a8037c5","title":"Automatically Identifying Twitter Users for Interventions to Support Dementia Family Caregivers: Annotated Data Set and Benchmark Classification Models"},{"paperId":"77cb1ca1485f88f4061570dc999524da339863af","title":"Hero-Gang Neural Model For Named Entity Recognition"},{"paperId":"468bfd9971b9712d2538e7825723925dd2f2dbbd","title":"neoMS: Attention-based Prediction of MHC-I Epitope Presentation"},{"paperId":"8e8110cc601eb35f9f2e33528981a3fbd7528ffb","title":"PathologyBERT - Pre-trained Vs. A New Transformer Language Model for Pathology Domain"},{"paperId":"6ee0a4bc4241b71610337e552f1dbf632791a4da","title":"Building Better Machine Learning Models for Rhetorical Analyses: The Use of Rhetorical Feature Sets for Training Artificial Neural Network Models"},{"paperId":"e86eb6ee7daa5e6aa46f1538c6fc503ef9cb688d","title":"The Case of Aspect in Sentiment Analysis: Seeking Attention or Co-Dependency?"},{"paperId":"a1a1c3f60f8b8adca96edbb1fa9b2b77bc1b17b5","title":"ScAN: Suicide Attempt and Ideation Events Dataset"},{"paperId":"3dc771a2f49cf8bfa30a0076ed99b8b6aca9eec9","title":"Automated medical chart review for breast cancer outcomes research: a novel natural language processing extraction system"},{"paperId":"1b4d785f4f57f1dae5445c7192dd3663bb0c48c3","title":"Multi-domain adaptation for named entity recognition with multi-aspect relevance learning"},{"paperId":"fa7e728c4c612025b9fb7601af65c4a8f5a2b33e","title":"Clinical Prompt Learning with Frozen Language Models"},{"paperId":"c51950111fc29ac83be64a5e220d93b202dc07ef","title":"Construction of an Assisted Model Based on Natural Language Processing for Automatic Early Diagnosis of Autoimmune Encephalitis"},{"paperId":"e75fac9090ac82b75c841ffa8fd468dcb7e7eb4b","title":"Biomedical Relation Extraction With Knowledge Graph-Based Recommendations"},{"paperId":"6eee5bee8b5b058547f2af164fa54179ece046ba","title":"pubmedKB: an interactive web server for exploring biomedical entity relations in the biomedical literature"},{"paperId":"c794a26766cceb4e0c373af0d01d9d129b316cf2","title":"SuMe: A Dataset Towards Summarizing Biomedical Mechanisms"},{"paperId":"89d9b122bcd7ddf4bca0ac8c92f94ab4a730c19f","title":"Natural Language Processing of Radiology Reports to Detect Complications of Ischemic Stroke"},{"paperId":"5476911896491f32ca123e7030e9bae1116d8de2","title":"BatteryBERT: A Pretrained Language Model for Battery Database Enhancement"},{"paperId":"5cc58bcfb9bf39d4114eab88fca36eb0ce36afd9","title":"Building a knowledge graph to enable precision medicine"},{"paperId":"a3b7f8bc5bfec9542f946faa03428b0d1e82efa0","title":"AKI-BERT: a Pre-trained Clinical Language Model for Early Prediction of Acute Kidney Injury"},{"paperId":"d061d5e1f8135a1819b1e260cb1efb97757cfc74","title":"Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds"},{"paperId":"9f37278355ae2820a08f4145e476d3499bfef693","title":"A Dataset for N-ary Relation Extraction of Drug Combinations"},{"paperId":"29b7ab3e305b9a57ae81d7f15596cd91a2e99139","title":"Mixed-effects transformers for hierarchical adaptation"},{"paperId":"9439aae01306f8c508b7af8626ea16a3f23024f7","title":"A Library Perspective on Nearly-Unsupervised Information Extraction Workflows in Digital Libraries"},{"paperId":"182e296d349662376d91f2b2ee1f05c5d577ea6e","title":"POLITICS: Pretraining with Same-story Article Comparison for Ideology Prediction and Stance Detection"},{"paperId":"7f369202dfbfc57ae89efccbc54b232cabefe66d","title":"A Novel Patient Similarity Network (PSN) Framework Based on Multi-Model Deep Learning for Precision Medicine"},{"paperId":"92bfb252dccfe950c08c00561d7d19e8cb9561ba","title":"Crude Oil-related Events Extraction and Processing: A Transfer Learning Approach"},{"paperId":"f7e8f369ae12bdcc76eaab4e42839fd36406abc0","title":"Semantics Driven Embedding Learning for Effective Entity Alignment"},{"paperId":"555a689b3771102c94fe0a9f40130bce443ca5d8","title":"Medical Coding with Biomedical Transformer Ensembles and Zero/Few-shot Learning"},{"paperId":"42a093d34ed6c233107dbf613681d3d7ec55ad5a","title":"Machine Learning Approach to Facilitate Knowledge Synthesis at the Intersection of Liver Cancer, Epidemiology, and Health Disparities Research"},{"paperId":"f2b41971a705a69b56279df5e928e4847c693c50","title":"A text mining framework for screening catalysts and critical process parameters from scientific literature - a study on Hydrogen production from alcohol"},{"paperId":"7fef58043d0a80af816447a0e440d59627af2ea6","title":"Evaluation of clinical named entity recognition methods for Serbian electronic health records"},{"paperId":"696b682e5bcfaddae4810392293acf591f930477","title":"Utilization of sentiment analysis to assess and compare negative finding reporting in veterinary and human literature."},{"paperId":"0120de89fbd45a2e3e2adf0f64d812afa2f5f130","title":"Scoping review and classification of deep learning in medical genetics."},{"paperId":"2c6ac205e11ecb522d990e4a257f907f738c2539","title":"Leveraging fusion of sequence tagging models for toxic spans detection"},{"paperId":"86dad974d555e8239d1ad3ca62978706e94d14ac","title":"Comparison of state-of-the-art machine and deep learning algorithms to classify proximal humeral fractures using radiology text."},{"paperId":"ee18ec08a0cdfd23e8cb85bb9c2421b88453e314","title":"Artificial Intelligence Based on Machine Learning in Pharmacovigilance: A Scoping Review"},{"paperId":"49bc72be5ee7085be32c753b8480a2f8d39b5c58","title":"A Deep Learning Approach to Estimate the Incidence of Infectious Disease Cases for Routinely Collected Ambulatory Records: The Example of Varicella-Zoster"},{"paperId":"ccf6a056efa73d83c7b120e2e4e3515e9fbd2543","title":"Discovering Thematically Coherent Biomedical Documents Using Contextualized Bidirectional Encoder Representations from Transformers-Based Clustering"},{"paperId":"7bb115c518eab1e3a421b7fa3823159455fadbb6","title":"Evaluating Biomedical Word Embeddings for Vocabulary Alignment at Scale in the UMLS Metathesaurus Using Siamese Networks"},{"paperId":"b2431ccff95909db6d40a266c4461bfc6d2d7ec1","title":"Artificial intelligence in COVID-19 evidence syntheses was underutilized, but impactful: a methodological study"},{"paperId":"45dfe98c74c3f65a4a0349ece03c6f12914a6217","title":"Named Entity Recognition for Pet Disease Q&A System"},{"paperId":"c378bbcc7d339809642ff7c2b202ea034c60cc11","title":"Knowledge integration and decision support for accelerated discovery of antibiotic resistance genes"},{"paperId":"87ce562e937dacc3f8a6efaab93f4f11fa0fda6a","title":"BPI-MVQA: a bi-branch model for medical visual question answering"},{"paperId":"1fafaccebc4a74898a74c606f846318c4c2c7536","title":"On the Effect of Pretraining Corpora on In-context Learning by a Large-scale Language Model"},{"paperId":"0d1aacf97cb67c6b4af9f7297f6affbdf559caa8","title":"UBERT: A Novel Language Model for Synonymy Prediction at Scale in the UMLS Metathesaurus"},{"paperId":"623fa1d6f3389fc081c43dacf2c16b43150b2989","title":"German Medical NER Model and Dataset Creation using Machine Translation and Word Alignment: Feasibility Study (Preprint)"},{"paperId":"3f200791d33165673740a3224a0afc5daf36f387","title":"Attention mechanism in neural networks: where it comes and where it goes"},{"paperId":"7433d1945c549040d3d06589185bbb2746f3bf76","title":"TimeBERT: Enhancing Pre-Trained Language Representations with Temporal Information"},{"paperId":"0b2a24ab36d9b30c2dc2472421ffa02a5a25b2a4","title":"SkillSpan: Hard and Soft Skill Extraction from English Job Postings"},{"paperId":"7e68adf6c97a6279a08831f563b5be46df1fe874","title":"Propose-and-Refine: A Two-Stage Set Prediction Network for Nested Named Entity Recognition"},{"paperId":"61843c4915c1cf633069b04e4628545cfffb5660","title":"BiTimeBERT: Extending Pre-Trained Language Representations with Bi-Temporal Information"},{"paperId":"c3637ae891321c0b97e90d9c526a55e603a77eb4","title":"HerbKG: Constructing a Herbal-Molecular Medicine Knowledge Graph Using a Two-Stage Framework Based on Deep Transfer Learning"},{"paperId":"513d947c064694ecb781d6b1cbe51dacee7bb379","title":"Machine learning approaches for electronic health records phenotyping: A methodical review"},{"paperId":"3842b66b82bd9b8e6a220c84ab15c026b404d767","title":"CoVERT: A Corpus of Fact-checked Biomedical COVID-19 Tweets"},{"paperId":"ee68b72ecef019adef17ae0cd375ab5d9659062d","title":"Using Machine Learning to Fuse Verbal Autopsy Narratives and Binary Features in the Analysis of Deaths from Hyperglycaemia"},{"paperId":"ee7a2e19af5f0497d305f31005dc14b549b7883c","title":"Unsupervised Representation Learning of Player Behavioral Data with Confidence Guided Masking"},{"paperId":"dc08b6ce4a6d922d550ae5d452590524dce82f41","title":"Detecting Regulation Violations for an Indian Regulatory Body through Multi Label Classification"},{"paperId":"43e29b34a41752ef83d838fce82120348fbff60c","title":"Exploring Representations for Singular and Multi-Concept Relations for Biomedical Named Entity Normalization"},{"paperId":"734bd6d02a4b4cd4f529381be6d8504582b1fee6","title":"Novel Artificial Intelligence Applications in Cardiology: Current Landscape, Limitations, and the Road to Real-World Applications"},{"paperId":"4fd46afb416a8a3bd24c664bd4e21c4c90fdd200","title":"Hierarchical Label-wise Attention Transformer Model for Explainable ICD Coding"},{"paperId":"6ae63be462816bdd0da32894985d16f1e8cbdd5c","title":"KALA: Knowledge-Augmented Language Model Adaptation"},{"paperId":"9727fa4acdc5312ff86745875ef3db8578f153ac","title":"Decorate the Examples: A Simple Method of Prompt Design for Biomedical Relation Extraction"},{"paperId":"18504ce364a5e7dc7c90a855e22b1635a62e8e72","title":"ICDBigBird: A Contextual Embedding Model for ICD Code Classification"},{"paperId":"5bfff0955b511ce4ecb906c67cbe323b60b5c6d3","title":"Towards an Enhanced Understanding of Bias in Pre-trained Neural Language Models: A Survey with Special Emphasis on Affective Bias"},{"paperId":"5b1fe75845271debc984c5e347b9d8fb486e28d3","title":"Leveraging Part-of-Speech Tagging Features and a Novel Regularization Strategy for Chinese Medical Named Entity Recognition"},{"paperId":"fba2b199350acea210cd7dc9dc1599f814e131fe","title":"An Attention-Based Model for Predicting Contextual Informativeness and Curriculum Learning Applications"},{"paperId":"d23fd0226c4355fc954aacfc7036d88b5d8a384e","title":"Recovering Patient Journeys: A Corpus of Biomedical Entities and Relations on Twitter (BEAR)"},{"paperId":"3b60fa113f9d448eb17d855173b24f30d105aed8","title":"Making the Most of Text Semantics to Improve Biomedical Vision-Language Processing"},{"paperId":"cf824130727f7a4b07657af71762e3205451bfc5","title":"LitMC-BERT: Transformer-Based Multi-Label Classification of Biomedical Literature With An Application on COVID-19 Literature Curation"},{"paperId":"cbccb1201eee6432020276762a44ebfbf8f981a0","title":"Unsupervised Numerical Reasoning to Extract Phenotypes from Clinical Text by Leveraging External Knowledge"},{"paperId":"73a6961fdf5202804a34a2a87425fc9e38919080","title":"A Multitask Deep Learning Framework for DNER"},{"paperId":"fb30166c218bef3597b0d9789ad340defc3989ca","title":"In-BoXBART: Get Instructions into Biomedical Multi-Task Learning"},{"paperId":"9377423732cf4cae109bd1a069eca1736ab0c84c","title":"Mixture of Experts for Biomedical Question Answering"},{"paperId":"30f9ec2c72bdbc92f34f52aa70aab340410e4006","title":"Multi-label topic classification for COVID-19 literature with Bioformer"},{"paperId":"670aebb676de8c23e42589c5414e37aefb6e4a6b","title":"State of the art: a review of sentiment analysis based on sequential transfer learning"},{"paperId":"13946197a704d6cdc3424dc2e95421ce549ca888","title":"EHRKit: A Python Natural Language Processing Toolkit for Electronic Health Record Texts"},{"paperId":"2eb0b5b9c1f03f0f945fd69949fbd623ce206cad","title":"Detection, Disambiguation, Re-ranking: Autoregressive Entity Linking as a Multi-Task Problem"},{"paperId":"2db2fb161750a77927e88ac0a657eb7b5fa7be63","title":"Doctor XAvIer: Explainable Diagnosis on Physician-Patient Dialogues and XAI Evaluation"},{"paperId":"b3011d40781412f3ad640e939b3ae88f1878ed25","title":"MedDistant19: Towards an Accurate Benchmark for Broad-Coverage Biomedical Relation Extraction"},{"paperId":"6058ce3819d72c3e429bea58d78d80c719cb4bdb","title":"Data Augmentation for Biomedical Factoid Question Answering"},{"paperId":"cd0372e0c55a41685aeb7bf42735657275771462","title":"Benchmarking for Public Health Surveillance tasks on Social Media with a Domain-Specific Pretrained Language Model"},{"paperId":"f5affa38941076c3c8db15fbaba487fb87421389","title":"BioRED: A Comprehensive Biomedical Relation Extraction Dataset"},{"paperId":"175dcaf0e3a8a6c702e13f1d1d656ff31484b66a","title":"BioRED: a rich biomedical relation extraction dataset"},{"paperId":"19ebb6a6674227278822a1688da8619d93a92cf3","title":"RuBioRoBERTa: a pre-trained biomedical language model for Russian language biomedical text mining"},{"paperId":"0db5207510819b9956849eb84bfe8703f8f3688d","title":"BioBART: Pretraining and Evaluation of A Biomedical Generative Language Model"},{"paperId":"c8b6edf3e3280e1af9692a176667e9ebd2f66952","title":"Development and Validation of an Automatic System for Intracerebral Hemorrhage Medical Text Recognition and Treatment Plan Output"},{"paperId":"232fa491c124ebefb041cd6e3e3aff20aa53d0ef","title":"The HoPE Model Architecture: a Novel Approach to Pregnancy Information Retrieval Based on Conversational Agents"},{"paperId":"796aba07b417b8dd3e428ef7a1bdbd9df019647b","title":"Paying More Attention to Self-attention: Improving Pre-trained Language Models via Attention Guiding"},{"paperId":"5099f9d053eb53f55bd73db5b46b8b1836456242","title":"Global Readiness of Language Technology for Healthcare: What Would It Take to Combat the Next Pandemic?"},{"paperId":"456a70485aafc12dfed4fb7354668d72aae9b658","title":"SecureBERT: A Domain-Specific Language Model for Cybersecurity"},{"paperId":"456a70485aafc12dfed4fb7354668d72aae9b658","title":"SecureBERT: A Domain-Specific Language Model for Cybersecurity"},{"paperId":"3336f8eb7ce2b0b8a8a38066ce6d483a7d5fbd20","title":"Combining biomedical knowledge graphs and text to improve predictions for drug-target interactions and drug-indications"},{"paperId":"4714313c8dcc5e51236e90146c24df1f440250e5","title":"Graph Enhanced Contrastive Learning for Radiology Findings Summarization"},{"paperId":"bcb71c92c1643e9d1c5aeaf6c9ef34ccab6e209b","title":"Connecting the dots in clinical document understanding with Relation Extraction at scale"},{"paperId":"596ec1c14f59eabd9cefebef9a7a4f6b363496b0","title":"Examining AI Methods for Micro-Coaching Dialogs"},{"paperId":"493677b136a9c37cf375364759dea267a49a0267","title":"Context-Enriched Learning Models for Aligning Biomedical Vocabularies at Scale in the UMLS Metathesaurus"},{"paperId":"7e86cdac1194a75c49534d0d85eb143807a7306b","title":"ISeeU2: Visually interpretable mortality prediction inside the ICU using deep learning and free-text medical notes"},{"paperId":"754955362330c7ffde74517a4b0f0908f2da4d93","title":"A multi-input multi-label claims channeling system using insurance-based language models"},{"paperId":"0e9d5452ea84ddf2cff0d8181dc612c752a60909","title":"Privacy-preserving mimic models for clinical named entity recognition in French"},{"paperId":"acc9707181fcf13b7976e127ec3841cb0a67ce32","title":"Pre2Pub—Tracking the Path From Preprint to Journal Article: Algorithm Development and Validation"},{"paperId":"f9d31dbc487db243653581c37546bf607aa522cc","title":"Effects of data and entity ablation on multitask learning models for biomedical entity recognition"},{"paperId":"96320d0ae587b4755df1a81ad71bf3f45acce08f","title":"Understanding what patients think about hospitals: A deep learning approach for detecting emotions in patient opinions"},{"paperId":"1e76a2298cc43d3cc6621a978731473d4f059852","title":"Quantifying the advantage of domain-specific pre-training on named entity recognition tasks in materials science"},{"paperId":"d4ca18fcb670875d9189572a0e90776042e120ce","title":"Manifold biomedical text sentence embedding"},{"paperId":"7625a53d1c27b2aca9c4868e72356db21abab68e","title":"A Web Application for Biomedical Text Mining of Scientific Literature Associated with Coronavirus-Related Syndromes: Coronavirus Finder"},{"paperId":"9cae815605a7c74c2e986933d8f913620011250f","title":"Efficient Argument Structure Extraction with Transfer Learning and Active Learning"},{"paperId":"b6faf518efe5eec04680e0e063a0a762c65b6121","title":"UGDAS: Unsupervised Graph-Network based Denoiser for Abstractive Summarization in biomedical domain."},{"paperId":"05787af79b25e78d8a7c57bc9e3cdf3351bb24fe","title":"Predicting Intervention Approval in Clinical Trials through Multi-Document Summarization"},{"paperId":"facae763f56c1ce9d2a5dd55d4ca607933ff6c4d","title":"Refining electronic medical records representation in manifold subspace"},{"paperId":"df1b3e55e8092a2aa42bb3eab8db778f2b94d66c","title":"The auto segmentation for cardiac structures using a dual‐input deep learning network based on vision saliency and transformer"},{"paperId":"2c12d24c5ba5ad3bb3994635fcfcb9f8caac31d0","title":"Position-based Prompting for Health Outcome Generation"},{"paperId":"844c60f5f1fced8fecf43febd0147e0422553564","title":"Entity-Driven Fact-Aware Abstractive Summarization of Biomedical Literature"},{"paperId":"f9a6a09dd22be01feb70045251bf893378043b21","title":"Self-Supervised Generalized Zero Shot Learning for Medical Image Classification Using Novel Interpretable Saliency Maps"},{"paperId":"af38697d8acf289ce8b0ebe2bcc638aff0eb1a1d","title":"The Inefficiency of Language Models in Scholarly Retrieval: An Experimental Walk-through"},{"paperId":"a83cdcc0135c58fddf89fc72f1b92b7a9d1e170f","title":"LinkBERT: Pretraining Language Models with Document Links"},{"paperId":"f8e84536ad1e2ba1a86c1548821bbac991321d24","title":"Hierarchical Transformer Model for Scientific Named Entity Recognition"},{"paperId":"e51b0fe8683e0ccde29d7bf560b6dec4e2bfe116","title":"Getting Personal: A Deep Learning Artifact for Text-Based Measurement of Personality"},{"paperId":"ee8b03a868a66d741e6f1508fa141ae8e0a7bd99","title":"Integrating Physiological Time Series and Clinical Notes with Transformer for Early Prediction of Sepsis"},{"paperId":"741776172685b9717159a9fcd21841461bb33b14","title":"MedMCQA : A Large-scale Multi-Subject Multi-Choice Dataset for Medical domain Question Answering"},{"paperId":"7fbc34f15f62be3711e24fa209d4830c7735ca0e","title":"ESGBERT: Language Model to Help with Classification Tasks Related to Companies Environmental, Social, and Governance Practices"},{"paperId":"5e0c3e19dfbcf3040f70f77821b4b5372810d273","title":"Predicting Clinical Intent from Free Text Electronic Health Records"},{"paperId":"94d05045e9bf69e015f5398086ac5c27a70d13e6","title":"A Comparative Evaluation Of Transformer Models For De-Identification Of Clinical Text Data"},{"paperId":"6cfe73cba2050aeb14badc4aa33c18ac837552f5","title":"Ontology-Aware Biomedical Relation Extraction"},{"paperId":"66718735f4dbe579d2d61441c2d53c10fa13ee48","title":"Predicting Adverse Drug Reactions from Social Media Posts: Data Balance, Feature Selection and Deep Learning"},{"paperId":"e68d1aa5e78226bb868a43842a87a5532b813b0b","title":"CancerBERT: a cancer domain-specific language model for extracting breast cancer phenotypes from electronic health records"},{"paperId":"0ec91fd9c5c3ff9758d9cfddc2e5046eaa3c1ab0","title":"Multi-armed bandits for online optimization of language model pre-training: the use case of dynamic masking"},{"paperId":"434f4ecbfdea4496bbcd763427fc605bf11abddc","title":"Token Dropping for Efficient BERT Pretraining"},{"paperId":"437d711231ad59c3720c0b8dcbc9f8730b40a271","title":"An Efficient Method for Biomedical Entity Linking Based on Inter- and Intra-Entity Attention"},{"paperId":"5ca7fed2176b862a521c12b235d5e27c5ded12a4","title":"TCM-SD: A Large Dataset for Syndrome Differentiation in Traditional Chinese Medicine"},{"paperId":"3c876033cf83c9b40156aa8f8ff7f044abf188d9","title":"PTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with Pre-trained Models"},{"paperId":"124e2ca9f36d13c3b33cc3cd9a5aed953713efb1","title":"TCM-SD: A Benchmark for Probing Syndrome Differentiation via Natural Language Processing"},{"paperId":"70e2fe147c3fea47d25f40b9cbf4b7e8e3228810","title":"Towards Structuring Real-World Data at Scale: Deep Learning for Extracting Key Oncology Information from Clinical Text with Patient-Level Supervision"},{"paperId":"56af3c451396b4e9d7c4d9757d23b4a85cd6ece7","title":"Cluster & Tune: Boost Cold Start Performance in Text Classification"},{"paperId":"78a4f90b348f5401e8fb6b84bca0e539142b2530","title":"Enriching Unsupervised User Embedding via Medical Concepts"},{"paperId":"65e4847e3a873c47308137552c00b182e034b6f7","title":"Improving End-to-End Biomedical Question Answering System"},{"paperId":"903e43969669a84f1c2e775408d17f4e49d12e80","title":"Graph-Text Multi-Modal Pre-training for Medical Representation Learning"},{"paperId":"f52f7964febd6d6d72aa23505b50d33e1d4ce0aa","title":"Prompt-Based Rule Discovery and Boosting for Interactive Weakly-Supervised Learning"},{"paperId":"72600c2aee2ef4e3c229b5e72512fad2b5ad6450","title":"MLIR-based code generation for GPU tensor cores"},{"paperId":"bdf57f977b54ab3126396041cab087485530638f","title":"Exploiting Intersentence Information for Better Question-Driven Abstractive Summarization: Algorithm Development and Validation"},{"paperId":"57150554101ab59add536858da0ab5df34e9f98c","title":"Deep learning-based methods for natural hazard named entity recognition"},{"paperId":"182b92dafafd619a472418818fda0947efc100a8","title":"ERNIE-GeoL: A Geography-and-Language Pre-trained Model and its Applications in Baidu Maps"},{"paperId":"d5265d3294897df2e9514e796d1248813f27d609","title":"Comparison of Text Mining Models for Food and Dietary Constituent Named-Entity Recognition"},{"paperId":"a2cd34174ffd3822ec04d00f261ee1690e1318b1","title":"An Extensive Study on Pretrained Models for Natural Language Processing Based on Transformers"},{"paperId":"cfc12c38a4d848ff3c4225488a2c72e7d4300f4b","title":"Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again"},{"paperId":"a761e7e9c731ccc98ac1ba60ead15713b077514a","title":"Representation Learning for Resource-Constrained Keyphrase Generation"},{"paperId":"ff1d47527279d353e29ef1071c7c58cc85c09146","title":"DFDT: An End-to-End DeepFake Detection Framework Using Vision Transformer"},{"paperId":"73b66acf99307cdde95c464350656c06fd1fefeb","title":"Hierarchical BERT for Medical Document Understanding"},{"paperId":"57d922f509438de1f1bb9b92a1589dbbacc612ab","title":"Survey of BERT-Base Models for Scientific Text Classification: COVID-19 Case Study"},{"paperId":"5493aefc07e331045be76003ea516aef57f76cb9","title":"BERTopic: Neural topic modeling with a class-based TF-IDF procedure"},{"paperId":"3d5b3a4d1da867615e6e9c5b9b8e975772d4396e","title":"An Efficient Approach to Validate COVID-19 Related Vaccine Myths Utilizing LDA Algorithm"},{"paperId":"2c6bf40b52ced7f34497ac78bf91046a2e9095a7","title":"A Syntactic Information–Based Classification Model for Medical Literature: Algorithm Development and Validation Study"},{"paperId":"2b16f2d2982693c878d8959740454e49c58b67ad","title":"Using Rule-Based Decision Trees to Digitize Legislation"},{"paperId":"6c3bad0a8c08799602321adf7ed006d89ba583fe","title":"SentiMedQAer: A Transfer Learning-Based Sentiment-Aware Model for Biomedical Question Answering"},{"paperId":"e466cd7c47a245a62652c26306c9e7f2f8d463e3","title":"Reliably Filter Drug-Induced Liver Injury Literature With Natural Language Processing and Conformal Prediction"},{"paperId":"bf22ef16a6a912763780aea454198edc3e2bb3c9","title":"HealthPrompt: A Zero-shot Learning Paradigm for Clinical Natural Language Processing"},{"paperId":"a24c6530ef9e886313e264cdbd7652177535f25b","title":"Nested Named Entity Recognition as Latent Lexicalized Constituency Parsing"},{"paperId":"73a9b0bde23c70faa6917da3b075af5bc9a5ab6d","title":"How Do Your Biomedical Named Entity Recognition Models Generalize to Novel Entities?"},{"paperId":"aad2f3891a480fec7e91fdd90760b7cc701687fa","title":"Identifying the Perceived Severity of Patient-Generated Telemedical Queries Regarding COVID: Developing and Evaluating a Transfer Learning–Based Solution"},{"paperId":"2cec6c2f2208a9c0e73f3861dfe968f70a3a17bd","title":"Conditional Probability Joint Extraction of Nested Biomedical Events: Design of a Unified Extraction Framework Based on Neural Networks"},{"paperId":"31162bf598a551b34d604381b5611591370bc8dc","title":"Adaptor: Objective-Centric Adaptation Framework for Language Models"},{"paperId":"cc3b41c4d2ededb94b481089633ecb43d6b2162f","title":"Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks"},{"paperId":"822677a7f151dbeb090bf873b29b1a90617a992b","title":"An Explainable Fake News Detector Based on Named Entity Recognition and Stance Classification Applied to COVID-19"},{"paperId":"9dcdfd4cdaedd58ed6c5628b1f552db7240885bb","title":"Negation and uncertainty detection in clinical texts written in Spanish: a deep learning-based approach"},{"paperId":"69d63c22fdcc0fe55a8257f21a1d5b28dafebb6b","title":"Pretrained transformer framework on pediatric claims data for population specific tasks"},{"paperId":"59043fbe7e072281b5865c3843179a2a7ec72b29","title":"Semantic-guided Image Virtual Attribute Learning for Noisy Multi-label Chest X-ray Classification"},{"paperId":"e5455cf9805553cc9fe6245bd023040394584a0c","title":"BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification"},{"paperId":"4d641be66d74cf365a985dea38c9f04827d18a3c","title":"Neuroimaging-ITM: A Text Mining Pipeline Combining Deep Adversarial Learning with Interaction Based Topic Modeling for Enabling the FAIR Neuroimaging Study"},{"paperId":"0f03a9b6d6c7179469b0f4c70651e5b9cca09496","title":"Joint Event Extraction Based on CNN-BiGRU and Attention Mechanism"},{"paperId":"0183e229e6461bd8dbd190164b277475b8c6710c","title":"Language Model Adaptation for Downstream Tasks using Text Selection"},{"paperId":"e4c7a03532b6dcf24f91419077c9dfae1680b522","title":"A Survey of Automated ICD Coding: Development, Challenges, and Applications"},{"paperId":"429018881ad753f0d5be21fdad6c036c44566005","title":"Sources of bias in artificial intelligence that perpetuate healthcare disparities—A global review"},{"paperId":"d31284e19582704026ee3404a9bcc4ad844e3e04","title":"Scarcity-aware spam detection technique for big data ecosystem"},{"paperId":"cf29119491af550cde4948f7ba7444cef3e66fec","title":"Implementation of specialised attention mechanisms: ICD-10 classification of Gastrointestinal discharge summaries in English, Spanish and Swedish"},{"paperId":"aaef5ad317dee2898cc2882fc1f205a48c9bf826","title":"A Question-and-Answer System to Extract Data From Free-Text Oncological Pathology Reports (CancerBERT Network): Development Study"},{"paperId":"202d2d74eb034cdb04763cbfb289e4054933c99b","title":"A soft sensor model based on long&short-term memory dual pathways convolutional gated recurrent unit network for predicting cement specific surface area."},{"paperId":"ac5743bde52e722ba39809dffa683d885c551dbe","title":"LTM-TCM: A Comprehensive Database for the Linking of Traditional Chinese Medicine with Modern Medicine at Molecular and Phenotypic Levels."},{"paperId":"e7c14972ce1799350970d9f5813020c3b951a4af","title":"Rule-Enhanced Active Learning for Semi-Automated Weak Supervision"},{"paperId":"6511c2f6207ebd7f2a70766d62540825c928f8b3","title":"Advances in Machine Learning Approaches to Heart Failure with Preserved Ejection Fraction."},{"paperId":"276737efc637bcb77875661192b5a3850eaa8db5","title":"CG-ANER: Enhanced contextual embeddings and glyph features-based agricultural named entity recognition"},{"paperId":"769eae977c287f7696ad8fd4cc568785fdbe1779","title":"PMC-Patients: A Large-scale Dataset of Patient Notes and Relations Extracted from Case Reports in PubMed Central"},{"paperId":"cdab0f65ea52e278dc04210f6844d12e8ed8a1e2","title":"Layout Aware Semantic Element Extraction for Sustainable Science & Technology Decision Support"},{"paperId":"2b350bdc69ea732293a21b524e7226c59afc9f62","title":"Semi-Automatic Systematic Literature Reviews and Information Extraction of COVID-19 Scientific Evidence: Description and Preliminary Results of the COKE Project"},{"paperId":"708c3a048132cf23f48dc5c4720667ee1fbfe0ba","title":"Using Text Content From Coronary Catheterization Reports to Predict 5-Year Mortality Among Patients Undergoing Coronary Angiography: A Deep Learning Approach"},{"paperId":"433c04f22c89d8ed6d0d3b2a163ac21f80a5beb5","title":"Research on Word Vector Training Method Based on Improved Skip-Gram Algorithm"},{"paperId":"883b944a877c2bb868dec304f5ba8616caf7bacb","title":"Enhancing Legal Argument Mining with Domain Pre-training and Neural Networks"},{"paperId":"92b3bf2fb4d73fac5df391febe403ef643c6a6fe","title":"BioADAPT-MRC: adversarial learning-based domain adaptation improves biomedical machine reading comprehension task"},{"paperId":"3099c275ba22d119580aaffa76eb5d19bf292745","title":"A review of biomedical named entity recognition"},{"paperId":"06ef1f9e1a760df942548ab38ea7e49e6145c6bd","title":"Deep Learning, Natural Language Processing, and Explainable Artificial Intelligence in the Biomedical Domain"},{"paperId":"ea0ce99f729d8ef1d33377298cabf101c921e435","title":"Infusing Biomedical Knowledge into BERT for Chinese Biomedical NLP Tasks with Adversarial Training"},{"paperId":"8dec610f8e0f40ab596a926c19d6d07bdaa7cbd9","title":"MetaboListem and TABoLiSTM: Two Deep Learning Algorithms for Metabolite Named Entity Recognition"},{"paperId":"7a9df88b2e10fd071d045cad1d4239116095ca99","title":"Machine Reading Comprehension-Enabled Public Service Information System: A Large-Scale Dataset and Neural Network Models"},{"paperId":"6aa11fd88d13fc710ae3c58ba04f05f30a28ae6d","title":"IDDLncLoc: Subcellular Localization of LncRNAs Based on a Framework for Imbalanced Data Distributions"},{"paperId":"3607680a9c4394cfbf8bcf567785789a0391d307","title":"BERT WEAVER: Using WEight AVERaging to Enable Lifelong Learning for Transformer-based Models"},{"paperId":"9bcf15f5be80cbfbf8c94cae4e634a41a4fd848c","title":"Contextual Semantic Embeddings for Ontology Subsumption Prediction"},{"paperId":"cc03ca7e9397106acc6f718a276ce06f5b7955fc","title":"DrugShot: querying biomedical search terms to retrieve prioritized lists of small molecules"},{"paperId":"1835271fa8536a707d14e3b9cff111a2b8ab0444","title":"Identifying the Adoption or Rejection of Misinformation Targeting COVID-19 Vaccines in Twitter Discourse"},{"paperId":"595ebf1c5a50b416d14ca0aa4bd8ab3cd55c7736","title":"VaccineLies: A Natural Language Resource for Learning to Recognize Misinformation about the COVID-19 and HPV Vaccines"},{"paperId":"894b0e04d4cd8b94728469c3467b78653bfcd271","title":"MLM-based typographical error correction of unstructured medical texts for named entity recognition"},{"paperId":"e6c0565b1ae39d725d384f76c7093775ba870361","title":"Deciphering endothelial heterogeneity in health and disease at single-cell resolution: progress and perspectives"},{"paperId":"37351ba2948ed9657a6cceecd0b7e1cfae4dbedc","title":"Prediction and Diagnosis of Respiratory Disease by Combining Convolutional Neural Network and Bi-directional Long Short-Term Memory Methods"},{"paperId":"cdd8eed4157422f417b5ffdb8ce02a7152440bf3","title":"A deep-learning system bridging molecule structure and biomedical text with comprehension comparable to human professionals"},{"paperId":"e4d098db56387be56b6b29e9b05bc6be071a099c","title":"Hospital Readmission Prediction Using Clinical Admission Notes"},{"paperId":"d2aa948525bac48fcf54dad4fee94be594928a89","title":"DILI C : An AI-Based Classifier to Search for Drug-Induced Liver Injury Literature"},{"paperId":"d1b37c777ba25b2f92a28ea09b59b06bb8014f4c","title":"LMN at SemEval-2022 Task 11: A Transformer-based System for English Named Entity Recognition"},{"paperId":"29ed68d701f8450853938827b5124c9613c56aff","title":"ET-BERT: A Contextualized Datagram Representation with Pre-training Transformers for Encrypted Traffic Classification"},{"paperId":"f2df1a1c2c157bf53233a6648deb5135746fec43","title":"Assessment of contextualised representations in detecting outcome phrases in clinical trials"},{"paperId":"a166957ec488cd20e61360d630568b3b81af3397","title":"Multimodal reasoning based on knowledge graph embedding for specific diseases"},{"paperId":"af66582e38fc660a664dcd22d3fd147ad34144b5","title":"Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification"},{"paperId":"39b5a3b516a060d8f7460e0fbedcce72f0190e20","title":"TimeLMs: Diachronic Language Models from Twitter"},{"paperId":"1cee062839bf769565bc64df1d7842ff0b223f3d","title":"HistBERT: A Pre-trained Language Model for Diachronic Lexical Semantic Analysis"},{"paperId":"86e08c737727732c904bec1de2f485cecbdde1f5","title":"RerrFact: Reduced Evidence Retrieval Representations for Scientific Claim Verification"},{"paperId":"974b94cbc0990b55cb9ede765146d3455eeee33d","title":"Transformers and the Representation of Biomedical Background Knowledge"},{"paperId":"220590e7815ea278959329058a5de3e4c9df9f4e","title":"FedBERT: When Federated Learning Meets Pre-training"},{"paperId":"1afefea0ca3ed8650540caa5c11dde05b550c6db","title":"Protein–DNA/RNA interactions: Machine intelligence tools and approaches in the era of artificial intelligence and big data"},{"paperId":"af0fe7f31315a4173de5695887dffb20be458f48","title":"GatorTron: A Large Clinical Language Model to Unlock Patient Information from Unstructured Electronic Health Records"},{"paperId":"47cb4bf54310fa0974b73efd5e34390044b65cef","title":"Beyond belief: a cross-genre study on perception and validation of health information online"},{"paperId":"268bc8744f96519bd687ae857a48f8c3b5ce3d74","title":"The h-ANN Model: Comprehensive Colonoscopy Concept Compilation using Combined Contextual Embeddings"},{"paperId":"a005c00b390fdb3997a44a51118d44510c99c686","title":"SE<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" display=\"inline\" id=\"d1e1334\" altimg=\"si1.svg\"><mml:msup><mml:mrow /><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msup></mml:math>M: A model for software effort estimation using pre-trained embedding models"},{"paperId":"6a7976da7268d1fd85e93ae1b9a846d4b682d812","title":"TAX-Corpus: Taxonomy based Annotations for Colonoscopy Evaluation"},{"paperId":"a7c8a5bb20394e89e96466ddeb473574a0902e9b","title":"Leveraging Multi-source knowledge for Chinese clinical named entity recognition via relational graph convolutional network"},{"paperId":"926cdffdf81aa59b2d48733a934e013adabb7534","title":"Deep Learning-based detection of psychiatric attributes from German mental health records"},{"paperId":"6787c0592b508ff6d1c164ad52ba7c9d2d6eea90","title":"Merging Data Curation and Machine Learning to Improve Nanomedicines."},{"paperId":"43023976b47e415d5d92cf50c6101d5b5492434a","title":"Health Misinformation Detection in the Social Web: An Overview and a Data Science Approach"},{"paperId":"d88eb88a8d2564dd1352a2a4b1ac73019d259364","title":"Can natural language processing models extract and classify instances of interpersonal violence in mental healthcare electronic records: an applied evaluative study"},{"paperId":"8824f2934c39b3c3e9a9ed81a1a8a9628e05a12f","title":"Deep Learning Approaches for Predicting Glaucoma Progression Using Electronic Health Records and Natural Language Processing"},{"paperId":"04bf877d77318ac0c8fc81a58664d1ff14da1612","title":"Disambiguating Clinical Abbreviations Using a One-Fits-All Classifier Based on Deep Learning Techniques"},{"paperId":"6ed70b7c3ff806f6e6e1559656c2af9e655949ec","title":"Examining linguistic shifts between preprints and publications"},{"paperId":"18695b682d8061dbd1f4f49360d577a518730a2b","title":"Bridging the Gap between Structured and Free-form Radiology Reporting: A Case-study on Coronary CT Angiography"},{"paperId":"439e410b3a8b69da51ffe9b026c3834b8aa61954","title":"Improving Crisis Events Detection Using DistilBERT with Hunger Games Search Algorithm"},{"paperId":"c40e4e72a4d08b45f9ea6113711e8256b62fed40","title":"Automated Creation and Human-assisted Curation of Computable Scientific Models from Code and Text"},{"paperId":"8b1413494e38097610d100dc73cd87b57f022f5b","title":"Clinical-Longformer and Clinical-BigBird: Transformers for long clinical sequences"},{"paperId":"fef7e9eeed1ec5f0ba28ff88699f2965cf4d8c40","title":"The Text Anonymization Benchmark (TAB): A Dedicated Corpus and Evaluation Framework for Text Anonymization"},{"paperId":"22bc283434afffb32a049d2984333687c65e6fe6","title":"A Semantic Annotation Pipeline towards the Generation of Knowledge Graphs in Tribology"},{"paperId":"27210a85919e9d6304cb7f70a24f593bd7a88155","title":"Two heads are better than one: Enhancing medical representations by pre-training over structured and unstructured electronic health records"},{"paperId":"313d64e319aa1543ea101ef79b7c5c68a6d8451e","title":"Improving Chest X-Ray Report Generation by Leveraging Warm-Starting"},{"paperId":"4ab41d9780f1d1ac34d39fa7e527e73652507fcc","title":"GreaseLM: Graph REASoning Enhanced Language Models for Question Answering"},{"paperId":"ec72909b75b2389efd588aa38d9c664e654d90d3","title":"Automatic Classification of Cancer Pathology Reports: A Systematic Review"},{"paperId":"08a3cc9ec38a2b78b8c9bed856712852d02f13d5","title":"Automated extraction of genes associated with antibiotic resistance from the biomedical literature"},{"paperId":"29c21e5a4512e88466a8f1b63164d47a2a34c0f1","title":"An annotated dataset for extracting gene-melanoma relations from scientific literature"},{"paperId":"15031e6a94f9d6d19f74740c224a5523ec64d975","title":"Improving Biomedical Information Retrieval with Neural Retrievers"},{"paperId":"bfd9ea31854e0441e53d3f189ae395a77c28cb68","title":"TourBERT: A pretrained language model for the tourism industry"},{"paperId":"f550db22cc95914612157d4b46c2d2d3f263e0bf","title":"Telugu named entity recognition using bert"},{"paperId":"18a27fb69084b5d97fd2428b099c8fc303f4ba75","title":"Automated recognition of functioning, activity and participation in COVID-19 from electronic patient records by natural language processing: a proof- of- concept"},{"paperId":"15d6ffcb57cdfac3ed8c92a4347b0574f7c99ba1","title":"Incorporation of gene ontology in identification of protein interactions from biomedical corpus: a multi-modal approach"},{"paperId":"11a348120b115ddeb4bcee18c876a60a07852355","title":"RuMedBench: A Russian Medical Language Understanding Benchmark"},{"paperId":"7b54cb7b9c9b821846b00a05aecc6ccfdb56c409","title":"Extraction of the Relations among Significant Pharmacological Entities in Russian-Language Reviews of Internet Users on Medications"},{"paperId":"da18398274bec87d3568acfd6aba6977be7ba6b8","title":"Transferability in Deep Learning: A Survey"},{"paperId":"eec7e7eea9fe6cdf84954f3ce0dab7897bfb061f","title":"The role of software in science: a knowledge graph-based analysis of software mentions in PubMed Central"},{"paperId":"4523d17a54150a01aef62ea0b1ce13f7100f3d88","title":"Comparison of different feature extraction methods for applicable automated ICD coding"},{"paperId":"95f1c3920f9ecaf3a2886998d5aa179066e54fc4","title":"A visual atlas of genes’ tissue-specific pathological roles"},{"paperId":"9afc670578ff18c3ab9eee541e4e04b40eb31b9b","title":"Medication Error Detection Using Contextual Language Models"},{"paperId":"abe271c4dfb187cb5dc80c23ebdf16b443ce68a4","title":"Zero-Shot and Few-Shot Classification of Biomedical Articles in Context of the COVID-19 Pandemic"},{"paperId":"55fef956f84e0f205cc6ee6655065403e6554222","title":"Clinical impact of a deep learning system for automated detection of missed pulmonary nodules on routine body computed tomography including the chest region"},{"paperId":"7b1079a4348b43ae704b2a886532180a846f8ff7","title":"Biomedical relation extraction via knowledge-enhanced reading comprehension"},{"paperId":"f14aa0856733f36c058b89eb58eb0a9f40c68ead","title":"Unstructured clinical notes within the 24 hours since admission predict short, mid & long-term mortality in adult ICU patients"},{"paperId":"22a77ab4b79b43c69ce25a272de480b2a025c6a4","title":"BERN2: an advanced neural biomedical named entity recognition and normalization tool"},{"paperId":"22a77ab4b79b43c69ce25a272de480b2a025c6a4","title":"BERN2: an advanced neural biomedical named entity recognition and normalization tool"},{"paperId":"d6a64f4691c3738aecaf33fb568aed5ecaf5377c","title":"Analyzing COVID-19 Medical Papers Using Artificial Intelligence: Insights for Researchers and Medical Professionals"},{"paperId":"056d735b9c370cb97282a2ec227f0300d7268f29","title":"Mining Adverse Drug Reactions from Unstructured Mediums at Scale"},{"paperId":"bec4c10172237981f1f73e7e7af472ad1bdbb7fe","title":"Hierarchical shared transfer learning for biomedical named entity recognition"},{"paperId":"31d871379976f859abc0dc0f9f713b004083e4e4","title":"COVIDSum: A linguistically enriched SciBERT-based summarization model for COVID-19 scientific papers"},{"paperId":"49bfcf6a9a8781b358dc5b3baaa7e8ac67dd14cd","title":"Chemical–protein relation extraction with ensembles of carefully tuned pretrained language models"},{"paperId":"a2439d350943601be90afb0516b747e4a6caebac","title":"Multi-label classification for biomedical literature: an overview of the BioCreative VII LitCovid Track for COVID-19 literature topic annotations"}],"references":[{"paperId":"31fe8afa6531400e3b76982a3984c7e2605074f8","title":"Document-level attention-based BiLSTM-CRF incorporating disease dictionary for disease named entity recognition"},{"paperId":"14ad9d060c1e8f0449e697ee189ac346353fbfbc","title":"CollaboNet: collaboration of deep neural networks for biomedical named entity recognition"},{"paperId":"2a567ebd78939d0861d788f0fedff8d40ae62bf2","title":"Publicly Available Clinical BERT Embeddings"},{"paperId":"fa82a552e9001ec95432f63fe4f3172dbba3beab","title":"The cell line ontology-based representation, integration and analysis of cell lines used in China"},{"paperId":"d08be34cb90718b331aa6574dc80b0370ca5895f","title":"A Silver Standard Corpus of Human Phenotype-Gene Relations"},{"paperId":"e65715d20baac11d0a53fd7107de18cb7f67e775","title":"MedMentions: A Large Biomedical Corpus Annotated with UMLS Concepts"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"afc317b098cd6744611049ff16f351032ab14f83","title":"A BERT-based Universal Model for Both Within- and Cross-sentence Clinical Temporal Relation Extraction"},{"paperId":"8b13ef2ac652221715259b85f792c49ae14c7dd7","title":"Clinical Concept Extraction with Contextual Word Embedding"},{"paperId":"f8b901c330e7f946ef93453b24682f294b8764a1","title":"In-domain Context-aware Token Embeddings Improve Biomedical Named Entity Recognition"},{"paperId":"cc09d65183d3b986d1477df8584c96ecfee2b184","title":"Automatic extraction of gene-disease associations from literature using joint ensemble learning"},{"paperId":"2966e82ec5f89f23ec7636acc00c9ee74d491968","title":"Chemical–gene relation extraction using recursive neural network"},{"paperId":"fa4e9eb4020ef7152adbd62906d605d63236ef37","title":"Transfer learning for biomedical named entity recognition with neural networks"},{"paperId":"dbcceca38e09de4a69ff2920e2fe3efc90511fa5","title":"An attention‐based BiLSTM‐CRF approach to document‐level chemical named entity recognition"},{"paperId":"3febb2bed8865945e7fddc99efd791887bb7e14f","title":"Deep Contextualized Word Representations"},{"paperId":"418cd8e078ed9b91b08e7915ac6753ed811053e4","title":"Cross-type Biomedical Named Entity Recognition with Deep Multi-Task Learning"},{"paperId":"d5400c4cc068eda5fd4c6f7c7f4bfcea41a5a1f8","title":"A Pilot Study of Biomedical Text Comprehension using an Attention-Based Deep Neural Reader: Design and Experimental Analysis"},{"paperId":"9223c95f0e600aee2dcf476094a5102adc386e0f","title":"Effective Use of Bidirectional Language Modeling for Transfer Learning in Biomedical Named Entity Recognition"},{"paperId":"91c035165ee5f251c4a0c0b2af67d2891b404316","title":"NSML: A Machine Learning Platform That Enables You to Focus on Your Models"},{"paperId":"c54e8c7a4f9c2ebd8787aecafa4cfdb35bfd49e0","title":"Effective Use of Bidirectional Language Modeling for Medical Named Entity Recognition"},{"paperId":"db8562bb8dc69a7628c49c92ac8e08b5da91130e","title":"A transition‐based joint model for disease named entity recognition and normalization"},{"paperId":"bc8fa64625d9189f5801837e7b133e7fe3c581f7","title":"Learned in Translation: Contextualized Word Vectors"},{"paperId":"91d4498849fe1966a629cddb187d3cd62eedb2ca","title":"Deep learning with word embeddings improves biomedical named entity recognition"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","title":"Attention is All you Need"},{"paperId":"4c16a6fd7b4aad8c1331e4753b30701fdf6d12f4","title":"Neural Domain Adaptation for Biomedical Question Answering"},{"paperId":"f27c51137c40940e2facc0ec932cf560967e1f5a","title":"ChimerDB 3.0: an enhanced database for fusion genes from cancer transcriptome and literature data mining"},{"paperId":"eed781f498b563df5a9e8a241c67d63dd1d92ad5","title":"Overview of the BioCreative VI chemical-protein interaction Track"},{"paperId":"dbde7dfa6cae81df8ac19ef500c42db96c3d1edd","title":"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"},{"paperId":"05dd7254b632376973f3a1b4d39485da17814df5","title":"SQuAD: 100,000+ Questions for Machine Comprehension of Text"},{"paperId":"61322ec6cfc54fe9723d4637239b8fb9938dc501","title":"BioCreative V CDR task corpus: a resource for chemical disease relation extraction"},{"paperId":"a4cec122a08216fe8a3bc19b22e78fbaea096256","title":"Deep Learning"},{"paperId":"c4dd9a19d822c965ce8cde55ab23b8a0b628278a","title":"An overview of the BIOASQ large-scale biomedical semantic indexing and question answering competition"},{"paperId":"932117813af889104cafb457ebbc52a38d8b64eb","title":"The CHEMDNER corpus of chemicals and drugs and its annotation principles"},{"paperId":"f37e1b62a767a307c046404ca96bc140b3e68cb5","title":"GloVe: Global Vectors for Word Representation"},{"paperId":"cfb4edb7541fafcf593b466320c63ae32d27f57e","title":"Extraction of relations between genes and diseases from text and large-scale data analysis: implications for translational research"},{"paperId":"696753d59185436ec95ecf3021c413f353be4874","title":"NCBI disease corpus: A resource for disease name recognition and concept normalization"},{"paperId":"87f40e6f3022adbc1f1905e3e506abad05a9964f","title":"Distributed Representations of Words and Phrases and their Compositionality"},{"paperId":"c83d05b15797ade0f8dffb9a311a859682d43a27","title":"The SPECIES and ORGANISMS Resources for Fast and Accurate Identification of Taxonomic Names in Text"},{"paperId":"e2f28568031e1902d4f8ee818261f0f2c20de6dd","title":"Distributional Semantics Resources for Biomedical Text Processing"},{"paperId":"506c7e333efa0b31823c1b1914b1180c346773ee","title":"The EU-ADR corpus: Annotated drugs, diseases, targets, and their relationships"},{"paperId":"5e095981ebf4d389e9356bd56e59e0ade1b42e88","title":"2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text"},{"paperId":"e1039346942874c59d89028bb934b72524827b8c","title":"LINNAEUS: A species name identification system for biomedical literature"},{"paperId":"f5a0c6593ba95d23c025608ce9280848da8b929f","title":"Overview of BioCreative II gene mention recognition"},{"paperId":"3bd4d2de49d8a092abb295b845dba14874f8787d","title":"Introduction to the Bio-entity Recognition Task at JNLPBA"},{"paperId":"6c2b28f9354f667cd5bd07afc0471d8334430da7","title":"A Neural Probabilistic Language Model"}],"id":"1e43c7084bdcb6b3102afaf301cce10faead2702","summary":"This article introduces BioBERT (Bidirectional Encoder Representations from Transformers for Biomedical Text Mining), which is a domain-specific language representation model pre-trained on large-scale biomedical corpora that largely outperforms BERT and previous state-of-the-art models in a variety of biomedical text mining tasks when pre- trained on biomedical Corpora."},{"url":"https://www.semanticscholar.org/paper/4ef3d9e492479e28fa57d107e52acc6a0c803de2","title":"Does CLIP Benefit Visual Question Answering in the Medical Domain as Much as it Does in the General Domain?","venue":"arXiv.org","year":2021,"referenceCount":30,"citationCount":23,"influentialCitationCount":7,"publicationDate":"27/12/2021","authors":"Sedigheh Eslami,Gerard de Melo,C. Meinel","citations":[{"paperId":"4cf4528e3b19a22bcfb041d09be53bd3095bcef8","title":"Q2ATransformer: Improving Medical VQA via an Answer Querying Decoder"},{"paperId":"61b877c3ef91286fe3fca51c899bf6c857ea4add","title":"Leveraging medical Twitter to build a visual–language foundation model for pathology AI"},{"paperId":"ce865a1d2ad7ac6850bfc72edcea9e6cf3930976","title":"Increasing Textual Context Size Boosts Medical Image-Text Matching"},{"paperId":"a5bc3c0bce8d105a6b95f999fed4ea59c342cb1d","title":"MultiModal Bias: Introducing a Framework for Stereotypical Bias Assessment beyond Gender and Race in Vision Language Models"},{"paperId":"d8da72e7857cc1a0d3505e6c8a746eac815901b2","title":"Large-Scale Domain-Specific Pretraining for Biomedical Vision-Language Processing"},{"paperId":"4d4a96708fc67403176bb2b891b564af7a20c148","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training"},{"paperId":"c011a59b155965caf2ab5cdf9e61e6544142a981","title":"X-TRA: Improving Chest X-ray Tasks with Cross-Modal Retrieval Augmentation"},{"paperId":"cd7d70a3fc45608c2c17b784539a2add8ccffcf9","title":"CLIP-Driven Universal Model for Organ Segmentation and Tumor Detection"},{"paperId":"24aa57dae649b6683d8f5bc8deaf2ff549cdacc4","title":"Transformers in Medical Imaging: A Survey"},{"paperId":"2ea26b243171e37ef20af269942ffde414f9f8cc","title":"UnICLAM: Contrastive Representation Learning with Adversarial Masking for Unified and Interpretable Medical Vision Question Answering"},{"paperId":"56d8d9fff399f798da97a69e891de4eeb4568d4f","title":"MHKD-MVQA: Multimodal Hierarchical Knowledge Distillation for Medical Visual Question Answering"},{"paperId":"170667a96f04adf3b3b83526f75fe8d1063e0f7a","title":"Self-supervised vision-language pretraining for Medical visual question answering"},{"paperId":"4be48792dfdb5876023fb0523cd25d4b89083ef4","title":"Remote sensing visual question answering with a self-attention multi-modal encoder"},{"paperId":"51d2032637f97fd0a10d01d80ced906d0b6e6444","title":"Transfer Learning for Medical Image Classification on Multiple Datasets using PubMedCLIP"},{"paperId":"6ae700c89a9a9a3da7e55dd51c4710b5ed8c8d4e","title":"Caption-Aware Medical VQA via Semantic Focusing and Progressive Cross-Modality Comprehension"},{"paperId":"5d8fd04c436367b18b35e28332ee8e452a477f3f","title":"Medical Image Understanding with Pretrained Vision Language Models: A Comprehensive Study"},{"paperId":"28ff0816f19a5e3e37eac5569de41872fd262f0a","title":"Align, Reason and Learn: Enhancing Medical Vision-and-Language Pre-training with Knowledge"},{"paperId":"2441230bd2f3cca924d597b3044ad63aaff269ec","title":"Self-supervised Co-learning of Uncurated Images and Reports Enables Oversight AI in Radiology"},{"paperId":"79478a2ac67b9fdbeadcde13faa2d84eb239e080","title":"Vision-Language Pretraining Enables Radiographs and Reports to be Learned without Curation"},{"paperId":"b047b3b7d76b79958e23b0fcab985be22b1ce42d","title":"Alternating Cross-attention Vision-Language Model for Efficient Learning with Medical Image and Report without Curation"},{"paperId":"6dd9f99cecd38504b667d320eb2a6267a9fee35d","title":"Contrastive Learning of Medical Visual Representations from Paired Images and Text"},{"paperId":"49b43e98c4ffc4ee0383f15940c97e9540a64c9f","title":"Language over Labels: Contrastive Language Supervision Exceeds Purely Label-Supervised Classification Performance on Chest X-Rays"}],"references":[{"paperId":"8f167ec1149921fac63b1ea855443de109bb013a","title":"How Much Can CLIP Benefit Vision-and-Language Tasks?"},{"paperId":"6dd9f99cecd38504b667d320eb2a6267a9fee35d","title":"Contrastive Learning of Medical Visual Representations from Paired Images and Text"},{"paperId":"e4f99837e02e7fbcccec1bf15cececacaaabbe32","title":"MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering"},{"paperId":"ac74a160e0ca53d3ffb15f79f0b9d3911df2fc28","title":"Glance-and-Gaze Vision Transformer"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"93b6b79b4ef6c345f31722ce7c829385c6dce0d6","title":"Slake: A Semantically-Labeled Knowledge-Enhanced Dataset For Medical Visual Question Answering"},{"paperId":"a6ca91afe845ef5294c40c2029e0c1cba19ba40b","title":"Unifying Vision-and-Language Tasks via Text Generation"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"519799a9e2a72b808d81c6bcba5de263503de053","title":"Contrastive Pre-training and Representation Distillation for Medical Visual Question Answering Based on Radiology Images"},{"paperId":"357fc385caf2e5b9898c9140fa3ac9955e6bb3c6","title":"TeamS at VQA-Med 2021: BBN-Orchestra for Long-tailed Medical Visual Question Answering"},{"paperId":"13e7212d5af59137ad770f42712d762247ebd3ed","title":"SYSU-HCP at VQA-Med 2021: A Data-centric Model with Efficient Training Methodology for Medical Visual Question Answering"},{"paperId":"b8d5b853f2212cbb48a43f1edec9b96d76d388ec","title":"Medical Visual Question Answering via Conditional Reasoning"},{"paperId":"1e5fb8003f866f9beeb1003f0be9a129d480ae75","title":"Problems and Opportunities in Training Deep Learning Software Systems: An Analysis of Variance"},{"paperId":"6adb61121ca4560915ade532910acde56440b88f","title":"A Question-Centric Model for Visual Question Answering in Medical Imaging"},{"paperId":"2527626c11a84f15709e943fbfa2356e19930e3b","title":"VL-BERT: Pre-training of Generic Visual-Linguistic Representations"},{"paperId":"39dbb2e49fb33351044a9b8c152a173b31f4c405","title":"Overview of the VQA-Med Task at ImageCLEF 2021: Visual Question Answering and Generation in the Medical Domain"},{"paperId":"3c8a456509e6c0805354bd40a35e3f2dbf8069b1","title":"PyTorch: An Imperative Style, High-Performance Deep Learning Library"},{"paperId":"33301b25a297b701bdc287e985c006375cb7bb21","title":"Overcoming Data Limitation in Medical Visual Question Answering"},{"paperId":"18f9a6045ba01cb079c4fa49a630d71bbd27cd92","title":"A dataset of clinically generated visual questions and answers about radiology images"},{"paperId":"a564fabf130ff6e2742cfba90c7a4018937d764d","title":"Radiology Objects in COntext (ROCO): A Multimodal Image Dataset"},{"paperId":"a5d10341717c0519cf63151b496a6d2ed67aa05f","title":"Bilinear Attention Networks"},{"paperId":"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81","title":"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge"},{"paperId":"c889d6f98e6d79b89c3a6adf8a921f88fa6ba518","title":"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"},{"paperId":"e7eef2ac4136ec93bd306d2c9c353a13729a4553","title":"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"},{"paperId":"2c03df8b48bf3fa39054345bafabfeff15bfd11d","title":"Deep Residual Learning for Image Recognition"},{"paperId":"2c1890864c1c2b750f48316dc8b650ba4772adc5","title":"Stacked Attention Networks for Image Question Answering"},{"paperId":"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db","title":"VQA: Visual Question Answering"},{"paperId":"a6cb366736791bcccc5c8639de5a8f9636bf87e8","title":"Adam: A Method for Stochastic Optimization"},{"paperId":"f37e1b62a767a307c046404ca96bc140b3e68cb5","title":"GloVe: Global Vectors for Word Representation"},{"paperId":"1c6d990c80e60aa0b0059415444cdf94b3574f0f","title":"Stacked Convolutional Auto-Encoders for Hierarchical Feature Extraction"}],"id":"4ef3d9e492479e28fa57d107e52acc6a0c803de2","summary":"A fine-tuned version of CLIP for the medical domain based on PubMed articles is presented, which leads to noticeable improvements for MedVQA and fundamental performance differences of VQA in general versus medical domains are witnessed."},{"url":"https://www.semanticscholar.org/paper/02251886950770e82b3d68564d60cdfe15e73199","title":"Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks","venue":"arXiv.org","year":2022,"referenceCount":74,"citationCount":164,"influentialCitationCount":25,"publicationDate":"22/08/2022","authors":"Wenhui Wang,Hangbo Bao,Li Dong,Johan Bjorck,Zhiliang Peng,Qiang Liu,Kriti Aggarwal,O. Mohammed,Saksham Singhal,S. Som,Furu Wei","citations":[{"paperId":"131c6f328c11706de2c43cd16e0b7c5d5e610b6a","title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond"},{"paperId":"268fa90820d0a1db5c35e056d291984ede3f0aed","title":"A Strong and Reproducible Object Detector with Only Public Datasets"},{"paperId":"12c5ae248c9e724d3675c3c43806fadf3411c618","title":"A Cookbook of Self-Supervised Learning"},{"paperId":"2bc22b50f2a517fa57ae48135f42b18ba3da1cb4","title":"CoT-MoTE: Exploring ConTextual Masked Auto-Encoder Pre-training with Mixture-of-Textual-Experts for Passage Retrieval"},{"paperId":"5b69c50a3699c8c46c3016b0dcf176b8e0bfe3aa","title":"Enhancing Textbooks with Visuals from the Web for Improved Learning"},{"paperId":"22a7d8293f1b487372938977a76706462aed6045","title":"Shuffled Transformer for Privacy-Preserving Split Learning"},{"paperId":"b7d73f22d861f526541575a3b17449bd3c58ca74","title":"MVP-SEG: Multi-View Prompt Learning for Open-Vocabulary Semantic Segmentation"},{"paperId":"a43a3fadc9190e61b34f59a913f1716e443519e4","title":"On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence"},{"paperId":"e8acb3e6ae754b18eb5e1d8466b11d6e1d81d1ae","title":"Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction"},{"paperId":"51615bee01c966ba055920e10778d5331d35bccd","title":"MoMo: A shared encoder Model for text, image and multi-Modal representations"},{"paperId":"0312e70901f352a6d95f23573788f9f7b737c983","title":"Training Large Language Models Efficiently with Sparsity and Dataflow"},{"paperId":"2a8d0f85252f486d6585621268ead2c941f0bd8a","title":"Improving Image Recognition by Retrieving from Web-Scale Image-Text Data"},{"paperId":"45c2f1672ef1de301868453acaf23f6df9a34b8a","title":"A Billion-scale Foundation Model for Remote Sensing Images"},{"paperId":"aae77fd74c99b2f6c10366267ce993b2d94141d5","title":"On Robustness in Multimodal Learning"},{"paperId":"87df8e436b91823b69ce660e1913bf723bc1cec5","title":"Token Boosting for Robust Self-Supervised Visual Transformer Pre-training"},{"paperId":"47e3a2efde1df91a4d90a8f008f39a55f983f6bc","title":"Video ChatCaptioner: Towards Enriched Spatiotemporal Descriptions"},{"paperId":"41721e0e0b7ce945d9d317bb83df2d9cb74b3114","title":"Attention: Marginal Probability is All You Need?"},{"paperId":"13581a46d32822e44cbeb1acdba4a59cef2b2ec1","title":"On Efficient Training of Large-Scale Deep Learning Models: A Literature Review"},{"paperId":"db1c83ef73d2f7731b0dd255835f2f26db749e17","title":"Not All Features Matter: Enhancing Few-shot CLIP with Adaptive Prior Refinement"},{"paperId":"599080fc0e2af249d2dc2e4ecb90a900c380926c","title":"A Novel Scenarios Engineering Methodology for Foundation Models in Metaverse"},{"paperId":"d8b0425e83bdf0335092f21147884236956872db","title":"Self-Supervised Multimodal Learning: A Survey"},{"paperId":"c84e2801512069acbc63f1a7f73273281939428c","title":"A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision"},{"paperId":"5643d0f64b326ce07797ab78da1ec013096dc0cd","title":"MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks"},{"paperId":"b259d853b71a2d03cefa844bb9343b8e3ed816b1","title":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"},{"paperId":"d7adb2e6c8e381ca6c7a9a74ec5c54061573f9e1","title":"Revisiting Multimodal Representation in Contrastive Learning: From Patch and Token Embeddings to Finite Discrete Tokens"},{"paperId":"d064075c47e358f604034d06df4b985356757c71","title":"Equivariant Similarity for Vision-Language Foundation Models"},{"paperId":"f9badd638eb683f2ba39fd089fbabb87c9a63787","title":"IFSeg: Image-free Semantic Segmentation via Vision-Language Model"},{"paperId":"830d4beeaf56db871db842e3445c16b571f5a904","title":"Accelerating Vision-Language Pretraining with Free Language Modeling"},{"paperId":"8a4dd69533378b4e1e1d6429de4f2c6eab18e101","title":"CoBIT: A Contrastive Bi-directional Image-Text Generation Model"},{"paperId":"67317a73151316933c3943ff68b5f7cfcbc7e4c7","title":"MAGVLT: Masked Generative Vision-and-Language Transformer"},{"paperId":"3049c992adbd56e29c4d957ee0c4e9d05fe3c6d1","title":"EVA-02: A Visual Representation for Neon Genesis"},{"paperId":"21b94d1878fe19fcaeed12361d7453aea9181ea7","title":"eP-ALM: Efficient Perceptual Augmentation of Language Models"},{"paperId":"f760912a793b53b0164670956e27bad9edd8bff1","title":"MXM-CLR: A Unified Framework for Contrastive Learning of Multifold Cross-Modal Representations"},{"paperId":"4396e30f28eb49bb07c63cf62ca90415ebbe43d4","title":"IRGen: Generative Modeling for Image Retrieval"},{"paperId":"6c5cfc5a8debff3dab55764b6b6b534d7c47ce72","title":"Enhancing the Role of Context in Region-Word Alignment for Object Detection"},{"paperId":"bb8075a3ac5375566bab20a244da74a2d10b1352","title":"Dual-path Adaptation from Image to Video Transformers"},{"paperId":"45d29ab954a9cc3888883217b686e7ab80296716","title":"Reinforce Data, Multiply Impact: Improved Model Accuracy and Robustness with Dataset Reinforcement"},{"paperId":"9d12916dd46df7a6446cbec0bc4d054f7dafcdab","title":"Scaling Vision-Language Models with Sparse Mixture of Experts"},{"paperId":"f5df5a3cc5435b3cfd517bded331e05fed961d78","title":"Align and Attend: Multimodal Summarization with Dual Contrastive Losses"},{"paperId":"3d45e69557f0c6a54ec698304c2e27ec29bc1c2b","title":"PMC-CLIP: Contrastive Language-Image Pre-training using Biomedical Documents"},{"paperId":"530bee65ee844ed794d98b1120e4cf2738558316","title":"ViM: Vision Middleware for Unified Downstream Transferring"},{"paperId":"019a4e48f0a29583427f6369ebc716174fe33746","title":"One Transformer Fits All Distributions in Multi-Modal Diffusion at Scale"},{"paperId":"69cfdc8df16ae63b7acba4ac6f727f78b86893c3","title":"ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions"},{"paperId":"374dc9612e3507d1d3517492589c177a73be8e21","title":"Understanding and Constructing Latent Modality Structures in Multi-modal Representation Learning"},{"paperId":"9cbf01298c09d7f9729be962a86ea368bb812050","title":"Tag2Text: Guiding Vision-Language Model via Image Tagging"},{"paperId":"980668424b68c02271f39b3f71dc416eb0439cc5","title":"HumanBench: Towards General Human-centric Perception with Projector Assisted Pretraining"},{"paperId":"b5b136ac59f1a75bdb1273f398526062ca223359","title":"New Audio Representations Image Gan Generation from BriVL"},{"paperId":"7ad627f426691601aa4ffea2092cb51c2f37ed8a","title":"Exploiting the Textual Potential from Vision-Language Pre-training for Text-based Person Search"},{"paperId":"e39e5601bde42fcc3ef770dc03e4607f42963bbe","title":"Bootstrap The Original Latent: Freeze-and-thaw Adapter for Back-Propagated Black-Box Adaptation"},{"paperId":"36291f1e302d95fa5558442d61a2d64e538ea206","title":"Bootstrap The Original Latent: Learning a Private Model from a Black-box Model"},{"paperId":"a935ba7ce7fd44fe372c6860504fbc164f012f03","title":"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention"},{"paperId":"0a0acae0a9466f24d17d447a575f0efa5b90ee0e","title":"FAME-ViL: Multi-Tasking Vision-Language Model for Heterogeneous Fashion Tasks"},{"paperId":"a339df8024808b006f8f91db613961dc1c346afe","title":"DejaVu: Conditional Regenerative Learning to Enhance Dense Prediction"},{"paperId":"e64dc184ec4ef8c6f3e0046e25e20b5dbe043ff4","title":"Visual Atoms: Pre-training Vision Transformers with Sinusoidal Waves"},{"paperId":"4d4a96708fc67403176bb2b891b564af7a20c148","title":"RAMM: Retrieval-augmented Biomedical Visual Question Answering with Multi-modal Pre-training"},{"paperId":"fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c","title":"Language Is Not All You Need: Aligning Perception with Language Models"},{"paperId":"facc16fa1226124cca9cc8f91411c3d6303e53d0","title":"Few-shot Multimodal Multitask Multilingual Learning"},{"paperId":"da9579539385daedd33a0de0f814e2977ad0d1f5","title":"Towards Unifying Medical Vision-and-Language Pre-training via Soft Prompts"},{"paperId":"4f56322c7a418900818723bad81f8315c9f1b627","title":"UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling"},{"paperId":"c3bd63aea228d74f086b81a7b7b90e0d3b4c4242","title":"SubTuning: Efficient Finetuning for Multi-Task Learning"},{"paperId":"0e57006711cc83095eeee02c12e371a5d991a2e7","title":"Analyzing Multimodal Objectives Through the Lens of Generative Diffusion Guidance"},{"paperId":"42c7c81f6b388334d65392a76ca37661660c8087","title":"Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning"},{"paperId":"f2b528e716f09f9e4bd6a45847c95814c47722c9","title":"SimCon Loss with Multiple Views for Text Supervised Semantic Segmentation"},{"paperId":"fac388b8c24044dea06cc8c7b03dd1d99c8439a0","title":"AIM: Adapting Image Models for Efficient Video Action Recognition"},{"paperId":"64caaab51d8339f1b99874d3bddb79debbe661ca","title":"mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image and Video"},{"paperId":"6d7534a41fc933f4f6a99e039f585dc57a370a29","title":"ADAPT: Action-aware Driving Caption Transformer"},{"paperId":"600d3ad507c581cd143f363d8d55042da53ef142","title":"UPop: Unified and Progressive Pruning for Compressing Vision-Language Transformers"},{"paperId":"81620597ffafb4368cf0fe4fab7b7cd4506e09cd","title":"Advancing Radiograph Representation Learning with Masked Record Modeling"},{"paperId":"336ce63b472a65f053f854d45851d6f0e896f05e","title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"},{"paperId":"f10d25c3a19d5bf3544dc56076d90a02ed99eae9","title":"ClimaX: A foundation model for weather and climate"},{"paperId":"46afac2f89e0f5ff1c250cdf280cf2669fefbe7d","title":"Masked Autoencoding Does Not Help Natural Language Supervision at Scale"},{"paperId":"b759f3fcf2459013c710bc0b000c46c8e70f9bf8","title":"PRUDEX-Compass: Towards Systematic Evaluation of Reinforcement Learning in Financial Markets"},{"paperId":"9b5a11d9bb3790dbbb02725231b290f67579469a","title":"A Survey of Self-Supervised Learning from Multiple Perspectives: Algorithms, Theory, Applications and Future Trends"},{"paperId":"701a9882884a473faa92324ea6c1ff6c9dacc3ce","title":"Toward Building General Foundation Models for Language, Vision, and Vision-Language Understanding Tasks"},{"paperId":"d16ac1cc0036ffda0d44383304df8bd4f8e38c95","title":"Vision Transformers Are Good Mask Auto-Labelers"},{"paperId":"e0b63fd4dd74239a7eb1b75e0108ca55bcad782d","title":"All in Tokens: Unifying Output Space of Visual Tasks via Soft Token"},{"paperId":"397156af1b4fc1f1c3bbbe5c2dbc698ef0b9b6ec","title":"Policy Pre-training for End-to-end Autonomous Driving via Self-supervised Geometric Modeling"},{"paperId":"aa5645b4896acb72aa4893d174af765d962aa708","title":"Policy Pre-training for Autonomous Driving via Self-supervised Geometric Modeling"},{"paperId":"6f6c19b44c1e82e24d2b34683669e93277539021","title":"Disjoint Masking with Joint Distillation for Efficient Masked Image Modeling"},{"paperId":"497a1accfd0be6cad1be4f2b6fa88078dae7414a","title":"Quant 4.0: Engineering Quantitative Investment with Automated, Explainable and Knowledge-driven Artificial Intelligence"},{"paperId":"14c840a7faa15a7e42e5664b5e896878d91dd8ae","title":"Self Supervision Does Not Help Natural Language Supervision at Scale"},{"paperId":"52b79321a4862d44db09065e4b40021e2ec1eb0c","title":"On Realization of Intelligent Decision-Making in the Real World: A Foundation Decision Model Perspective"},{"paperId":"ab972a92dd5ac31f8b8b026a64707bfeb3149397","title":"Do DALL-E and Flamingo Understand Each Other?"},{"paperId":"007323e9a19faa7be415eb2122dd331b11a54989","title":"Reversible Column Networks"},{"paperId":"d2aa89bbfa5eb972626f189cd7454f7d6d0af7c3","title":"MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction Tuning"},{"paperId":"967907503b24423b9b74621051811fcf684e3957","title":"Generalized Decoding for Pixel, Image, and Language"},{"paperId":"9575afb5702bc33d7df14c48feeee5901ea00369","title":"A Length-Extrapolatable Transformer"},{"paperId":"4c8655f2618b26317fee53190eb1efcddcdfd12b","title":"Position-guided Text Prompt for Vision-Language Pre-training"},{"paperId":"fbed623ca22abaa493081f7d97be51b1c317d437","title":"Transferring General Multimodal Pretrained Models to Text Recognition"},{"paperId":"89a1dbbfd4c96d90b769f5d3427bd970b082898e","title":"BEATs: Audio Pre-Training with Acoustic Tokenizers"},{"paperId":"22471140ae31b15dd55241e4be0c8bb851961ddc","title":"Autoencoders as Cross-Modal Teachers: Can Pretrained 2D Image Transformers Help 3D Representation Learning?"},{"paperId":"30279ffe74bc5eccbb37bf7082056e7065727bc4","title":"On Human Visual Contrast Sensitivity and Machine Vision Robustness: A Comparative Study"},{"paperId":"1b31dbf44e68b698120552366df03e6e35a1e428","title":"Objaverse: A Universe of Annotated 3D Objects"},{"paperId":"ec8f75e22ffbb5ad7e2f9cfc20a7780eed45715b","title":"CLIPPO: Image-and-Language Understanding from Pixels Only"},{"paperId":"fe34137e5cc07235eae65ce53a54cd226b9f8b23","title":"MAGVIT: Masked Generative Video Transformer"},{"paperId":"3e8251f259dc529b3aa2366fc68c1516b202cfb9","title":"REVEAL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory"},{"paperId":"c8dbf43fc20160814b9506de32be86ada91fa725","title":"VindLU: A Recipe for Effective Video-and-Language Pretraining"},{"paperId":"f5c853861fcde704a7100e24e963c5262e625229","title":"Video-Text Modeling with Zero-Shot Transfer from Contrastive Captioners"},{"paperId":"8ca316a10a2749e4c6bf3d0284e8cce2f56a4543","title":"Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive Learning"},{"paperId":"2096246df0649fbbd9adc7895d2a50beeb46b6b7","title":"Structured Vision-Language Pretraining for Computational Cooking"},{"paperId":"d232d97761490828f20e9b77d2c91a135a7270ee","title":"OFASys: A Multi-Modal Multi-Task Learning System for Building Generalist Models"},{"paperId":"933b37b21e9d61139660088adb032ff3fdf56d86","title":"Learning Video Representations from Large Language Models"},{"paperId":"508d9b43832790b4d35f4ae1fa76e9712859d6aa","title":"Vision and Structured-Language Pretraining for Cross-Modal Food Retrieval"},{"paperId":"458e3d2be80c401fb47e562d9d57012bd63da1c3","title":"Talking Head Generation with Probabilistic Audio-to-Visual Diffusion Priors"},{"paperId":"325d8e9501af05e594bd668b6cd6d43ed42c8b4d","title":"InternVideo: General Video Foundation Models via Generative and Discriminative Learning"},{"paperId":"17066da1e298a997c123f551bf0515daccc2b7b5","title":"Unifying Vision, Text, and Layout for Universal Document Processing"},{"paperId":"36306b2de6e9b2b11d53b029e754b03977de6072","title":"Compound Tokens: Channel Fusion for Vision-Language Representation Learning"},{"paperId":"040fdeabc5e934f13eb7b05c1907568b7d7efe81","title":"Knowledge Helps Pretrained Model: An Ensemble Model of Knowledge Model and CLIP for Zero-shot Image Recognition"},{"paperId":"1db3db7e00fd53290f0c0d07f22937ed5fedfabf","title":"Masked Contrastive Pre-Training for Efficient Video-Text Retrieval"},{"paperId":"91694fc5f0bae350157f4fc565d0207ae12f7eb9","title":"FusionBrain: Research Project in Multimodal and Multitask Learning"},{"paperId":"3dc7cb6c14cec8b02a150bfb8ce95e8e3e8a01f2","title":"Synaptic Dynamics Realize First-order Adaptive Learning and Weight Symmetry"},{"paperId":"4e6a2d863aeaafed82a8411f01be6e5a9f801b44","title":"SLAN: Self-Locator Aided Network for Cross-Modal Understanding"},{"paperId":"f64111aa1a5695e9209bca131469b1dc184d91d0","title":"Seeing What You Miss: Vision-Language Pre-training with Semantic Completion Learning"},{"paperId":"1c199e3d50349153c0b6200006b02fbe66c27acd","title":"X2-VLM: All-In-One Pre-trained Model For Vision-Language Tasks"},{"paperId":"13c97db0f424449ae384b20b18022a3d7e422455","title":"DETRs with Collaborative Hybrid Assignments Training"},{"paperId":"fd8c1b8741163d8737652fbcd3507bcd7d6225c7","title":"Multitask Vision-Language Prompt Tuning"},{"paperId":"66e6d0dd6fe47db69f55bb6f959d672e6e5c6bbd","title":"VATLM: Visual-Audio-Text Pre-Training with Unified Masked Prediction for Speech Representation Learning"},{"paperId":"33ef78737ba57ecc1ff98c22369a8e17ed90eb98","title":"Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models"},{"paperId":"ee96ec926f06ff2f3ce3d131cffcbfe63af39f0c","title":"Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information"},{"paperId":"b2286da2b293b50644e5dc8ddd75eb8651e8b257","title":"UniFormerV2: Spatiotemporal Learning by Arming Image ViTs with Video UniFormer"},{"paperId":"96282f6456b10da5acfb8268632ef86645f4b339","title":"Cross-Modal Adapter for Text-Video Retrieval"},{"paperId":"30a3731f09e7a391e79a28fa736fa6bdd8331866","title":"Uni-Perceiver v2: A Generalist Model for Large-Scale Vision and Vision-Language Tasks"},{"paperId":"78281482c1fdad8e167bab39cc9955c73d58ae8f","title":"EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"},{"paperId":"db3b99c407ff8a06bdc96151dfae1328fadfb858","title":"Grafting Pre-trained Models for Multimodal Headline Generation"},{"paperId":"26c80bd65baa90f5b18157de4951f4eb0b62ab69","title":"InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions"},{"paperId":"6a993404e07687b7edb7fb9a05092213a9419859","title":"OneFormer: One Transformer to Rule Universal Image Segmentation"},{"paperId":"b839b60ffcdedf3f0dfa43da3eefe843307679f3","title":"Towards Reasoning-Aware Explainable VQA"},{"paperId":"c90a33f1f0049d524e9b5b3174d35611fd9a8096","title":"Pretraining in Deep Reinforcement Learning: A Survey"},{"paperId":"58a18a0937fc199e87fbd455af3a53b157462217","title":"Group DETR v2: Strong Object Detector with Encoder-Decoder Pretraining"},{"paperId":"3526c4f136b70b0b8c050a5e2e2926103da1c871","title":"Semantic Segmentation Algorithms for Ground AGV and UAV Medical Transport Scenes"},{"paperId":"3c2b12824b0027edb49b68300cbeab02cfc49ca8","title":"Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese"},{"paperId":"82a867d6d699231bf4de20dcac8efb293d11e7df","title":"State-of-the-art Models for Object Detection in Various Fields of Application"},{"paperId":"c3d38dcba5b954d7b9919eb3f6f90afd095f1801","title":"Behavioral Intention Prediction in Driving Scenes: A Survey"},{"paperId":"9a6d83c836ce6389b526b941d971eee775aa573e","title":"ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts"},{"paperId":"30477855d76058a9b542cabea3058aad1a837d51","title":"A Case for Business Process-Specific Foundation Models"},{"paperId":"aeaf6966d460f28db97609e9baa45276395d05d5","title":"Less is More: Learning Simplicity in Datacenter Scheduling"},{"paperId":"eba51c023f3ae9eeca783893b973db60e7a99a6c","title":"A Unified View of Masked Image Modeling"},{"paperId":"07099fe26ee8850c9ccba6fe2ee139d67289b67c","title":"Foundation Transformers"},{"paperId":"6540916e3ebaeaccefeaa303ba94c50bd581ff2a","title":"Like a bilingual baby: The advantage of visually grounding a bilingual language model"},{"paperId":"a7336f6afd4eb817e66ca3eeb9c0a89ffacd53ed","title":"VoLTA: Vision-Language Transformer with Weakly-Supervised Local-Feature Alignment"},{"paperId":"29c2d3d77b6d6f24f4356d5ba20c1a6ab4229c76","title":"Open-Vocabulary Semantic Segmentation with Mask-adapted CLIP"},{"paperId":"d68c8db0e1b8b7f1e6c44393e0a425daa44a16c7","title":"VIMA: General Robot Manipulation with Multimodal Prompts"},{"paperId":"8d6da4ea99898b208d93e7cba4d0ab0b8e160002","title":"W HEN AND WHY V ISION -L ANGUAGE M ODELS BE HAVE LIKE B AGS - OF -W ORDS , AND WHAT TO DO ABOUT IT ?"},{"paperId":"10667c1ae4b49808772b5a377c5b52196701267f","title":"When and why vision-language models behave like bags-of-words, and what to do about it?"},{"paperId":"836ca61c0226fd5f763335ad4c13acc784251343","title":"Towards a Unified View on Visual Parameter-Efficient Transfer Learning"},{"paperId":"13d78bde4dc7059ab941871048ffa91d556584c8","title":"Where Should I Spend My FLOPS? Efficiency Evaluations of Visual Pre-training Methods"},{"paperId":"9b9fb973e5d3b413baa90648d9eb0743bd889747","title":"Spotlight: Mobile UI Understanding using Vision-Language Models with a Focus"},{"paperId":"fdb86bd47092e777b6a75c597ec9982df37a8da8","title":"Correlation Information Bottleneck: Towards Adapting Pretrained Multimodal Models for Robust Visual Question Answering"},{"paperId":"9fc5878d49c41beb12b62032b0afe9a8501fe9db","title":"PaLI: A Jointly-Scaled Multilingual Language-Image Model"},{"paperId":"0afc96eca8b94d19a4c98fdd78e5fd9c68f6859a","title":"Statistical Foundation Behind Machine Learning and Its Impact on Computer Vision"},{"paperId":"29ac542838974c75a3ac40e5855ec7d346ea87ee","title":"Design of the topology for contrastive visual-textual alignment"},{"paperId":"599be9043ef3571f65758cf36e184c9dc1781baf","title":"BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers"},{"paperId":"620369d6ed3ed68c3e4374d6ddf282e0b036d2f8","title":"Masked Vision and Language Modeling for Multi-modal Representation Learning"},{"paperId":"8b5eab31e1c5689312fff3181a75bfbf5c13e51c","title":"Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"},{"paperId":"e617e103269488c0dae861066ccbacc0375a0efc","title":"Bridge-Tower: Building Bridges Between Encoders in Vision-Language Representation Learning"},{"paperId":"53ae1072fd04080e4fc2c9205ebcbc2683d7264c","title":"Sparse Mixture-of-Experts are Domain Generalizable Learners"},{"paperId":"5598c4ece8ffc69a7eb584d16f6de6629044e76a","title":"Vision Transformer Adapter for Dense Predictions"},{"paperId":"c26bb68806a992bf4fc85b5639e1657a445c4781","title":"On the Representation Collapse of Sparse Mixture of Experts"},{"paperId":"fa717a2e31f0cef4e26921f3b147a98644d2e64c","title":"Focal Modulation Networks"},{"paperId":"3c9ba25baca64151af4e9d50c7947de28eb2a599","title":"Survey of Hallucination in Natural Language Generation"},{"paperId":"660ddea322b193c7428f2a3149ebe3d24ff9d88d","title":"Image-and-Language Understanding from Pixels Only"},{"paperId":"363270facc8a3ff229a2688f29f16800d45092ff","title":"A Unified View of Masked Image Modeling"},{"paperId":"0d0269f8533a33c3c310fd0a59815aa16a0c47ff","title":"Perception Test : A Diagnostic Benchmark for Multimodal Models"},{"paperId":"26a2a15c16c78f586169e4768720187c1ef14f8a","title":"COMPRESSING VISION-LANGUAGE TRANSFORMERS"}],"references":[{"paperId":"599be9043ef3571f65758cf36e184c9dc1781baf","title":"BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers"},{"paperId":"3e448df5aa191f7a3945d0fd609c8bc5966a2333","title":"HorNet: Efficient High-Order Spatial Interactions with Recursive Gated Convolutions"},{"paperId":"a8fd9c1625011741f74401ff9bdc1c584e25c86d","title":"Language Models are General-Purpose Interfaces"},{"paperId":"49b5ffebdbcbd683010a2558a19eaa9b21cd8c34","title":"GLIPv2: Unifying Localization and Vision-Language Understanding"},{"paperId":"eb940c4169b83d2a204aec4b8547d1b1a8d0491c","title":"Mask DINO: Towards A Unified Transformer-based Framework for Object Detection and Segmentation"},{"paperId":"0aa3cd5ab502b3dd7f23cf4781cd44305a642bea","title":"VL-BEiT: Generative Vision-Language Pretraining"},{"paperId":"5c4f8de98525eebd762773093d149ba459cef290","title":"Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation"},{"paperId":"5598c4ece8ffc69a7eb584d16f6de6629044e76a","title":"Vision Transformer Adapter for Dense Predictions"},{"paperId":"a26a7a74f1e5fd562be95c3611a0680759fbdf84","title":"CoCa: Contrastive Captioners are Image-Text Foundation Models"},{"paperId":"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","title":"Flamingo: a Visual Language Model for Few-Shot Learning"},{"paperId":"2ad12a7be5eaf339a98c4defd8669e11fe726acc","title":"MaxViT: Multi-Axis Vision Transformer"},{"paperId":"a09cbcaac305884f043810afc4fa4053099b5970","title":"Exploring Plain Vision Transformer Backbones for Object Detection"},{"paperId":"54020e5fe48ebb250f27d744e20a63cac2988a84","title":"Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time"},{"paperId":"850aafb5c565e3ba4e374a9367bc464c1b8d8676","title":"DINO: DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection"},{"paperId":"1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa","title":"Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"},{"paperId":"a3b42a83669998f65df60d7c065a70d07ca95e99","title":"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"},{"paperId":"2fd6f77540c1cc8e70b96208ccf9971b4251fc02","title":"FLAVA: A Foundational Language And Vision Alignment Model"},{"paperId":"9137efc758f80dd22bb56f82cca5c94f78a5db3e","title":"MViTv2: Improved Multiscale Vision Transformers for Classification and Detection"},{"paperId":"658a017302d29e4acf4ca789cb5d9f27983717ff","title":"Masked-attention Mask Transformer for Universal Image Segmentation"},{"paperId":"be0fbb810583930c071d0b9b2c5187fe260783f5","title":"Swin Transformer V2: Scaling Up Capacity and Resolution"},{"paperId":"f675c62abfa788ea0be85d3124eba15a14d5e9d6","title":"FILIP: Fine-grained Interactive Language-Image Pre-Training"},{"paperId":"5e00596fa946670d894b1bdaeff5a98e3867ef13","title":"SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"},{"paperId":"722ad6ac92286507437b31486f47987d6ece05c9","title":"BEiT: BERT Pre-Training of Image Transformers"},{"paperId":"2a805d0e1b067444a554c5169d189fa1f649f411","title":"Scaling Vision Transformers"},{"paperId":"21ec90872abd986c12afe39bebe807732ffa70c9","title":"Florence: A New Foundation Model for Computer Vision"},{"paperId":"cf7c2e0e4fb2af689aaf4b7a7cddf7b1f4d5e3f0","title":"VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts"},{"paperId":"633d88b3b9c2dd578d9cfa90aa0abecd6ac86789","title":"s2s-ft: Fine-Tuning Pretrained Transformer Encoders for Sequence-to-Sequence Learning"},{"paperId":"b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1","title":"Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"},{"paperId":"fd51da088c5fe89eba0e363edad746bb3c2407d1","title":"End-to-End Semi-Supervised Object Detection with Soft Teacher"},{"paperId":"9f4b69762ffb1ba42b573fd4ced996f3153e21c0","title":"CoAtNet: Marrying Convolution and Attention for All Data Sizes"},{"paperId":"63c74d15940af1af9b386b5762e4445e54c73719","title":"VinVL: Revisiting Visual Representations in Vision-Language Models"},{"paperId":"1ee1160b8c7c70ded02e786c184a6da651e88bed","title":"Dynamic Head: Unifying Object Detection Heads with Attentions"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"394be105b87e9bfe72c20efe6338de10604e1a11","title":"Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"},{"paperId":"141a5033d9994242b18bb3b217e79582f1ee9306","title":"Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"},{"paperId":"0839722fb5369c0abaff8515bfc08299efc790a1","title":"ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"bc626a52664e948a0ffb2b95d0e1e6377a01171a","title":"Cascade R-CNN: High Quality Object Detection and Instance Segmentation"},{"paperId":null,"title":"In 2021 IEEE/CVF International Conference on Computer Vision"},{"paperId":"2f5f81bc516a6d085d39479378af1fc27104f91e","title":"Large-Scale Adversarial Training for Vision-and-Language Representation Learning"},{"paperId":"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57","title":"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"},{"paperId":"f64e1d6bc13aae99aab5449fc9ae742a9ba7761e","title":"UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"},{"paperId":"d8a305b9366608d54452ac30459ee57b4f5cf1c9","title":"UNITER: UNiversal Image-TExt Representation Learning"},{"paperId":"c5ff974a69fd0c760b4855b819e61e89f31cfffe","title":"Objects365: A Large-Scale, High-Quality Dataset for Object Detection"},{"paperId":"077f8329a7b6fa3b7c877a57b81eb6c18b5f87de","title":"RoBERTa: A Robustly Optimized BERT Pretraining Approach"},{"paperId":"f4327b978dec52f16b089c222c43543f8ecf4717","title":"arXiv"},{"paperId":"1c71771c701aadfd72c5866170a9f5d71464bb88","title":"Unified Language Model Pre-training for Natural Language Understanding and Generation"},{"paperId":"cf336d272a30d6ad6141db67faa64deb8791cd61","title":"A Corpus for Reasoning about Natural Language Grounded in Photographs"},{"paperId":"d07284a6811f1b2745d91bdb06b040b57f226882","title":"Decoupled Weight Decay Regularization"},{"paperId":null,"title":"In 7th International Conference on Learning Representations"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"b5246fa284f86b544a7c31f050b3bd0defd053fd","title":"SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing"},{"paperId":"b4df354db88a70183a64dbc9e56cf14e7669a6c0","title":"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"},{"paperId":"d7b6753a2d4a2b286c396854063bde3a91b75535","title":"A Simple Method for Commonsense Reasoning"},{"paperId":"155b7782dbd713982a4133df3aee7adfd0b6b304","title":"Unsupervised Feature Learning via Non-parametric Instance Discrimination"},{"paperId":"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8","title":"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"},{"paperId":"88512be44744615f4baa8e14f600f036db4c2433","title":"Semantic Understanding of Scenes Through the ADE20K Dataset"},{"paperId":"cd18800a0fe0b668a1cc19f2ec95b5003d0a5035","title":"Improving Language Understanding by Generative Pre-Training"},{"paperId":null,"title":"In 2018 IEEE Conference on Computer Vision and Pattern Recognition"},{"paperId":null,"title":"and Ilya Sutskever"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","title":"Attention is All you Need"},{"paperId":"53c0aa8d33d240197caff824a6225fb223c1181c","title":"Soft-NMS — Improving Object Detection with One Line of Code"},{"paperId":"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e","title":"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"},{"paperId":"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88","title":"Deep Visual-Semantic Alignments for Generating Image Descriptions"},{"paperId":"51db1f3c8dfc7d4077da39c96bb90a6358128111","title":"Deep Networks with Stochastic Depth"},{"paperId":"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d","title":"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"},{"paperId":null,"title":"editors"},{"paperId":"0e6824e137847be0599bb0032e37042ed2ef5045","title":"Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books"},{"paperId":"11c9c31dff70de92ada9160c78ff8bb46b2912d6","title":"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models"},{"paperId":"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd","title":"ImageNet Large Scale Visual Recognition Challenge"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","title":"Microsoft COCO: Common Objects in Context"},{"paperId":"bc6dff14a130c57a91d5a21339c23471faf1d46f","title":"Et al"},{"paperId":"8e080b98efbe65c02a116439205ca2344b9f7cd4","title":"Im2Text: Describing Images Using 1 Million Captioned Photographs"},{"paperId":"b5d998e26c6ca1eb24f0008125baddac273c80f7","title":"Tasks"}],"id":"02251886950770e82b3d68564d60cdfe15e73199","summary":"This work introduces a general-purpose multimodal foundation model BEiT-3, which achieves state-of-the-art transfer performance on both vision and vision-language tasks and introduces Multiway Transformers for general- Purpose modeling, where the modular architecture enables both deep fusion and modality-specific encoding."},{"url":"https://www.semanticscholar.org/paper/967907503b24423b9b74621051811fcf684e3957","title":"Generalized Decoding for Pixel, Image, and Language","venue":"arXiv.org","year":2022,"referenceCount":99,"citationCount":7,"influentialCitationCount":0,"publicationDate":"21/12/2022","authors":"Xueyan Zou,Zi-Yi Dou,Jianwei Yang,Zhe Gan,Linjie Li,Chunyuan Li,Xiyang Dai,Harkirat Singh Behl,Jianfeng Wang,Lu Yuan,Nanyun Peng,Lijuan Wang,Yong Jae Lee,Jianfeng Gao","citations":[{"paperId":"9570a3abed7c339ea2fa8d89ad1ee0f459e42fc1","title":"Transformer-Based Visual Segmentation: A Survey"},{"paperId":"644ccdedbe79bf1de26ffec692ad7f7d6cbe7b1e","title":"Segment Everything Everywhere All at Once"},{"paperId":"0931888d5cd7c26427cc116af2ac33863552da27","title":"SAM.MD: Zero-shot medical image segmentation capabilities of the Segment Anything Model"},{"paperId":"c7a9c7302a72301ed79a7c0696d5af2e03ad3ac4","title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action"},{"paperId":"f8e37aa69b3c9b743055e648851c530b18dc54d2","title":"Neural Implicit Vision-Language Feature Fields"},{"paperId":"33827bb0bb8188817083be024614f82bec002c42","title":"A Simple Framework for Open-Vocabulary Segmentation and Detection"},{"paperId":"994a1ce6677b496bd3c0c63aceafc6556005e994","title":"GLIGEN: Open-Set Grounded Text-to-Image Generation"}],"references":[{"paperId":"b287a2765e5bceb732de39dafdf70594dc9cd664","title":"Vision-Language Pre-training: Basics, Recent Advances, and Future Trends"},{"paperId":"667bb464a348b2bc85e7a8e8159b948498850ec7","title":"DetCLIP: Dictionary-Enriched Visual-Concept Paralleled Pre-training for Open-world Detection"},{"paperId":"02251886950770e82b3d68564d60cdfe15e73199","title":"Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"},{"paperId":"42254a2361f8a1380f3593fbc56ece21da806103","title":"Open-Vocabulary Panoptic Segmentation with MaskCLIP"},{"paperId":"4540b16bc97e329bd9d987c96321ffb210844edd","title":"k-means Mask Transformer"},{"paperId":"8b5eab31e1c5689312fff3181a75bfbf5c13e51c","title":"Unified-IO: A Unified Model for Vision, Language, and Multi-Modal Tasks"},{"paperId":"06761cb27e14aa55a6c3d98b949898aa26416698","title":"A Unified Sequence Interface for Vision Tasks"},{"paperId":"4c559d29e19f1226353f52ffe9f8068db1cef943","title":"Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone"},{"paperId":"49b5ffebdbcbd683010a2558a19eaa9b21cd8c34","title":"GLIPv2: Unifying Localization and Vision-Language Understanding"},{"paperId":"add94abe9502e1853e870d63abaddfcbe36a0e8e","title":"Towards General Purpose Vision Systems: An End-to-End Task-Agnostic Vision-Language Architecture"},{"paperId":"60ee030773ba1b68eb222a265b052ca028353362","title":"GIT: A Generative Image-to-text Transformer for Vision and Language"},{"paperId":"055cd2faeebc7a9df43923d554a61ae924a4af6b","title":"UViM: A Unified Modeling Approach for Vision with Learned Guiding Codes"},{"paperId":"5598c4ece8ffc69a7eb584d16f6de6629044e76a","title":"Vision Transformer Adapter for Dense Predictions"},{"paperId":"9dae204dad41633188022002a04c8aa67c79a4e1","title":"Simple Open-Vocabulary Object Detection with Vision Transformers"},{"paperId":"a26a7a74f1e5fd562be95c3611a0680759fbdf84","title":"CoCa: Contrastive Captioners are Image-Text Foundation Models"},{"paperId":"7d3b912398c6132d506bebb070211f6b9c339482","title":"ELEVATER: A Benchmark and Toolkit for Evaluating Language-Augmented Visual Models"},{"paperId":"dc25df2fa756ec90cfe8f7cac0cba34b570b7d0b","title":"X-DETR: A Versatile Architecture for Instance-wise Vision-Language Tasks"},{"paperId":"4b8d8d36a18fd61a6eda3322d8dd3baad2819600","title":"Unified Contrastive Learning in Image-Text-Label Space"},{"paperId":"15480f3e0a909938f874bed983399cbac064e653","title":"DaViT: Dual Attention Vision Transformers"},{"paperId":"fa717a2e31f0cef4e26921f3b147a98644d2e64c","title":"Focal Modulation Networks"},{"paperId":"0b5f27a5766c5d1394a6282ad94fec21d620bd6b","title":"GroupViT: Semantic Segmentation Emerges from Text Supervision"},{"paperId":"1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa","title":"Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"},{"paperId":"cc9826c222ac1e81b4b374dd9e0df130f298b1e8","title":"Language-driven Semantic Segmentation"},{"paperId":"c10075b3746a9f3dd5811970e93c8ca3ad39b39d","title":"High-Resolution Image Synthesis with Latent Diffusion Models"},{"paperId":"e77c484af99fc1eb3d3c36699ac81822e98cb74d","title":"Image Segmentation Using Text and Image Prompts"},{"paperId":"837173ef1f260adc0d50b76675915776e1cc8ade","title":"RegionCLIP: Region-based Language-Image Pretraining"},{"paperId":"2fd6f77540c1cc8e70b96208ccf9971b4251fc02","title":"FLAVA: A Foundational Language And Vision Alignment Model"},{"paperId":"5341b412383c43f4a693ad63ec4489e3ec7688c8","title":"Grounded Language-Image Pre-training"},{"paperId":"bbb583dccbec7407f0d01502b03deb67323724fe","title":"LAVT: Language-Aware Vision Transformer for Referring Image Segmentation"},{"paperId":"658a017302d29e4acf4ca789cb5d9f27983717ff","title":"Masked-attention Mask Transformer for Universal Image Segmentation"},{"paperId":"6d1ef4436904de111c8b1975bbf25d3fe2f165f7","title":"DenseCLIP: Language-Guided Dense Prediction with Context-Aware Prompting"},{"paperId":"74f4439c6a0ec7baa17d1829c9dbc7d2010404fd","title":"Open-Vocabulary Instance Segmentation via Robust Cross-Modal Pseudo-Labeling"},{"paperId":"22312f763328cf540791de8c2449ea1e7436f476","title":"UniTAB: Unifying Text and Box Outputs for Grounded Vision-Language Modeling"},{"paperId":"94ff111c4d81bd03f159321728ceec8b4711c89d","title":"An Empirical Study of Training End-to-End Vision-and-Language Transformers"},{"paperId":"ca30f4371367f07a17ba42d9dab76cac1d9fd943","title":"Panoptic SegFormer: Delving Deeper into Panoptic Segmentation with Transformers"},{"paperId":"5e00596fa946670d894b1bdaeff5a98e3867ef13","title":"SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"},{"paperId":"cf9b8da26d9b92e75ba49616ed2a1033f59fce14","title":"Open-vocabulary Object Detection via Vision and Language Knowledge Distillation"},{"paperId":"21ec90872abd986c12afe39bebe807732ffa70c9","title":"Florence: A New Foundation Model for Computer Vision"},{"paperId":"c05cd00ae61f3c1c39be2603a2f96fdfe0c59dd8","title":"UFO: A UniFied TransfOrmer for Vision-Language Representation Learning"},{"paperId":"b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1","title":"Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"},{"paperId":"3d4b1c580c4df032549a84ee1a5114a09863ce18","title":"SOLQ: Segmenting Objects by Learning Queries"},{"paperId":"63c74d15940af1af9b386b5762e4445e54c73719","title":"VinVL: Revisiting Visual Representations in Vision-Language Models"},{"paperId":"e3d7778a47c6cab4ea1ef3ee9d19ec1510c15c60","title":"SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers"},{"paperId":"7ba9c013988eaff5cd186d73704af329d027872d","title":"MDETR - Modulated Detection for End-to-End Multi-Modal Understanding"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"a87bb9e70d1127b6a9c0e721e48c0b58c997c70e","title":"UniT: Multimodal Multitask Learning with a Unified Transformer"},{"paperId":"141a5033d9994242b18bb3b217e79582f1ee9306","title":"Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"},{"paperId":"0839722fb5369c0abaff8515bfc08299efc790a1","title":"ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision"},{"paperId":"a6ca91afe845ef5294c40c2029e0c1cba19ba40b","title":"Unifying Vision-and-Language Tasks via Text Generation"},{"paperId":"81002fbb777f860f9aac2bbc24467a62345af279","title":"Decoupling the Role of Data, Attention, and Losses in Multimodal Transformers"},{"paperId":"787119e3c3f819244c82b7d97779473773e60696","title":"MaX-DeepLab: End-to-End Panoptic Segmentation with Mask Transformers"},{"paperId":"268d347e8a55b5eb82fb5e7d2f800e33c75ab18a","title":"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"},{"paperId":"39ca8f8ff28cc640e3b41a6bd7814ab85c586504","title":"Deformable DETR: Deformable Transformers for End-to-End Object Detection"},{"paperId":"90b95c6a63df4cbcc52aa8eb77e5f8bc71b90deb","title":"Open-Vocabulary Image Segmentation"},{"paperId":"c8b25fab5608c3e033d34b4483ec47e68ba109b7","title":"Swin Transformer: Hierarchical Vision Transformer using Shifted Windows"},{"paperId":"4cec2f39cbf10d670140d7146dd221049fdc2afc","title":"A survey on instance segmentation: state of the art"},{"paperId":"1a09b8d7946bb61deffe21cdd453b2c53cdd1634","title":"MSeg: A Composite Dataset for Multi-Domain Semantic Segmentation"},{"paperId":"962dc29fdc3fbdc5930a10aba114050b82fe5a3e","title":"End-to-End Object Detection with Transformers"},{"paperId":"862f2e2e5ba7b8b83f42226170c634ecb02834e4","title":"Conditional Convolutions for Instance Segmentation"},{"paperId":"d8a305b9366608d54452ac30459ee57b4f5cf1c9","title":"UNITER: UNiversal Image-TExt Representation Learning"},{"paperId":"2527626c11a84f15709e943fbfa2356e19930e3b","title":"VL-BERT: Pre-training of Generic Visual-Linguistic Representations"},{"paperId":"1a0912bb76777469295bb2c059faee907e7f3258","title":"Mask R-CNN"},{"paperId":null,"title":"Oscar: Object-semantics aligned pretraining for vision-language"},{"paperId":"79c93274429d6355959f1e4374c2147bb81ea649","title":"LXMERT: Learning Cross-Modality Encoder Representations from Transformers"},{"paperId":"5aec474c31a2f4b74703c6f786c0a8ff85c450da","title":"VisualBERT: A Simple and Performant Baseline for Vision and Language"},{"paperId":"65a9c7b0800c86a196bc14e7621ff895cc6ab287","title":"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"},{"paperId":"69455376f5ad52cac5b72d5e8c6cf03fb466b55c","title":"Cross-Modal Self-Attention Network for Referring Image Segmentation"},{"paperId":"653d92ca61d77a906eabb880f40cac12f6f1dc12","title":"YOLACT: Real-Time Instance Segmentation"},{"paperId":"dce916351ef589afa7a63452648dd8acba931e92","title":"Panoptic Segmentation"},{"paperId":"d07284a6811f1b2745d91bdb06b040b57f226882","title":"Decoupled Weight Decay Regularization"},{"paperId":"cc628fee1e83bfba1d581bfa128c9cb6c28ef8ad","title":"YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark"},{"paperId":"810eafc9e854ea9b1d7a9e9f755f8102310d5db6","title":"Dynamic Multimodal Instance Segmentation guided by natural language queries"},{"paperId":"b4df354db88a70183a64dbc9e56cf14e7669a6c0","title":"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"},{"paperId":"4f0b8f730273e9f11b2bfad2415485414b96299f","title":"BDD100K: A Diverse Driving Video Database with Scalable Annotation Tooling"},{"paperId":"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8","title":"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"},{"paperId":"2cc6ba3dfd6bf1f6257b2e4651f4cae355284286","title":"Obj2Text: Generating Visually Descriptive Language from Object Layouts"},{"paperId":"2a5667702b0f1ff77dde8fb3e2e10d4e05e8de9d","title":"Scene Parsing through ADE20K Dataset"},{"paperId":"ee4a012a4b12d11d7ab8c0e79c61e807927a163c","title":"Rethinking Atrous Convolution for Semantic Image Segmentation"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","title":"Attention is All you Need"},{"paperId":"3d69edb02e935b782b90175cb691f6ab5f4bd64f","title":"Recurrent Multimodal Interaction for Referring Image Segmentation"},{"paperId":"86eef3a1dff2bd2808847358cdb7f5ba2b7e0214","title":"Modeling Context Between Objects for Referring Expression Understanding"},{"paperId":"29efbe391950ae438c63d86ad5c82b2942efb0b4","title":"Modeling Context in Referring Expressions"},{"paperId":"b133e361e2f8af22b823d25060b2e7c47f690985","title":"Segmentation from Natural Language Expressions"},{"paperId":"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d","title":"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"},{"paperId":"e65142010431ffc089b272a1174214e00693e503","title":"Generation and Comprehension of Unambiguous Object Descriptions"},{"paperId":"acae6171717fcf3795dd8fc187384d70ea1b9076","title":"A REVIEW ON IMAGE SEGMENTATION TECHNIQUES"},{"paperId":"11c9c31dff70de92ada9160c78ff8bb46b2912d6","title":"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models"},{"paperId":"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db","title":"VQA: Visual Question Answering"},{"paperId":"696ca58d93f6404fea0fc75c62d1d7b378f47628","title":"Microsoft COCO Captions: Data Collection and Evaluation Server"},{"paperId":"317aee7fc081f2b137a85c4f20129007fd8e717e","title":"Fully convolutional networks for semantic segmentation"},{"paperId":"5ffd74d2873b7cba2cbc5fd295cc7fbdedca22a2","title":"The Cityscapes Dataset"},{"paperId":"3419ccd5c94d301ee08d716d037f0c3c6a62e78e","title":"The Role of Context for Object Detection and Semantic Segmentation in the Wild"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","title":"Microsoft COCO: Common Objects in Context"},{"paperId":"8e080b98efbe65c02a116439205ca2344b9f7cd4","title":"Im2Text: Describing Images Using 1 Million Captioned Photographs"},{"paperId":"d2c733e34d48784a37d717fe43d9e93277a8c53e","title":"ImageNet: A large-scale hierarchical image database"},{"paperId":"0ec48ac86456cea3d6d6172ca81ef68e98b21a61","title":"The PASCAL Visual Object Classes Challenge"},{"paperId":"26e1f436f653dcae6d6c4a3e104629ff4da6ffe2","title":"Survey on Image Segmentation"},{"paperId":null,"title":"Dataset Scene Annotation Format # Images # Classes Sem Inst Pano ADE-150 common"},{"paperId":null,"title":"SegInW results with tuning on X-Decoder for different image shots and backbone architectures. (0.26M parameters tuned in the setting"}],"id":"967907503b24423b9b74621051811fcf684e3957","summary":"X-Decoder is the first work that provides a unified way to support all types of image segmentation and a variety of vision-language (VL) tasks and achieves state-of-the-art results on open-vocabulary segmentsation and referring segmentation on eight datasets."},{"url":"https://www.semanticscholar.org/paper/336ce63b472a65f053f854d45851d6f0e896f05e","title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models","venue":"arXiv.org","year":2023,"referenceCount":40,"citationCount":49,"influentialCitationCount":10,"publicationDate":"30/01/2023","authors":"Junnan Li,Dongxu Li,S. Savarese,Steven Hoi","citations":[{"paperId":"7e32aac43e9f1df49e116add03327ee6f365dbf3","title":"mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"},{"paperId":"d4f1b4b094748eb7b847de9437023a35882b9094","title":"ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System"},{"paperId":"59dfa986cc7468561d2c19cdb43f816406ea30d8","title":"TR0N: Translator Networks for 0-Shot Plug-and-Play Conditional Generation"},{"paperId":"598b3961f767c1ad40cbb393afd936de4e30d578","title":"SATIN: A Multi-Task Metadataset for Classifying Satellite Imagery using Vision-Language Models"},{"paperId":"7562e25b666cba841b1dd5cf6e700978922beb04","title":"SkinGPT: A Dermatology Diagnostic System with Vision Large Language Model"},{"paperId":"8fce3142bc144bdc08bf0cab1db908c7ad3f8454","title":"Contrastive Language, Action, and State Pre-training for Robot Learning"},{"paperId":"f44ad7ad67ddd5fe74598fe491ca75c5221380df","title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"},{"paperId":"05859a33290f3c581dcf7ab0d4796b35d9cd4d74","title":"LLM as A Robotic Brain: Unifying Egocentric Memory and Control"},{"paperId":"1a8eb2cae1833df3bf12fe3b41b03d60b4a4a98d","title":"Visual Instruction Tuning"},{"paperId":"b7d73f22d861f526541575a3b17449bd3c58ca74","title":"MVP-SEG: Multi-View Prompt Learning for Open-Vocabulary Semantic Segmentation"},{"paperId":"a43a3fadc9190e61b34f59a913f1716e443519e4","title":"On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence"},{"paperId":"f12ebcc9a0a7296cc6c85b243a003f7205c68b3d","title":"What does CLIP know about a red circle? Visual prompt engineering for VLMs"},{"paperId":"4d94dcc6c9c261c8edcd0f3c5a1318a98a45b79d","title":"HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models"},{"paperId":"47e3a2efde1df91a4d90a8f008f39a55f983f6bc","title":"Video ChatCaptioner: Towards Enriched Spatiotemporal Descriptions"},{"paperId":"db1c83ef73d2f7731b0dd255835f2f26db749e17","title":"Not All Features Matter: Enhancing Few-shot CLIP with Adaptive Prior Refinement"},{"paperId":"1c7471996a4f2e08a5ef592a6ffcde65a034a1e4","title":"GlyphDraw: Learning to Draw Chinese Characters in Image Synthesis Models Coherently"},{"paperId":"c84e2801512069acbc63f1a7f73273281939428c","title":"A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision"},{"paperId":"bf54ccf6e5c9a7da47a0909471002881913f02ba","title":"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace"},{"paperId":"b259d853b71a2d03cefa844bb9343b8e3ed816b1","title":"LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention"},{"paperId":"a08b7123a7158f1a7fbbc18e8b5aaebd47980ecf","title":"EVA-CLIP: Improved Training Techniques for CLIP at Scale"},{"paperId":"d064075c47e358f604034d06df4b985356757c71","title":"Equivariant Similarity for Vision-Language Foundation Models"},{"paperId":"d84616f108ccbd958735fef7622e58d148b32139","title":"Make-It-3D: High-Fidelity 3D Creation from A Single Image with Diffusion Prior"},{"paperId":"0d3817ae7fecc204c7c79a039dc47ae88890d5f3","title":"ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model"},{"paperId":"285dae5c2f2ef55c70971094a1ddd45afe720eee","title":"Fundamentals of Generative Large Language Models and Perspectives in Cyber-Defense"},{"paperId":"994e08ac813028601907516aee9c4699234a6b4d","title":"Large AI Models in Health Informatics: Applications, Challenges, and the Future"},{"paperId":"7733cf84e5447339dd57ca96133e14e36c29e0e7","title":"Contrastive Alignment of Vision to Language Through Parameter-Efficient Transfer Learning"},{"paperId":"049a62ac86f59f2a912cd59f1cb179b82c4ae6b9","title":"TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering"},{"paperId":"c7a9c7302a72301ed79a7c0696d5af2e03ad3ac4","title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action"},{"paperId":"3049c992adbd56e29c4d957ee0c4e9d05fe3c6d1","title":"EVA-02: A Visual Representation for Neon Genesis"},{"paperId":"052a5e2bcc999810ee6f1eedcf758c528e4f125f","title":"Retrieving Multimodal Information for Augmented Generation: A Survey"},{"paperId":"3c39a600adb254f7520f513ed9c3412c9c62f17f","title":"MRIS: A Multi-modal Retrieval Approach for Image Synthesis on Diverse Modalities"},{"paperId":"4396e30f28eb49bb07c63cf62ca90415ebbe43d4","title":"IRGen: Generative Modeling for Image Retrieval"},{"paperId":"6e754273d54a91371efbc928cd6b156364d517da","title":"ViperGPT: Visual Inference via Python Execution for Reasoning"},{"paperId":"cf41ae462687f81ce95b27113c6a4f9c2751de42","title":"Vision-Language Models as Success Detectors"},{"paperId":"aa75ec0ee1aa18d3b0603d5a425e92eabcb7ac02","title":"Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of Synthetic and Compositional Images"},{"paperId":"9d12916dd46df7a6446cbec0bc4d054f7dafcdab","title":"Scaling Vision-Language Models with Sparse Mixture of Experts"},{"paperId":"e5a7be5b9e6c368a1839455bfbb51bc07ed161f1","title":"ODIN: On-demand Data Formulation to Mitigate Dataset Lock-in"},{"paperId":"69cfdc8df16ae63b7acba4ac6f727f78b86893c3","title":"ChatGPT Asks, BLIP-2 Answers: Automatic Questioning Towards Enriched Visual Descriptions"},{"paperId":"af997821231898a5f8d0fd78dad4eec526acabe5","title":"Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models"},{"paperId":"6a4ef6c4799dc871a4253c0536126d397ca3ec1e","title":"Interpretable Visual Question Answering Referring to Outside Knowledge"},{"paperId":"a7b3a868a80dbe97689135c99b1a6b6e10dcdfe5","title":"A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT"},{"paperId":"467b839cb8a2475477ca004df94b797d967ad057","title":"Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes"},{"paperId":"fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c","title":"Language Is Not All You Need: Aligning Perception with Language Models"},{"paperId":"c8f98f28f1f28a9f5db7c4b4d9a6b7853a100214","title":"Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?"},{"paperId":"a3ff4df653b6970898c04e6b768e58b99786d073","title":"Learning gain differences between ChatGPT and human tutor generated algebra hints"},{"paperId":"3062bb79d12ff55c29c8731211a84e8cf344e235","title":"Vision Learners Meet Web Image-Text Pairs"},{"paperId":"00c1ff63468305ea3fa430c2b3aef156d580c4ff","title":"P ROMPT C AP : Prompt-Guided Image Captioning for VQA with GPT-3"},{"paperId":"1367dcff4ccb927a5e95c452041288b3f0dd0eff","title":"Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation"},{"paperId":"d00ca5c49415d3a45bfcf3fabaf0a60a1c52a6ff","title":"PromptCap: Prompt-Guided Task-Aware Image Captioning"}],"references":[{"paperId":"78281482c1fdad8e167bab39cc9955c73d58ae8f","title":"EVA: Exploring the Limits of Masked Visual Representation Learning at Scale"},{"paperId":"5484d228bfc50efbac6e86677bc2ec2ee4ede1a6","title":"Scaling Instruction-Finetuned Language Models"},{"paperId":"9fc5878d49c41beb12b62032b0afe9a8501fe9db","title":"PaLI: A Jointly-Scaled Multilingual Language-Image Model"},{"paperId":"02251886950770e82b3d68564d60cdfe15e73199","title":"Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks"},{"paperId":"a26a7a74f1e5fd562be95c3611a0680759fbdf84","title":"CoCa: Contrastive Captioners are Image-Text Foundation Models"},{"paperId":"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","title":"Flamingo: a Visual Language Model for Few-Shot Learning"},{"paperId":"8342b592fe238f3d230e4959b06fd10153c45db1","title":"Training Compute-Optimal Large Language Models"},{"paperId":"7f71875f8214dffa4f3276da123c4990a6d437cc","title":"Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation"},{"paperId":"a3b42a83669998f65df60d7c065a70d07ca95e99","title":"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"},{"paperId":"197d5867a45a2988f4dd159063cdfbfe90164962","title":"LiT: Zero-Shot Transfer with Locked-image text Tuning"},{"paperId":"f675c62abfa788ea0be85d3124eba15a14d5e9d6","title":"FILIP: Fine-grained Interactive Language-Image Pre-Training"},{"paperId":"32d59ab951be74be351f9777da2cbc71bb68c3c1","title":"A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models"},{"paperId":"5e00596fa946670d894b1bdaeff5a98e3867ef13","title":"SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"},{"paperId":"616e0ed02ca024a8c1d4b86167f7486ea92a13d9","title":"VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning"},{"paperId":null,"title":"OFA: unifying architectures, tasks, and modalities through a simple sequence-tosequence learning framework"},{"paperId":"cf7c2e0e4fb2af689aaf4b7a7cddf7b1f4d5e3f0","title":"VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts"},{"paperId":"b668ce936cff0b0ca8b635cd5f25a62eaf4eb3df","title":"LAION-400M: Open Dataset of CLIP-Filtered 400 Million Image-Text Pairs"},{"paperId":"b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1","title":"Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"},{"paperId":"01b5412f3d17e90e09226d7c40ad4d4468a1414d","title":"Multimodal Few-Shot Learning with Frozen Language Models"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"394be105b87e9bfe72c20efe6338de10604e1a11","title":"Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts"},{"paperId":"141a5033d9994242b18bb3b217e79582f1ee9306","title":"Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision"},{"paperId":"a6ca91afe845ef5294c40c2029e0c1cba19ba40b","title":"Unifying Vision-and-Language Tasks via Text Generation"},{"paperId":"be0014c1fbc3e664686610d2c85f75038a4f6e4f","title":"VinVL: Making Visual Representations Matter in Vision-Language Models"},{"paperId":"6b85b63579a916f705a8e10a49bd8d849d91b1fc","title":"Language Models are Few-Shot Learners"},{"paperId":"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57","title":"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"},{"paperId":"d8a305b9366608d54452ac30459ee57b4f5cf1c9","title":"UNITER: UNiversal Image-TExt Representation Learning"},{"paperId":"79c93274429d6355959f1e4374c2147bb81ea649","title":"LXMERT: Learning Cross-Modality Encoder Representations from Transformers"},{"paperId":"28ad018c39d1578bea84e7cedf94459e3dbe1e70","title":"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"},{"paperId":"1c71771c701aadfd72c5866170a9f5d71464bb88","title":"Unified Language Model Pre-training for Natural Language Understanding and Generation"},{"paperId":"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1","title":"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"},{"paperId":"d07284a6811f1b2745d91bdb06b040b57f226882","title":"Decoupled Weight Decay Regularization"},{"paperId":"8b55402ffee2734bfc7d5d7595500916e1ef04e8","title":"nocaps: novel object captioning at scale"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"b4df354db88a70183a64dbc9e56cf14e7669a6c0","title":"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning"},{"paperId":"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e","title":"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"},{"paperId":"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d","title":"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations"},{"paperId":"11c9c31dff70de92ada9160c78ff8bb46b2912d6","title":"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","title":"Microsoft COCO: Common Objects in Context"},{"paperId":"8e080b98efbe65c02a116439205ca2344b9f7cd4","title":"Im2Text: Describing Images Using 1 Million Captioned Photographs"}],"id":"336ce63b472a65f053f854d45851d6f0e896f05e","summary":"BLIP-2 achieves state-of-the-art performance on various vision-language tasks, despite having significantly fewer trainable parameters than existing methods, and is demonstrated's emerging capabilities of zero-shot image-to-text generation that can follow natural language instructions."},{"url":"https://www.semanticscholar.org/paper/6edcb09a09c8df43cb62119133df9bb2eb75e5cf","title":"From Images to Textual Prompts: Zero-shot VQA with Frozen Large Language Models","venue":"arXiv.org","year":2022,"referenceCount":69,"citationCount":3,"influentialCitationCount":0,"publicationDate":"21/12/2022","authors":"Jiaxian Guo,Junnan Li,Dongxu Li,A. M. H. Tiong,Boyang Li,Dacheng Tao,Steven Hoi","citations":[{"paperId":"5dea6facab090a070be1444920230689e7189599","title":"SurgicalGPT: End-to-End Language-Vision GPT for Visual Question Answering in Surgery"},{"paperId":"09840a5c151f858ed0eaf1db2a4d3741516f693b","title":"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for Document Information Extraction"},{"paperId":"0f19e94f30b99d6c4b349900057cdae9262034f9","title":"The Contribution of Knowledge in Visiolinguistic Learning: A Survey on Tasks and Challenges"}],"references":[{"paperId":"bb15f3727f827a3cb88b5d3ca48415c09b40a88f","title":"What Language Model to Train if You Have One Million GPU Hours?"},{"paperId":"26fd105d0b5a458979c012cddb3ba2de943388c4","title":"Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training"},{"paperId":"dac3a172b504f4e33c029655e9befb3386e5f63a","title":"Emergent Abilities of Large Language Models"},{"paperId":"47a67e76ed84260ff19f7a948d764005d1edf1c9","title":"A-OKVQA: A Benchmark for Visual Question Answering using World Knowledge"},{"paperId":"57c64f233a0db4d17e0e750c12516364ca009fb2","title":"REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"5437e8adab596d7294124c0e798708e050e25321","title":"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"},{"paperId":"7f5170b8ec68629164a98f8dfa1d2cbef5bbe5f5","title":"All You May Need for VQA are Image Captions"},{"paperId":"13a0d8bb38f739990c8cd65a44061c6534f17221","title":"OPT: Open Pre-trained Transformer Language Models"},{"paperId":"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","title":"Flamingo: a Visual Language Model for Few-Shot Learning"},{"paperId":"094ff971d6a8b8ff870946c9b3ce5aa173617bfb","title":"PaLM: Scaling Language Modeling with Pathways"},{"paperId":"04ef9a02775ee98caca79c7c4d92e9e46eee9ae5","title":"Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding"},{"paperId":"7f71875f8214dffa4f3276da123c4990a6d437cc","title":"Enabling Multimodal Generation on CLIP via Vision-Language Knowledge Distillation"},{"paperId":"79956ac2a4164c298387546fc10139c3d5192842","title":"Webly Supervised Concept Expansion for General Purpose Vision Models"},{"paperId":"a3b42a83669998f65df60d7c065a70d07ca95e99","title":"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"ab8ee8d06ed581c876da3a2e7a5fdb1cbec21a45","title":"KAT: A Knowledge Augmented Transformer for Vision-and-Language"},{"paperId":"2fd6f77540c1cc8e70b96208ccf9971b4251fc02","title":"FLAVA: A Foundational Language And Vision Alignment Model"},{"paperId":"32d59ab951be74be351f9777da2cbc71bb68c3c1","title":"A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models"},{"paperId":"2672777d25562c9df6fc13b653181db62d39bece","title":"An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA"},{"paperId":"5e00596fa946670d894b1bdaeff5a98e3867ef13","title":"SimVLM: Simple Visual Language Model Pretraining with Weak Supervision"},{"paperId":"8dce342a435034fa0521b24b61393397df95c095","title":"Multi-Modal Answer Validation for Knowledge-Based VQA"},{"paperId":"e6a6b66eeb506dc326e3c3f7f49a1f260469c281","title":"VC-GPT: Visual Conditioned GPT for End-to-End Generative Vision-and-Language Pre-training"},{"paperId":"21ec90872abd986c12afe39bebe807732ffa70c9","title":"Florence: A New Foundation Model for Computer Vision"},{"paperId":"a7aa150b55d64d339b1c154d6d88455fc3cbc44f","title":"ClipCap: CLIP Prefix for Image Captioning"},{"paperId":"118962f61df9ab6c8310d5a3eb0ab61f22802360","title":"Language bias in Visual Question Answering: A Survey and Taxonomy"},{"paperId":"467e5a2164cf78c5be70c91129e1c6e843685fb3","title":"Discovering the Unknown Knowns: Turning Implicit Knowledge in the Dataset into Explicit Training Examples for Visual Question Answering"},{"paperId":"4e92fec0a61972ae076707d0630d1333affccdfc","title":"Weakly-Supervised Visual-Retriever-Reader for Knowledge-based Question Answering"},{"paperId":"f5a76442659066434b1bdf480cf11f4f549411ab","title":"QACE: Asking Questions to Evaluate an Image Caption"},{"paperId":"b82c5f9efdb2ae56baa084ca41aeddd8a665c1d1","title":"Align before Fuse: Vision and Language Representation Learning with Momentum Distillation"},{"paperId":"01b5412f3d17e90e09226d7c40ad4d4468a1414d","title":"Multimodal Few-Shot Learning with Frozen Language Models"},{"paperId":"63c74d15940af1af9b386b5762e4445e54c73719","title":"VinVL: Revisiting Visual Representations in Vision-Language Models"},{"paperId":"57ed901be5d1b4d853d4f8998dadc1b60e2151f9","title":"On Attention Redundancy: A Comprehensive Study"},{"paperId":"7e5008713c404445dd8786753526f1a45b93de12","title":"GPT-Neo: Large Scale Autoregressive Language Modeling with Mesh-Tensorflow"},{"paperId":"a6ca91afe845ef5294c40c2029e0c1cba19ba40b","title":"Unifying Vision-and-Language Tasks via Text Generation"},{"paperId":"1a9015e511ec3da873f6114eeb542905a92d7d62","title":"KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA"},{"paperId":"1a575075ba357723009a9a8905d5dccf9115ae6c","title":"WeaQA: Weak Supervision via Captions for Visual Question Answering"},{"paperId":"64a548ca02c8d647358cac809d9c059d34dc4f3a","title":"Radial Graph Convolutional Network for Visual Question Generation"},{"paperId":"4593c88fb33023bec84f8f443d16262810b9047a","title":"CrossVQA: Scalably Generating Benchmarks for Systematically Testing VQA Generalization"},{"paperId":null,"title":"GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https:// github.com/kingoflolz/mesh-transformerjax, May 2021"},{"paperId":"9958887e8dd5f84595818c50fb734b566996541a","title":"ConceptBert: Concept-Aware Representation for Visual Question Answering"},{"paperId":"0030605bfa0a11e7474a8c5ff5b00f3ccdb22b22","title":"Boosting Visual Question Answering with Context-aware Knowledge Aggregation"},{"paperId":"6b85b63579a916f705a8e10a49bd8d849d91b1fc","title":"Language Models are Few-Shot Learners"},{"paperId":"ad5970584754cc7a1d91c95ab84a1e210258183a","title":"UnifiedQA: Crossing Format Boundaries With a Single QA System"},{"paperId":"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57","title":"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"},{"paperId":"6548a60a6bcdf6c402d9de1c05ba7afe4f49fee9","title":"12-in-1: Multi-Task Vision and Language Representation Learning"},{"paperId":"3cfb319689f06bf04c2e28399361f414ca32c4b3","title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"79c93274429d6355959f1e4374c2147bb81ea649","title":"LXMERT: Learning Cross-Modality Encoder Representations from Transformers"},{"paperId":"65a9c7b0800c86a196bc14e7621ff895cc6ab287","title":"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks"},{"paperId":"8faa293b037fb1dc32041b09faa93f7d1aa098e4","title":"Generating Question Relevant Captions to Aid Visual Question Answering"},{"paperId":"28ad018c39d1578bea84e7cedf94459e3dbe1e70","title":"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"},{"paperId":"421cb75cc91e8e5683d41ee6a918121aedf6d24d","title":"Social IQA: Commonsense Reasoning about Social Interactions"},{"paperId":"c21a4d70d83e0f6eb2a9e1c41d034842dd561e47","title":"CommonsenseQA: A Question Answering Challenge Targeting Commonsense Knowledge"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"1536e8958697c5364f68b2e2448905dbbeb3a0ca","title":"Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering"},{"paperId":"36c3972569a6949ecca90bfa6f8e99883e092845","title":"Pythia v0.1: the Winning Entry to the VQA Challenge 2018"},{"paperId":"4d1c856275744c0284312a3a50efb6ca9dc4cd4c","title":"Know What You Don’t Know: Unanswerable Questions for SQuAD"},{"paperId":"99ad0533f84c110da2d0713d5798e6e14080b159","title":"Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences"},{"paperId":"29de7c0fb3c09eaf55b20619bceaeafe72fd87a6","title":"Hierarchical Neural Story Generation"},{"paperId":"90873a97aa9a43775e5aeea01b03aea54b28bfbd","title":"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering"},{"paperId":"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8","title":"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering"},{"paperId":"7e4b638e028498e900747b600f46cd723f1f231e","title":"Data Augmentation for Visual Question Answering"},{"paperId":"915b5b12f9bdebc321e970ecd713458c3479d70e","title":"An Analysis of Visual Question Answering Algorithms"},{"paperId":"26aa6fe2028b5eefbaa40ab54ef725bbbe7d9810","title":"ConceptNet 5.5: An Open Multilingual Graph of General Knowledge"},{"paperId":"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e","title":"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering"},{"paperId":"e7eef2ac4136ec93bd306d2c9c353a13729a4553","title":"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"},{"paperId":"2c1890864c1c2b750f48316dc8b650ba4772adc5","title":"Stacked Attention Networks for Image Question Answering"},{"paperId":"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db","title":"VQA: Visual Question Answering"},{"paperId":null,"title":"Success case analysis for VQAv2. Green color indicates answer cues and correct prediction"}],"id":"6edcb09a09c8df43cb62119133df9bb2eb75e5cf","summary":"Img2Prompt is a plug-and-play module that provides the prompts that can bridge the aforementioned modality and task disconnections, so that LLMs can perform zero-shot VQA tasks without end-to-end training."},{"url":"https://www.semanticscholar.org/paper/af997821231898a5f8d0fd78dad4eec526acabe5","title":"Visual ChatGPT: Talking, Drawing and Editing with Visual Foundation Models","venue":"arXiv.org","year":2023,"referenceCount":57,"citationCount":26,"influentialCitationCount":6,"publicationDate":"08/03/2023","authors":"Chenfei Wu,Sheng-Kai Yin,Weizhen Qi,Xiaodong Wang,Zecheng Tang,Nan Duan","citations":[{"paperId":"d4f1b4b094748eb7b847de9437023a35882b9094","title":"ChatVideo: A Tracklet-centric Multimodal and Versatile Video Understanding System"},{"paperId":"7e32aac43e9f1df49e116add03327ee6f365dbf3","title":"mPLUG-Owl: Modularization Empowers Large Language Models with Multimodality"},{"paperId":"8bc617c9139648d7a92991d70c671230bac7b2e2","title":"AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head"},{"paperId":"7a5c31341e7ec22409e175542368eb76e08900aa","title":"The Potential of Visual ChatGPT For Remote Sensing"},{"paperId":"4c8ef2db0c77aba453783f5211ebafc6695d3835","title":"ChatABL: Abductive Learning via Natural Language Interaction with ChatGPT"},{"paperId":"f44ad7ad67ddd5fe74598fe491ca75c5221380df","title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"},{"paperId":"93cedc10eda0e89757c1d1de67d78cb7e1b5c55b","title":"Learning to Program with Natural Language"},{"paperId":"4c746d8a8368dbea13c7eb7cccfd5d0cc15edb31","title":"Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models"},{"paperId":"01f9b773408115a16fe872147348db175789e82f","title":"Tool Learning with Foundation Models"},{"paperId":"1a8eb2cae1833df3bf12fe3b41b03d60b4a4a98d","title":"Visual Instruction Tuning"},{"paperId":"be2b0396de9431bae931642516a1d3e4906329f5","title":"Low-code LLM: Visual Programming over LLMs"},{"paperId":"644ccdedbe79bf1de26ffec692ad7f7d6cbe7b1e","title":"Segment Everything Everywhere All at Once"},{"paperId":"6316cbb4f1e7dba5806a3310ec7f89f3571bc3db","title":"Boosting Cross-task Transferability of Adversarial Patches with Visual Relations"},{"paperId":"9fd980237e7fdfa4c103a2dc08657e73adf847c4","title":"OpenAGI: When LLM Meets Domain Experts"},{"paperId":"47e3a2efde1df91a4d90a8f008f39a55f983f6bc","title":"Video ChatCaptioner: Towards Enriched Spatiotemporal Descriptions"},{"paperId":"248ee36169895ddcaf3963eb76fb24e1d8ef2f81","title":"Summary of ChatGPT/GPT-4 Research and Perspective Towards the Future of Large Language Models"},{"paperId":"246b84bd960f1516584c82cb2185a12059e77661","title":"A Survey of Large Language Models"},{"paperId":"bf54ccf6e5c9a7da47a0909471002881913f02ba","title":"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace"},{"paperId":"ac7771c332da42b29a913b116bd6ef622cbf89cf","title":"TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs"},{"paperId":"74e8ae03a385e72f5ae377667ba9858fb3e0bfa0","title":"Unleashing the Power of Edge-Cloud Generative AI in Mobile Networks: A Survey of AIGC Services"},{"paperId":"994e08ac813028601907516aee9c4699234a6b4d","title":"Large AI Models in Health Informatics: Applications, Challenges, and the Future"},{"paperId":"c7a9c7302a72301ed79a7c0696d5af2e03ad3ac4","title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action"},{"paperId":"9fe9af7cf3d54b707a7be3c53ce94b77dcc3bae5","title":"A Short Survey of Viewing Large Language Models in Legal Aspect"},{"paperId":"419eb47fea3931c4098232f44ccbc216275d3f56","title":"Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features"},{"paperId":"09ca5072a76796c65e5936b6fb4968afead61944","title":"Semantics-Empowered Communication: A Tutorial-cum-Survey"},{"paperId":"6139b6bc065b24562cb7f4f08227a42f5766138f","title":"Diffusion Models: A Comprehensive Survey of Methods and Applications"}],"references":[{"paperId":"e55695dfe6cde42ee195aa6672fe720ec92ee8c3","title":"Adding Conditional Control to Text-to-Image Diffusion Models"},{"paperId":"780a7f5e8ba9b4b451e3dfee1bcfb0f68aba5050","title":"Multimodal Chain-of-Thought Reasoning in Language Models"},{"paperId":"336ce63b472a65f053f854d45851d6f0e896f05e","title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"},{"paperId":"a2d2bbe4c542173662a444b33b76c66992697830","title":"InstructPix2Pix: Learning to Follow Image Editing Instructions"},{"paperId":"eca35805d185374befe4da48c9f96ace6e962fad","title":"BLOOM: A 176B-Parameter Open-Access Multilingual Language Model"},{"paperId":"90350aa626bed47b02d0c162462e5b0ca82be6b2","title":"Automatic Chain of Thought Prompting in Large Language Models"},{"paperId":"d3135733aa39dec20ce72aa138589dda27c8406d","title":"Learn to Explain: Multimodal Reasoning via Thought Chains for Science Question Answering"},{"paperId":"e7ad08848d5d7c5c47673ffe0da06af443643bda","title":"Large Language Models are Zero-Shot Reasoners"},{"paperId":"5437e8adab596d7294124c0e798708e050e25321","title":"Least-to-Most Prompting Enables Complex Reasoning in Large Language Models"},{"paperId":"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","title":"Flamingo: a Visual Language Model for Few-Shot Learning"},{"paperId":"ada81a4de88a6ce474df2e2446ad11fea480616e","title":"Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"},{"paperId":"23dd78e424d32f6a48660dcd67ce994b8a7db8be","title":"STaR: Bootstrapping Reasoning With Reasoning"},{"paperId":"5f19ae1135a9500940978104ec15a5b8751bc7d2","title":"Self-Consistency Improves Chain of Thought Reasoning in Language Models"},{"paperId":"d766bffc357127e0dc86dd69561d5aeb520d6f4c","title":"Training language models to follow instructions with human feedback"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"a3b42a83669998f65df60d7c065a70d07ca95e99","title":"BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"},{"paperId":"9a2877874b82f64c8e8b3a11fe81e63c9460ce24","title":"UniFormer: Unifying Convolution and Self-attention for Visual Recognition"},{"paperId":"400d619cbabeb669115bb7281a889ab869829ef5","title":"MERLOT RESERVE: Neural Script Knowledge through Vision and Language and Sound"},{"paperId":"c10075b3746a9f3dd5811970e93c8ca3ad39b39d","title":"High-Resolution Image Synthesis with Latent Diffusion Models"},{"paperId":"bdea16e93fc70f316002e5f6aac8ce17388c6ee9","title":"MAGMA - Multimodal Augmentation of Generative Models through Adapter-based Finetuning"},{"paperId":"197d5867a45a2988f4dd159063cdfbfe90164962","title":"LiT: Zero-Shot Transfer with Locked-image text Tuning"},{"paperId":"767923635f2fd4467d848dba9655866e4f9b55c8","title":"Supervision Exists Everywhere: A Data Efficient Contrastive Language-Image Pre-training Paradigm"},{"paperId":"2672777d25562c9df6fc13b653181db62d39bece","title":"An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA"},{"paperId":"2a805d0e1b067444a554c5169d189fa1f649f411","title":"Scaling Vision Transformers"},{"paperId":"0cceb0393b87d3ff65a1f0beea696ce40e889597","title":"Towards Light-Weight and Real-Time Line Segment Detection"},{"paperId":"616e0ed02ca024a8c1d4b86167f7486ea92a13d9","title":"VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning"},{"paperId":"7bd83b055702bc178aa26def5b6df463f8eab7b9","title":"Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer"},{"paperId":"ba9d736006b897d06f75586ad46e28e00a5e566e","title":"VIOLET : End-to-End Video-Language Transformers with Masked Visual-token Modeling"},{"paperId":"cf7c2e0e4fb2af689aaf4b7a7cddf7b1f4d5e3f0","title":"VLMo: Unified Vision-Language Pre-Training with Mixture-of-Modality-Experts"},{"paperId":"260ad39a1dac4b451019e2bf17925f4df8e3b69a","title":"Per-Pixel Classification is Not All You Need for Semantic Segmentation"},{"paperId":"01b5412f3d17e90e09226d7c40ad4d4468a1414d","title":"Multimodal Few-Shot Learning with Frozen Language Models"},{"paperId":"8e33914d6051dd031a5e096962b9398fc1d16067","title":"Vision Transformers for Dense Prediction"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"be0014c1fbc3e664686610d2c85f75038a4f6e4f","title":"VinVL: Making Visual Representations Matter in Vision-Language Models"},{"paperId":"4a657ceb97829a4ab7502f6d01235d1f0140eb0f","title":"Text as Neural Operator:Image Manipulation by Text Instruction"},{"paperId":"053b1d7b97eb2c91fc3921d589c160b0923c70b1","title":"Learning to summarize from human feedback"},{"paperId":"2f5f81bc516a6d085d39479378af1fc27104f91e","title":"Large-Scale Adversarial Training for Vision-and-Language Representation Learning"},{"paperId":"6b85b63579a916f705a8e10a49bd8d849d91b1fc","title":"Language Models are Few-Shot Learners"},{"paperId":"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57","title":"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks"},{"paperId":"953667588e089ae99f049e8574d013bb70aa8517","title":"ManiGAN: Text-Guided Image Manipulation"},{"paperId":"3cfb319689f06bf04c2e28399361f414ca32c4b3","title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"},{"paperId":"af3f67b6639a50fd094e1467a2f3b6b8fef7c7c2","title":"Transformers: State-of-the-Art Natural Language Processing"},{"paperId":"d8a305b9366608d54452ac30459ee57b4f5cf1c9","title":"UNITER: UNiversal Image-TExt Representation Learning"},{"paperId":"29ddc1f43f28af7c846515e32cc167bc66886d0c","title":"Parameter-Efficient Transfer Learning for NLP"},{"paperId":"6dfc2ff03534a4325d06c6f88c3144831996629b","title":"From Recognition to Cognition: Visual Commonsense Reasoning"},{"paperId":"9405cc0d6169988371b2755e573cc28650d14dfe","title":"Language Models are Unsupervised Multitask Learners"},{"paperId":"df2b0e26d0599ce3e70df8a9da02e51594e0e992","title":"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"},{"paperId":"19c12e12946eb3bb9aa7fdeb511eef79fc53b6b3","title":"Canny edge detection based on Open CV"},{"paperId":"204e3073870fae3d05bcbc2f6a8e263d9b72e776","title":"Attention is All you Need"},{"paperId":"9e8db1519245426f3a78752a3d8360484f4626b1","title":"Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields"},{"paperId":"778ce81457383bd5e3fdb11b145ded202ebb4970","title":"Semantic Compositional Networks for Visual Captioning"},{"paperId":"8acbe90d5b852dadea7810345451a99608ee54c7","title":"Image-to-Image Translation with Conditional Adversarial Networks"},{"paperId":"9a522bdd86531839ff292d096e0c4050b787de02","title":"Commonsense reasoning and commonsense knowledge in artificial intelligence"},{"paperId":"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db","title":"VQA: Visual Question Answering"},{"paperId":"8da55e685a7bef9c897788ab519a8710c695c419","title":"Holistically-Nested Edge Detection"},{"paperId":"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0","title":"Show and tell: A neural image caption generator"},{"paperId":"71b7178df5d2b112d07e45038cb5637208659ff7","title":"Microsoft COCO: Common Objects in Context"}],"id":"af997821231898a5f8d0fd78dad4eec526acabe5","summary":"A system to enable the user to interact with ChatGPT by sending and receiving not only languages but also images and providing complex visual questions or visual editing instructions that require the collaboration of multiple AI models with multi-steps, and opens the door to investigating the visual roles ofChatGPT with the help of Visual Foundation Models."},{"url":"https://www.semanticscholar.org/paper/6e754273d54a91371efbc928cd6b156364d517da","title":"ViperGPT: Visual Inference via Python Execution for Reasoning","venue":"arXiv.org","year":2023,"referenceCount":67,"citationCount":5,"influentialCitationCount":1,"publicationDate":"14/03/2023","authors":"D'idac Sur'is,Sachit Menon,Carl Vondrick","citations":[{"paperId":"f44ad7ad67ddd5fe74598fe491ca75c5221380df","title":"MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models"},{"paperId":"4c746d8a8368dbea13c7eb7cccfd5d0cc15edb31","title":"Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models"},{"paperId":"47e3a2efde1df91a4d90a8f008f39a55f983f6bc","title":"Video ChatCaptioner: Towards Enriched Spatiotemporal Descriptions"},{"paperId":"2d3905c1a92c28c056dff1225d89e4ca72ac4d8e","title":"Man vs the machine: The Struggle for Effective Text Anonymisation in the Age of Large Language Models"},{"paperId":"c7a9c7302a72301ed79a7c0696d5af2e03ad3ac4","title":"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action"}],"references":[{"paperId":"fbfef4723d8c8467d7bd523e1d0b703cce0e0f9c","title":"Language Is Not All You Need: Aligning Perception with Language Models"},{"paperId":"53d128ea815bcc0526856eb5a9c42cc977cb36a7","title":"Toolformer: Language Models Can Teach Themselves to Use Tools"},{"paperId":"336ce63b472a65f053f854d45851d6f0e896f05e","title":"BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"},{"paperId":"b909c1905063fe247a7c9359842e8437448f929d","title":"HiTeA: Hierarchical Temporal-Aware Video-Language Pre-training"},{"paperId":"4eb5198062f78ecf844ff48bcaefe4c1c0f395cc","title":"Doubly Right Object Recognition: A Why Prompt for Visual Rationales"},{"paperId":"3e8251f259dc529b3aa2366fc68c1516b202cfb9","title":"REVEAL: Retrieval-Augmented Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory"},{"paperId":"e1c2a926df37107358ac51e460361e2a249c8b26","title":"Open-vocabulary Attribute Detection"},{"paperId":"598d9b235f5ab148fc757240d9bc39a47b8eaf72","title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks"},{"paperId":"6c1e1cc1e0e1f8fd026fe517607b2d4535565fa7","title":"PAL: Program-aided Language Models"},{"paperId":"af1c871282ec122869d03f5420ef5d9143358a91","title":"Visual Programming: Compositional visual reasoning without training"},{"paperId":"d00ca5c49415d3a45bfcf3fabaf0a60a1c52a6ff","title":"PromptCap: Prompt-Guided Task-Aware Image Captioning"},{"paperId":"152dc3042f5d4fc5a2686b5f4e0904f1e12a9207","title":"Code4Struct: Code Generation for Few-Shot Structured Prediction from Natural Language"},{"paperId":"26fd105d0b5a458979c012cddb3ba2de943388c4","title":"Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training"},{"paperId":"11f86abe3d6b1de0678390fed442fdcb62667768","title":"COFAR: Commonsense and Factual Reasoning in Image Search"},{"paperId":"39e40821b7207125e54e6ed7112e55cd38c6f0c3","title":"Language Models of Code are Few-Shot Commonsense Learners"},{"paperId":"a42b091adaf29b06a092b67192ac07cb93312f2a","title":"Visual Classification via Description from Large Language Models"},{"paperId":"6f85ec89d9c07a8db4545e64888ced820370a21b","title":"Retrieval Augmented Visual Question Answering with Outside Knowledge"},{"paperId":"009e40cdc9d98b9e5f6279d38b46936ceffcc124","title":"Video Graph Transformer for Video Question Answering"},{"paperId":"57c64f233a0db4d17e0e750c12516364ca009fb2","title":"REVIVE: Regional Visual Representation Matters in Knowledge-Based Visual Question Answering"},{"paperId":"809822d59203a462bc9f2e0f0e9a8314d6d469d4","title":"Revisiting the “Video” in Video-Language Understanding"},{"paperId":"c1ace33daf974d3d16752c7a8565f32a63b09c49","title":"Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners"},{"paperId":"9dae204dad41633188022002a04c8aa67c79a4e1","title":"Simple Open-Vocabulary Object Detection with Vision Transformers"},{"paperId":"26218bdcc3945c7edae7aa2adbfba4cd820a2df3","title":"Flamingo: a Visual Language Model for Few-Shot Learning"},{"paperId":"408efdd599b2b27ecb95a4d799869c9ff568fb31","title":"ReCLIP: A Strong Zero-Shot Baseline for Referring Expression Comprehension"},{"paperId":"ada81a4de88a6ce474df2e2446ad11fea480616e","title":"Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"},{"paperId":"1bfa62ddfa3f6691e0e40c06f8ead594b6449cfa","title":"Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework"},{"paperId":"1b6e810ce0afd0dd093f789d2b2742d047e316d5","title":"Chain of Thought Prompting Elicits Reasoning in Large Language Models"},{"paperId":"bba57c53ab9b600f71d888601ed0aa03812c8199","title":"MuMuQA: Multimedia Multi-Hop News Question Answering via Cross-Media Knowledge Extraction and Grounding"},{"paperId":"ab8ee8d06ed581c876da3a2e7a5fdb1cbec21a45","title":"KAT: A Knowledge Augmented Transformer for Vision-and-Language"},{"paperId":"5341b412383c43f4a693ad63ec4489e3ec7688c8","title":"Grounded Language-Image Pre-training"},{"paperId":"ec8afc75ec219f2a5f9ed9d7c9dde0720f69b5a2","title":"Multi-Grained Vision Language Pre-Training: Aligning Texts with Visual Concepts"},{"paperId":"09f2b1f1bd313cf9183c138fca8f17bb228b4435","title":"Coarse-to-Fine Reasoning for Visual Question Answering"},{"paperId":"2672777d25562c9df6fc13b653181db62d39bece","title":"An Empirical Study of GPT-3 for Few-Shot Knowledge-Based VQA"},{"paperId":"7bd83b055702bc178aa26def5b6df463f8eab7b9","title":"Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-Shot Cross-Dataset Transfer"},{"paperId":null,"title":"Transform-retrievegenerate: Natural language-centric outside-knowledge visual question answering"},{"paperId":"acbdbf49f9bc3f151b93d9ca9a06009f4f6eb269","title":"Evaluating Large Language Models Trained on Code"},{"paperId":"f46f77630b35a43e8c247916da5d809d6e5b4210","title":"Interpretable visual reasoning: A survey"},{"paperId":"6be64445935dcdf4053a6e78b623b80a314d9bbc","title":"Separating Skills and Concepts for Novel Visual Question Answering"},{"paperId":"6f870f7f02a8c59c3e23f407f3ef00dd1dcf8fc4","title":"Learning Transferable Visual Models From Natural Language Supervision"},{"paperId":"97b93509f6c3c33dd3665d05b1878e36d58a1efb","title":"Interpretable Visual Question Answering by Reasoning on Dependency Trees"},{"paperId":"6b85b63579a916f705a8e10a49bd8d849d91b1fc","title":"Language Models are Few-Shot Learners"},{"paperId":"0416fda32c39fc9531e87bab6a8a1a552bf9ada0","title":"Obtaining Faithful Interpretations from Compositional Neural Networks"},{"paperId":"007ca8ca7a68451c32da034c72a06238434843c1","title":"Learning to Learn Words from Visual Scenes"},{"paperId":null,"title":"arXiv:2005.00724 [cs"},{"paperId":"3c8a456509e6c0805354bd40a35e3f2dbf8069b1","title":"PyTorch: An Imperative Style, High-Performance Deep Learning Library"},{"paperId":"79c93274429d6355959f1e4374c2147bb81ea649","title":"LXMERT: Learning Cross-Modality Encoder Representations from Transformers"},{"paperId":"136c05cb8dd359fb8e0dc7947172a9ecb74ccbec","title":"Learning by Abstraction: The Neural State Machine"},{"paperId":"28ad018c39d1578bea84e7cedf94459e3dbe1e70","title":"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge"},{"paperId":"2dc698077cb178286c737484dcf67c5ab19314d0","title":"Language-Conditioned Graph Networks for Relational Reasoning"},{"paperId":"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1","title":"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering"},{"paperId":"6c7494a47cc5421a7b636c244e13586dc2dab007","title":"Systematic Generalization: What Is Required and Can It Be Learned?"},{"paperId":"b1b852d4bf934863397e7b965a5dd0124ad8670c","title":"Interpretable Visual Question Answering by Visual Grounding From Attention Supervision Mining"},{"paperId":"f27b833c4a0dcb809215b185e8e2601aef6e7fb8","title":"Visual Reasoning by Progressive Module Networks"},{"paperId":"9d15ebe3f5aaf32a9f835f88703241461324c35b","title":"Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language Understanding"},{"paperId":"8d1c8dd0559642a3bdd5c7234d2ce4611e911e23","title":"Visual Grounding via Accumulated Attention"},{"paperId":"289fb3709475f5c87df8d97f129af54029d27fee","title":"Compositional Attention Networks for Machine Reasoning"},{"paperId":"ef153ece43ee50f8208f6197f0eaf3d324e4475b","title":"Multimodal Explanations: Justifying Decisions and Pointing to the Evidence"},{"paperId":"8165d6217a2f623f7d9e613c791e94102921cd3b","title":"Thinking Fast and Slow"},{"paperId":"0fff5c49c05c27c22ac7685130197146491f0b36","title":"The Consciousness Prior"},{"paperId":"2e17cf6a339fd071ad222062f868e882ef4120a4","title":"Inferring and Executing Programs for Visual Reasoning"},{"paperId":"a396a6febdacb84340d139096455e67049ac1e22","title":"Learning to Reason: End-to-End Module Networks for Visual Question Answering"},{"paperId":"e7eef2ac4136ec93bd306d2c9c353a13729a4553","title":"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization"},{"paperId":"21c99706bb26e9012bfb4d8d48009a3d45af59b2","title":"Neural Module Networks"},{"paperId":"4d8f2d14af5991d4f0d050d22216825cac3157bd","title":"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention"},{"paperId":"83cfb832eace6b378d868bba1d32825531438cbd","title":"Visual Programming"},{"paperId":"f9bdd27c48c57426179b1b09ffc517e94cbfca56","title":"Information Streams Sharing a Finite Buffer"},{"paperId":null,"title":"Felipe Petroski Such"}],"id":"6e754273d54a91371efbc928cd6b156364d517da","summary":"ViperGPT is introduced, a framework that leverages code-generation models to compose vision-and-language models into subroutines to produce a result for any query and achieves state-of-the-art results across various complex visual tasks."}]}